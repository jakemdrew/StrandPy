{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StrandPy Library Overview\n",
    "**StrandPy is a Python 3 library including Classifiers, Vectorizers, and Feature Selection tools.**\n",
    "## Vectorizers\n",
    "* **MinhashVectorizer** - An extension of [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) implementing minhashing. MinhashVectorizer supports all [TfidfVectorizer features](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), adding a new minhashing layer. \n",
    " \n",
    " **Novel functionality implemented by MinhashVectorizer also includes:**  \n",
    "  * MinhashVectorizer is able to retain the feature names of features selected during the minhashing process.\n",
    "  * It also supports the creation of both binary and non-binary minhashed matrices. For example, capturing how many times a minhash selected feature occured for a minhashed row / gene sequence / document. \n",
    "  \n",
    "* **StrandVectorizer** - An entirely new minhashing vectorizer that can process both text and numeric data for both sparse and dense matrices.  \n",
    " * Minhashing is typically used on text data only. The StrandVectorizer transforms both text and numeric data into binary or non-binary mihashed feature bins for machine learning. \n",
    "\n",
    "## Classifiers\n",
    "**All StrandPy classifiers implement a single-threaded version of the patented Strand functionality disclosed [here](https://patents.google.com/patent/US20140222736) and [here](https://patents.google.com/patent/US20140344195).** \n",
    "* **StrandSliceClassifier** - A extremely fast and naive Strand sparse matrix based classifier implementing a binary feature voting strategy. \n",
    "* **StrandGiniClassifier** - A Strand classifier assuming that selection of a feature as a minhash value is a mutually exclusive event.  The probability of feature selection is determined by (feature count for class / feature count).\n",
    "* **StrandBinaryClassifier** - A Strand classifier implementing a feature voting strategy which also considers both binary and non-binary feature data provided during classification.\n",
    "* **StrandNonBinaryClassifier** - **UNDER DEVELOPMENT** A Strand classifier implementing a feature voting strategy which also considers both binary and non-binary feature data provided during training and classification.\n",
    "\n",
    "## Feature Selection\n",
    "**StrandPy implements a rapid Cross Validated Feature Selection tool that is optimized for sparse data:**\n",
    "* **CVFE** - Implements sparse matrix based cross validated feature elimination including the following novel optimizations:\n",
    " * Low Nonzero Features - Uses cross validation to eliminates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minhash Vectorizer Overview\n",
    "* MinhashVectorizer uses the python string__hash() function to randomly select features / columns with non-zero values from each input record / document in a consistent fashion.\n",
    "* In this case, the term \"consistent\" means that if two features / columns producing minimum hash values exist in two different input records / documents the MinhashVectorizer would always select those features as part of the minhash signature during the minhashing process.      \n",
    "* When processing string data, each unique k-mer, word, token, n-gram, noun phrase, or any other chunk of text consistently extracted from documents is considered a feature / column in a giant feature matrix. \n",
    " * In a Binary Matrix, a value of True or False would indicate if the feature exists within each record / document / gene sequence.\n",
    " * In a Non-Binary Matrix, a frequency would indicate how many times the feature exists within each record / document / gene sequence. \n",
    " * The values in both Binary and Non-Binary Matrices could also be further transformed using Tf-Idf, L1 / L2 Normalization, IDF Smoothing, Sublinear Tf scaling, among others.   \n",
    "* A dense feature matrix would include: \n",
    " * One column for each unique feature in a document corpora.  \n",
    " * Each row would represent one document. \n",
    " * Each row and column intersection would represent a binary flag, frequency, tfidf value or any other numeric value describing a particular feature within a particular document and document corpus.\n",
    " * When a feature did not exist in a record, the dense matrix would still record NA or 0 for all row and column intersections taking up the same amount of space as when the value exists. \n",
    " * This can take up a considerable amount of extra space for sparse data such as text, gene sequences, or columns resulting from one hot encoding.  In such data, only a small percentage of all known features are used within each row / document.  \n",
    " \n",
    "### Minhash Vectorizer Sparse Matrix Output Format\n",
    "* In practice, most features contained within a given document, gene sequence, or row from a collection of one hot encoded columns will represent a very small fraction (< 1%) of all the unique features found within the document corpora or data table. \n",
    "* As a result, the data is stored in a sparse matrix which allows the vectorizer to fit much larger datasets into memory.  \n",
    "* For example, the RDP gene sequence dataset used below contains 4,786 gene sequences with 807,185 unique k-mers at a length of 20 charcters.  In a dense matrix representation, this dataset would contain 4786 x 807185 = 3,863,187,410 elements / values.  \n",
    "* When represented as a sparse matrix, the same dataset contains only 6,940,414 elements / values.\n",
    "### Minhashing Benefits \n",
    "* For some massive datasets, a sparse matrix representation is still too large.\n",
    "* Minhashing the dataset randomly and consistently selects n non-zero features from the matrix, where n is a number provided in the signature_length parameter. \n",
    "* Minhashing and the signature_length parameter guarantees that no individual document / record will contain more than n non-zero features.\n",
    "* This is a form of dimensionality reduction that effectively shrinks the dataset in a consitent manner, ensuring that the same non-zero features producing minimum hash values are selected from each document when they exist. \n",
    "* For example, the RDP gene sequence dataset used below contains only 1,196,500 stored elements at a signature length of 250 and 4,784,594 stored elements at a signature length of 1,000.\n",
    "* Classification accuracy typically increases as the minhash signature length increases.  However, very accurate classification results may be achieved with shorter signature lengths on some datasets.   \n",
    "### Minhashing Disadvantages\n",
    "* Minhashing is a form of lossy compression.  You cannot return back to the original dataset using a \"minhashed\" dataset.\n",
    "* Both TfidfVectorizer and MinhashVectorizer do not support the transformation of numeric data \"out of the box\" (i.e. You cannot TfidfVectorize or MinhashVectorize numbers).\n",
    "* Hash functions can cause collisions.  Likewise, there may be some collisions that occur during minhashing.\n",
    "* However, since minhashing only impacts which non-zero columns / features are selected from a given document, collisions only impact which features are placed into the minhash signature rather than impacting the underlying data values themselves.   \n",
    "### Feature Importance\n",
    "* Typically feature names become obfuscated by thier respective hash values during minhashing.\n",
    "* However, the MinhashVectorizer() is able to retain feature names during the minhashing process.  \n",
    "* This means that the resulting sparse matrix contains a list of all the unique feature names selected during minhashing and which feature names were selected for a particular row within the minhash signature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinhashVectorizer and the PYTHONHASHSEED\n",
    "* Since the Python 3 string__hash() function is randomly seeded for each new Python 3 session, we need to override this behavior when using the MinhashVectorizer.\n",
    "* Otherwise, the non-zero features randomly selected during fitting and transformations will be different when advanced Python / scikit learn features such as Pipelines are used during cross validation. \n",
    "* We could easily implement our own un-seeded hashing function for the MinhashVectorizer.  However, the Python 3 string__hash() function is implemented in C. So, we would take a big performance hit.  \n",
    "* Implementing an un-seeded hashing function in C specifically for MinhashVectorizer may be worth exploring. \n",
    "* Even when using PYTHONHASHSEED, the behavior is inconsistent between individual Python 3 sessions. \n",
    " * Total number of elements selected from minhashing will remain the same across sessions when using the same parameters.\n",
    " * The features selected as minimum hash values for each row will change, since the hash seed changes between sessions.  \n",
    " * The total number of unique features will also change between sessions for the same data.\n",
    " * The data selected between sessions will still be minhashed properly, a representative sample, and perform with similar accuracy results during cross validation. \n",
    " * Each session's data will just represent a different random selection dur to the randomly seeded hash function.\n",
    "* **WORKAROUND:** You can easily save and read any minhashed sparse datasets to .npz files using .save_npz() and .load_npz()  \n",
    " * This feature allows you to use the same minhashed dataset across any number of sesssions when required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=42\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the RDP Test Dataset (A gene sequence .fasta dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size: 4786\n",
      "Longest Sequence Chars:1834\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_fasta_file(file_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(file_path, 'r') as dat:\n",
    "        for line in dat.readlines():\n",
    "            #print(line)\n",
    "            if line[0] == '>':\n",
    "                g_start = line.find(\"g__\")\n",
    "                g_end = line.find(\";\", g_start)\n",
    "                genus = line[g_start:g_end]\n",
    "                y.append(genus)\n",
    "            else:\n",
    "                X.append(line)\n",
    "    return X, y\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the fasta file\n",
    "X, y = read_fasta_file('D:/StrandPy/Data/RDP_All_Clean.strand')\n",
    "#Remove low count genera that halt cross validation\n",
    "data = {'X': X,'y':y}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Inspect counts for each class\n",
    "vcts = df.y.value_counts()\n",
    "low_vcts = vcts[vcts < 20].index.values\n",
    "\n",
    "#Remove low count genera. Any classes < the fold count will halt cross validation\n",
    "df = df[~df.y.isin(low_vcts)]\n",
    "\n",
    "# Create X and y\n",
    "X = df.X.values\n",
    "y = df.y.values\n",
    "\n",
    "print('File Size: ' + str(len(X)))\n",
    "print('Longest Sequence Chars:' + str(len(max(X, key=len))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Does the Data Look Like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g__Paenibacillus</th>\n",
       "      <td>TCGAGGGGAGCTAGAGTTTTATTAATCCCGGAAATCCACTGANACTTTAGCGGCGGACGGGTGAGTAACACGTAGGTAACCTGCCCATAAGACCGGGATAACATTCGGAAACGGATGCTAATACCCGGATACGCGATTCTCTCGCATGAGAGAAGTTGGGAAAGGCGGAGCAATCTGTCACTTATGGATGGACATGCGGCGCATTAGCTAGTTGGTGAGGTAACGGCTCACCAAGGAGATGATGTGTAGCCCACGTGACAGGGTGATCGGCCACACTGGGNCAGAGACACGGCCCAGACTCTGACGGGAGGCAGCAGTAGGGAATCTTCCGCAATGGAAGAAAATCTGACGGAGCAACGCCGCCTGAGTGATGAAGGTTTTCGGATCGAAAAGCTCTGTTGCCAGGGAAGAACGCTAGAGAGAGTAACTGCTCTTTAGGTGACGGTACCTGAGAAGAAAGCCCCGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGGGCAAGCGTTGTCCGGAATTATTGGGCGTAAAGCGCGCGCAGGCGGTTGATTAAGTCTGGTGTTTAAGGCTATGGCTCAACCATAGTTCGCACTGGAAACTGGTTGAATTGAGTGCAGAAGAGGAAAGTGGAATTCCACGTGTAGCGGTGAAATGCGTAGAGATGTGGAGGAACACCAGTGGCGAAGGCGACTTTCTGGGCGGTAACTGACGCTGAGGCACGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGAATGCTAGGTGTTAGGGGTTTCGATACCCTTGGTGCCGAAGTTAACACATTAAGCATTCCGCCTGGGGAGTACGGTCGCAAGACTGAAACTCAAAGGAATTGACGGGGACCCGCACAAGCAGTGGAGTATGTGGTTTAATTCGAAGCAACGCGAAGAACCTTACCAGGTCTTGACATGCCTCTGACCGCTCTAGAGATAGAGCTTCTCTTCGGAGCAGGGGACACAGGTGGTGCATGGTTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCTGCAACGAGCGCAACCCCTAATGTTAGTTGCCAGCAGGTAGAGCTGGGCACTCTAACGTGACTGCCGGTGACAAACCGGAGGAAGGTGGGGATGACGTCAAATCATCATGCCCCTTATGACCTGGGCTACACACGTACTACAATGGCCAGTACAACGGGAAGCGAAGTCGCGAGATGGAGCCAATCCTCAAAAGCTGGTCTCAGTTCGGATTGCAGGCTGCAACTCGCCTGCATGAAGTCGGAATTGCTAGTAATCGCGGATCAGCATGCCGCGGTGAATACGTTCCCGGGTCTTGTACACACCGCCCGTCACACCACGAGAGTTTACAACACCCGAAGCCGGTGGGGTAACCCGCAAGGGAGCCAGCCGTCGAAGGTGGGGTAGATGATTGGGGTGAAGTCGTAT\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Propionibacterineae</th>\n",
       "      <td>AGGACGAACGCTGGCGGCGTGCTTAACACATGCAAGTCGAACGGTAAGGCCTTTCGGGGTCATACGAGTGGCGAACGGGTGAGTAACACGTGAGCAACCTGCCCTTGACTTCGGAATACCAGCTGGAAACAGCTGCTAATACCGGATATGACCCTGGTCCTCCTGGACTGGGGTGGAAAGCTCCGGCGGTCAGGGATGGGCTCGCGGCCTATCAGCTTGTTGGTGAGGTAATGGCTCACCAAGGCTTCGACGGGTAGCCGGCCTGAGAGGGCGACCGGCCACACTGGGACTGAGATACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGCACAATGGGCGCAAGCCTGATGCAGCAACGCCGCGTGCGGGATGACGGCCTTCGGGTTGTAAACCGCTTTCAGTAGGGACGAAGCCACAAGTGACGGTACCTACAGAAGAAGGACCGGCTAACTACGTGCCAGCAGCCGCGGTGATACGTAGGGTCCGAGCGTTGTCCGGAATTATTGGGCGTAAAGGGCTTGTAGGCGGTCCGTCGCGTCAGGAGTGAAAACTCGGGGCTTAACCCCGAGCCTGCTTTTGATACGGGCGGACTAGAGGGATGCAGGGGAGAACGGAATTCCTGGTGGAGCGGTGGAATGCGCAGATATCAGGAGGAACACCGGTGGCGAAGGCGGTTCTCTGGGCATCACCTGACGCTGAGAAGCGAAAGCGTGGGGAGCAAACAGGCTTAGATACCCTGGTAGTCCACGCCGTAAACGGTGGGCACTAGGTGTGGGGGACATTCCACGTTCTCCGTGCCGAAGCTAACGCATTAAGTGCCCCGCCTGGGGAGTACGGCCGCAAGGCTAAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCGGCGGAGCATGCGGATTAATTCGATGCAACGCGAAGAACCTTACCTGGGTTTGACATACACCGGAAAGCTGCAGAGATGTAGCCCCCGCAAGGTCGGTGTACAGGTGGTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTCGTTCTATGTTGCCAGCACGTCATGGTGGGGACTCATAGGAGACTGCCGGGGTCAACTCGGAGGAAGGTGGGGATGACGTCAAGTCATCATGCCCCTTAAGTCCAGGGCTTCACGCATGCTACAATGGCCGGTACAAAGGGCTGCGATACCGCAAGGTGGAGCGAATCCCAAAAAGCCGGTCTCAGTTCGGATTGGGGTCTGCAACTCGACCCCATGAAGTCGGAGTCGCTAGTAATCGCAGATCAGCAACGCTGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCAAGTCATGAAAGTCGGTAACACCCGAAGCCGGTGGCCCAACCCTTGTGGAGGGAGCCGTCTAAGGTGGGACTGGCGATTAGGACTAAGTCGTAACAAGGTAGCCGTACCGGAAGGT\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Coriobacterineae</th>\n",
       "      <td>CGCTGGCGGCGTGCCTAACACATGCAAGTCGAACGAATAACCCGCCTTCGGGCGGTCATAGAGTGGCGAACGGGTGAGTAACACGTGACCAACCTTCCCCCCGCATGGGGATAACCGGGCGAAAGCCCGGCTAATACCCAATACTCCGGGCCCTCCGCATGGAGGGGCCGGGAAAGCCCAGGCGGCGGGGGATGGGGTCGCGGCCCATTAGGTAGACGGCGGGGTAACGGCCCACCGTGCCCGCGATGGGTAGCCGGACTGAGAGGTCGATCGGNCACATTGGGACTGAGATACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGNAATTTTNCGCNATGGGNNAAACCCTGACGCNGCNACGCCGCGTGCGGGATGAAGGCCCTAGGGTTGTAANCCNCTTTCNGCNGGGAAGAAACNTGACGGNACCTGCAGAAGAAGCTCCGNCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGAGCGAGCGTTATCCGGATTCATTGGGCGTAAAGCGCGCGTAGGCGGCTGNCCAANCGGGATCTCANATCCGGGGGCTCAACCTCCGGCCGGATCCCGAACTGNCCGGCTCGAGTTCGGTAGAGGAAGACGGAATTCCCAGTGTAGCGGTGNAATNCGCAGATATTGGGAAGAACACCGATGNCGAAGGCAGTCTTCTGGGCCNCGACTGACNCTGAGGTGCGAAAGCCGGGGGAGCGAACAGGATTAGATACCCTGGTAGTCCCGNCCGTAAACGATGGGCACTAGGTGTGGGGGAGCCTTTCCTCCGCGCCGCAGCTAACGCATTAAGTGCCCCGCCTGGGGAGTACGGCCGCAAGGCTAAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCAGCGGAGCATGTGGNTTAATTCGAAGCAACGCGAAGAACCTTACCAGGGCTTGACATGCGGGTGAAGCCGGGGAAACCCGGTGGCCGAGAGGAGCCCGCGCAGGTGGTGNATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCCTGCCCCATGTTGCCAGCATTAGGTTGGGGACTCATGGGGGACTGCCGGCGTCAAGCCGGAGGAAGGTGGGGACGACGTCAAGTCATCATGCCCCTTATGCCCTGGNCCGCACACGTGCTACAATGGCCGGTACAGAGGGCTGCCAGACCGCGAGGTCGAGCGAATCCCCCAAAGCCGGCCCCAGTTCGGACAGGAGGCTGCAACCCGCCTCCTCGAAGCCGGAGTTGCTAGTAATCGCGGATCAGCACGCCGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACACCACCCGAGTCGTCTGCACCCGAAGTCCCCGGCCCAACCTCGTGAGGGAGGGGCCGAAGGTGTGGAGGTGA\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Acinetobacter</th>\n",
       "      <td>CGGCAGGCTTACCATGCAAGTCGAGCGGGGAAGGTACTTGCTCCTACCTAGCGGCGGACGGGTGAGTAATGCTTAGGAATCTGCCTATTAGTGGGGGACAACATTCCGAAAGGAATGCTAATACCGCATACGTCCTACGGGAGAAAGCAGGGGACCTTCGGGCCTTGCGCTAATAGATGAGCCTAAGTCGGATTAGCTAGTTGGTGGGGTAAAGGCCTACCAAGGCGACGATCTGTAGCGGGTCTGAGAGGATGATCCGCCACACTGGGACTGAGACACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGGACAATGGGGGGAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTTTGGTTGTAAAGCACTTTAAGCGAGGAGGAGGCTACTAGTATTAATACTACTGGATAGTGGACGTTACTCGCAGAATAAGCACCGGCTAACTCTGTGCCAGCAGCCGCGGTAATACAGAGGGTGCGAGCGTTAATCGGATTTACTGGGCGTAAAGCGTGCGTAGGCGGCTGATTAAGTCGGATGTGAAATCCCTGAGCTTAACTTAGGAATTGCATTCGATACTGGTCAGCTAGAGTATGGGAGAGGATGGTAGAATTCCAGGTGTAGCGGTGAAATGCGTAGAGATCTGGAGGAATACCGATGGCGAAGGCAGCCATCTGGCCTAATACTGACGCTGAGGTACGAAAGCATGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCATGCCGTAAACGATGTCTACTAGCCGTTGGGGCCTTTGAGGCTTTAGTGGCGCAGCTAACGCGATAAGTAGACCGCCTGGGGAGTACGGTCGCAAGACTAAAACTCAAATGAATTGACGGGGGCCCGCACAAGCGGTGGAGCATGTGGTTTAATTCGATGCAACGCGAAGAACCTTACCTGGTCTTGACATAGTAAGAACTTTCCAGAGATGGATTGGTGCCTTCGGGAACTTACATACAGGTGCTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTTTTCCTTATTTGCCAGCGGGTTAAGCCGGGAACTTTAAGGATACTGCCAGTGACAAACTGGAGGAAGGCGGGGACGACGTCAAGTCATCATGGCCCTTACGACCAGGGCTACACACGTGCTACAATGGTCGGTACAAAGGGTTGCTACCTAGCGATAGGATGCTAATCTCAAAAAGCCGATCGTAGTCCGGATTGGAGTCTGCAACTCGACTCCATGAAGTCGGAATCGCTAGTAATCGCGGATCAGAATGCCGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACACCATGGGAGTTTG\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Corynebacterineae</th>\n",
       "      <td>CTGGCGGCGTGCTTAACACATGCAAGTCGAACGGAAAGGTCTCTTCGGAGATACTCGAGTGGCGAACGGGTGAGTAACACGTGGGCGATCTGCCCTGCACTTCGGGATAAGCCTGGGAAACTGGGTCTAATACCGGATAGGACCACGGGATTCATGTCCTGTGGTGGAAAGCTTTTGCGGTGTGGGATGGGCCCGCGGCCTATCAGCTTGTTGGTGGGGTAACGGCCTACCAAGGCGACGACGGGTAGCCGGCCTGAGAGGGTGTCCGGCCACACTGGGACTGAGATACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGCACAATGGGCGCAAGCCTGATGCAGCGACGCCGCGTGGGGGATGACGGCCTTCGGGTTGTAAACCTCTTTCACCATCGACGAAGGTTCGGGTTTTCTCGGATTGACGGTAGGTGGAGAAGAAGCACCGGCCAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTGTCCGGAATTACTGGGCGTAAAGAGCTCGTAGGTGGTTTGTCGCGTTGTTCGTGAAATCTCACGGCTTAACTGTGAGCGTGCGGGCGATACGGGCAGACTAGAGTACTGCAGGGGAGACTGGAATTCCTGGTGTAGCGGTGGAATGCGCAGATATCAGGAGGAACACCGGTGGCGAAGGCGGGTCTCTGGGCAGTAACTGACGCTGAGGAGCGAAAGCGTGGGGAGCGAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGGTGGGTACTAGGTGTGGGTTTCCTTCCTTGGGATCCGTGCCGTAGCTAACGCATTAAGTACCCCGCCTGGGGAGTACGGCCGCAAGGCTAAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCGGCGGAGCATGTGGATTAATTCGATGCAACGCGAAGAACCTTACCTGGGTTTGACATGCACAGGACGCGTCTAGAGATAGGCGTTCCCTTGTGGCCTGTGTGCAGGTGGTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTTGTCTCATGTTGCCAGCACGTAATGGTGGGGACTCGTGAGAGACTGCCGGGGTCAACTCGGAGGAAGGTGGGGATGACGTCAAGTCATCATGCCCCTTATGTCCAGGGCTTCACACATGCTACAATGGCCGGTGCAAAGGGCTGCGATGCCGCGAGGTTAAGCGAATCCTTTAACGCCGGTCTCAGTTCGGATCGGGGTCTGCAACTCGACCCCGTGAAGTCGGAGTCGCTAGTAATCGCAGATCAGCAACGCTGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACGTCATGAAAGTCGGTAACACCCGAAGCCAGTGGCCTAACCCTTTGGGAGGGAGCTGTCGAAGGTGGGATCGGCGATTGGGACGAAGTCGTAACAAGGTAGCCGTACCGGAAGG\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0\n",
       "g__Paenibacillus                   TCGAGGGGAGCTAGAGTTTTATTAATCCCGGAAATCCACTGANACTTTAGCGGCGGACGGGTGAGTAACACGTAGGTAACCTGCCCATAAGACCGGGATAACATTCGGAAACGGATGCTAATACCCGGATACGCGATTCTCTCGCATGAGAGAAGTTGGGAAAGGCGGAGCAATCTGTCACTTATGGATGGACATGCGGCGCATTAGCTAGTTGGTGAGGTAACGGCTCACCAAGGAGATGATGTGTAGCCCACGTGACAGGGTGATCGGCCACACTGGGNCAGAGACACGGCCCAGACTCTGACGGGAGGCAGCAGTAGGGAATCTTCCGCAATGGAAGAAAATCTGACGGAGCAACGCCGCCTGAGTGATGAAGGTTTTCGGATCGAAAAGCTCTGTTGCCAGGGAAGAACGCTAGAGAGAGTAACTGCTCTTTAGGTGACGGTACCTGAGAAGAAAGCCCCGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGGGCAAGCGTTGTCCGGAATTATTGGGCGTAAAGCGCGCGCAGGCGGTTGATTAAGTCTGGTGTTTAAGGCTATGGCTCAACCATAGTTCGCACTGGAAACTGGTTGAATTGAGTGCAGAAGAGGAAAGTGGAATTCCACGTGTAGCGGTGAAATGCGTAGAGATGTGGAGGAACACCAGTGGCGAAGGCGACTTTCTGGGCGGTAACTGACGCTGAGGCACGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGAATGCTAGGTGTTAGGGGTTTCGATACCCTTGGTGCCGAAGTTAACACATTAAGCATTCCGCCTGGGGAGTACGGTCGCAAGACTGAAACTCAAAGGAATTGACGGGGACCCGCACAAGCAGTGGAGTATGTGGTTTAATTCGAAGCAACGCGAAGAACCTTACCAGGTCTTGACATGCCTCTGACCGCTCTAGAGATAGAGCTTCTCTTCGGAGCAGGGGACACAGGTGGTGCATGGTTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCTGCAACGAGCGCAACCCCTAATGTTAGTTGCCAGCAGGTAGAGCTGGGCACTCTAACGTGACTGCCGGTGACAAACCGGAGGAAGGTGGGGATGACGTCAAATCATCATGCCCCTTATGACCTGGGCTACACACGTACTACAATGGCCAGTACAACGGGAAGCGAAGTCGCGAGATGGAGCCAATCCTCAAAAGCTGGTCTCAGTTCGGATTGCAGGCTGCAACTCGCCTGCATGAAGTCGGAATTGCTAGTAATCGCGGATCAGCATGCCGCGGTGAATACGTTCCCGGGTCTTGTACACACCGCCCGTCACACCACGAGAGTTTACAACACCCGAAGCCGGTGGGGTAACCCGCAAGGGAGCCAGCCGTCGAAGGTGGGGTAGATGATTGGGGTGAAGTCGTAT\\n\n",
       "g__Propionibacterineae    AGGACGAACGCTGGCGGCGTGCTTAACACATGCAAGTCGAACGGTAAGGCCTTTCGGGGTCATACGAGTGGCGAACGGGTGAGTAACACGTGAGCAACCTGCCCTTGACTTCGGAATACCAGCTGGAAACAGCTGCTAATACCGGATATGACCCTGGTCCTCCTGGACTGGGGTGGAAAGCTCCGGCGGTCAGGGATGGGCTCGCGGCCTATCAGCTTGTTGGTGAGGTAATGGCTCACCAAGGCTTCGACGGGTAGCCGGCCTGAGAGGGCGACCGGCCACACTGGGACTGAGATACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGCACAATGGGCGCAAGCCTGATGCAGCAACGCCGCGTGCGGGATGACGGCCTTCGGGTTGTAAACCGCTTTCAGTAGGGACGAAGCCACAAGTGACGGTACCTACAGAAGAAGGACCGGCTAACTACGTGCCAGCAGCCGCGGTGATACGTAGGGTCCGAGCGTTGTCCGGAATTATTGGGCGTAAAGGGCTTGTAGGCGGTCCGTCGCGTCAGGAGTGAAAACTCGGGGCTTAACCCCGAGCCTGCTTTTGATACGGGCGGACTAGAGGGATGCAGGGGAGAACGGAATTCCTGGTGGAGCGGTGGAATGCGCAGATATCAGGAGGAACACCGGTGGCGAAGGCGGTTCTCTGGGCATCACCTGACGCTGAGAAGCGAAAGCGTGGGGAGCAAACAGGCTTAGATACCCTGGTAGTCCACGCCGTAAACGGTGGGCACTAGGTGTGGGGGACATTCCACGTTCTCCGTGCCGAAGCTAACGCATTAAGTGCCCCGCCTGGGGAGTACGGCCGCAAGGCTAAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCGGCGGAGCATGCGGATTAATTCGATGCAACGCGAAGAACCTTACCTGGGTTTGACATACACCGGAAAGCTGCAGAGATGTAGCCCCCGCAAGGTCGGTGTACAGGTGGTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTCGTTCTATGTTGCCAGCACGTCATGGTGGGGACTCATAGGAGACTGCCGGGGTCAACTCGGAGGAAGGTGGGGATGACGTCAAGTCATCATGCCCCTTAAGTCCAGGGCTTCACGCATGCTACAATGGCCGGTACAAAGGGCTGCGATACCGCAAGGTGGAGCGAATCCCAAAAAGCCGGTCTCAGTTCGGATTGGGGTCTGCAACTCGACCCCATGAAGTCGGAGTCGCTAGTAATCGCAGATCAGCAACGCTGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCAAGTCATGAAAGTCGGTAACACCCGAAGCCGGTGGCCCAACCCTTGTGGAGGGAGCCGTCTAAGGTGGGACTGGCGATTAGGACTAAGTCGTAACAAGGTAGCCGTACCGGAAGGT\\n\n",
       "g__Coriobacterineae                                                                   CGCTGGCGGCGTGCCTAACACATGCAAGTCGAACGAATAACCCGCCTTCGGGCGGTCATAGAGTGGCGAACGGGTGAGTAACACGTGACCAACCTTCCCCCCGCATGGGGATAACCGGGCGAAAGCCCGGCTAATACCCAATACTCCGGGCCCTCCGCATGGAGGGGCCGGGAAAGCCCAGGCGGCGGGGGATGGGGTCGCGGCCCATTAGGTAGACGGCGGGGTAACGGCCCACCGTGCCCGCGATGGGTAGCCGGACTGAGAGGTCGATCGGNCACATTGGGACTGAGATACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGNAATTTTNCGCNATGGGNNAAACCCTGACGCNGCNACGCCGCGTGCGGGATGAAGGCCCTAGGGTTGTAANCCNCTTTCNGCNGGGAAGAAACNTGACGGNACCTGCAGAAGAAGCTCCGNCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGAGCGAGCGTTATCCGGATTCATTGGGCGTAAAGCGCGCGTAGGCGGCTGNCCAANCGGGATCTCANATCCGGGGGCTCAACCTCCGGCCGGATCCCGAACTGNCCGGCTCGAGTTCGGTAGAGGAAGACGGAATTCCCAGTGTAGCGGTGNAATNCGCAGATATTGGGAAGAACACCGATGNCGAAGGCAGTCTTCTGGGCCNCGACTGACNCTGAGGTGCGAAAGCCGGGGGAGCGAACAGGATTAGATACCCTGGTAGTCCCGNCCGTAAACGATGGGCACTAGGTGTGGGGGAGCCTTTCCTCCGCGCCGCAGCTAACGCATTAAGTGCCCCGCCTGGGGAGTACGGCCGCAAGGCTAAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCAGCGGAGCATGTGGNTTAATTCGAAGCAACGCGAAGAACCTTACCAGGGCTTGACATGCGGGTGAAGCCGGGGAAACCCGGTGGCCGAGAGGAGCCCGCGCAGGTGGTGNATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCCTGCCCCATGTTGCCAGCATTAGGTTGGGGACTCATGGGGGACTGCCGGCGTCAAGCCGGAGGAAGGTGGGGACGACGTCAAGTCATCATGCCCCTTATGCCCTGGNCCGCACACGTGCTACAATGGCCGGTACAGAGGGCTGCCAGACCGCGAGGTCGAGCGAATCCCCCAAAGCCGGCCCCAGTTCGGACAGGAGGCTGCAACCCGCCTCCTCGAAGCCGGAGTTGCTAGTAATCGCGGATCAGCACGCCGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACACCACCCGAGTCGTCTGCACCCGAAGTCCCCGGCCCAACCTCGTGAGGGAGGGGCCGAAGGTGTGGAGGTGA\\n\n",
       "g__Acinetobacter                                                                                                             CGGCAGGCTTACCATGCAAGTCGAGCGGGGAAGGTACTTGCTCCTACCTAGCGGCGGACGGGTGAGTAATGCTTAGGAATCTGCCTATTAGTGGGGGACAACATTCCGAAAGGAATGCTAATACCGCATACGTCCTACGGGAGAAAGCAGGGGACCTTCGGGCCTTGCGCTAATAGATGAGCCTAAGTCGGATTAGCTAGTTGGTGGGGTAAAGGCCTACCAAGGCGACGATCTGTAGCGGGTCTGAGAGGATGATCCGCCACACTGGGACTGAGACACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGGACAATGGGGGGAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTTTGGTTGTAAAGCACTTTAAGCGAGGAGGAGGCTACTAGTATTAATACTACTGGATAGTGGACGTTACTCGCAGAATAAGCACCGGCTAACTCTGTGCCAGCAGCCGCGGTAATACAGAGGGTGCGAGCGTTAATCGGATTTACTGGGCGTAAAGCGTGCGTAGGCGGCTGATTAAGTCGGATGTGAAATCCCTGAGCTTAACTTAGGAATTGCATTCGATACTGGTCAGCTAGAGTATGGGAGAGGATGGTAGAATTCCAGGTGTAGCGGTGAAATGCGTAGAGATCTGGAGGAATACCGATGGCGAAGGCAGCCATCTGGCCTAATACTGACGCTGAGGTACGAAAGCATGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCATGCCGTAAACGATGTCTACTAGCCGTTGGGGCCTTTGAGGCTTTAGTGGCGCAGCTAACGCGATAAGTAGACCGCCTGGGGAGTACGGTCGCAAGACTAAAACTCAAATGAATTGACGGGGGCCCGCACAAGCGGTGGAGCATGTGGTTTAATTCGATGCAACGCGAAGAACCTTACCTGGTCTTGACATAGTAAGAACTTTCCAGAGATGGATTGGTGCCTTCGGGAACTTACATACAGGTGCTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTTTTCCTTATTTGCCAGCGGGTTAAGCCGGGAACTTTAAGGATACTGCCAGTGACAAACTGGAGGAAGGCGGGGACGACGTCAAGTCATCATGGCCCTTACGACCAGGGCTACACACGTGCTACAATGGTCGGTACAAAGGGTTGCTACCTAGCGATAGGATGCTAATCTCAAAAAGCCGATCGTAGTCCGGATTGGAGTCTGCAACTCGACTCCATGAAGTCGGAATCGCTAGTAATCGCGGATCAGAATGCCGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACACCATGGGAGTTTG\\n\n",
       "g__Corynebacterineae    CTGGCGGCGTGCTTAACACATGCAAGTCGAACGGAAAGGTCTCTTCGGAGATACTCGAGTGGCGAACGGGTGAGTAACACGTGGGCGATCTGCCCTGCACTTCGGGATAAGCCTGGGAAACTGGGTCTAATACCGGATAGGACCACGGGATTCATGTCCTGTGGTGGAAAGCTTTTGCGGTGTGGGATGGGCCCGCGGCCTATCAGCTTGTTGGTGGGGTAACGGCCTACCAAGGCGACGACGGGTAGCCGGCCTGAGAGGGTGTCCGGCCACACTGGGACTGAGATACGGCCCAGACTCCTACGGGAGGCAGCAGTGGGGAATATTGCACAATGGGCGCAAGCCTGATGCAGCGACGCCGCGTGGGGGATGACGGCCTTCGGGTTGTAAACCTCTTTCACCATCGACGAAGGTTCGGGTTTTCTCGGATTGACGGTAGGTGGAGAAGAAGCACCGGCCAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGTGCGAGCGTTGTCCGGAATTACTGGGCGTAAAGAGCTCGTAGGTGGTTTGTCGCGTTGTTCGTGAAATCTCACGGCTTAACTGTGAGCGTGCGGGCGATACGGGCAGACTAGAGTACTGCAGGGGAGACTGGAATTCCTGGTGTAGCGGTGGAATGCGCAGATATCAGGAGGAACACCGGTGGCGAAGGCGGGTCTCTGGGCAGTAACTGACGCTGAGGAGCGAAAGCGTGGGGAGCGAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGGTGGGTACTAGGTGTGGGTTTCCTTCCTTGGGATCCGTGCCGTAGCTAACGCATTAAGTACCCCGCCTGGGGAGTACGGCCGCAAGGCTAAAACTCAAAGGAATTGACGGGGGCCCGCACAAGCGGCGGAGCATGTGGATTAATTCGATGCAACGCGAAGAACCTTACCTGGGTTTGACATGCACAGGACGCGTCTAGAGATAGGCGTTCCCTTGTGGCCTGTGTGCAGGTGGTGCATGGCTGTCGTCAGCTCGTGTCGTGAGATGTTGGGTTAAGTCCCGCAACGAGCGCAACCCTTGTCTCATGTTGCCAGCACGTAATGGTGGGGACTCGTGAGAGACTGCCGGGGTCAACTCGGAGGAAGGTGGGGATGACGTCAAGTCATCATGCCCCTTATGTCCAGGGCTTCACACATGCTACAATGGCCGGTGCAAAGGGCTGCGATGCCGCGAGGTTAAGCGAATCCTTTAACGCCGGTCTCAGTTCGGATCGGGGTCTGCAACTCGACCCCGTGAAGTCGGAGTCGCTAGTAATCGCAGATCAGCAACGCTGCGGTGAATACGTTCCCGGGCCTTGTACACACCGCCCGTCACGTCATGAAAGTCGGTAACACCCGAAGCCAGTGGCCTAACCCTTTGGGAGGGAGCTGTCGAAGGTGGGATCGGCGATTGGGACGAAGTCGTAACAAGGTAGCCGTACCGGAAGG\\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame(X, y).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinhashVectorizer Compared with TfidfVectorizer\n",
    "* Vectorizing the RDP file using TfidfVectorizer stores 6,940,414 elements and takes ~8.79 seconds.\n",
    "* Vectorizing the RDP file using MinhashVectorizer stores 1,196,500 elements and takes ~5.69 seconds at a signature length of 250.\n",
    "* Vectorizing the RDP file using MinhashVectorizer stores 4,784,594 elements and takes ~11.1 seconds at a signature length of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.79 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x807185 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6940414 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x143336 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1196500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from StrandPy import MinhashVectorizer\n",
    "mhv = MinhashVectorizer(signature_length=250, analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_mhv = mhv.fit_transform(X)\n",
    "X_mhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x568032 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4784594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv2 = MinhashVectorizer(signature_length=1000, analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_mhv2 = mhv2.fit_transform(X)\n",
    "X_mhv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analisys\n",
    "* Typically feature names become obfuscated by thier respective hash values during minhashing.\n",
    "* However, the MinhashVectorizer() is able to retain feature names during the minhashing process.  \n",
    "* This means that the resulting sparse matrix contains a list of all the unique feature names selected during minhashing and which feature names were selected for a particular document / row's minhash signature. \n",
    "* This is critical since we can use feature names to perform feature importance analisys for many classifiers and also feature ranking algorithms such as recursive feature elimination. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below, the RDP test dataset is minhashed using a signature_length of 50 features\n",
    "* We can see that there are 4786 (rows) x 29733 (columns) and 239,300 data values stored. \n",
    "* Each row starts out as a gene sequence that is broken into k-mers of length 20.\n",
    "* All k-mers are hashed and sorted, including duplicates. \n",
    "* Since a signature length of 50 is used, each row contains the first 50 non-zero features producing minimum hash values in a given document.\n",
    "* There are also 28,350 unique features observed in the document corpora ( all documents processed furing fit() ).\n",
    "* Only 50 of these 28,350 unique features will have a value > 0 for any given document in the document corpora after minhashing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x29733 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 239300 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv50 = MinhashVectorizer(signature_length=50, analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_mhv50 = mhv50.fit_transform(X)\n",
    "X_mhv50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Feature Names after Fitting\n",
    "* We can see that MinhashVectorizer() has a total of 28,350 features.\n",
    "* Inspecting the first 10 features, we can also see that these are k-mers of length 20, rather than hash codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Feature Names:  29733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aaaaaaccgttctcagttcg',\n",
       " 'aaaaacaggtcccagttcgg',\n",
       " 'aaaaacccagtcccagttcg',\n",
       " 'aaaaaccgcatggtttttgt',\n",
       " 'aaaaacctctctcagttcgg',\n",
       " 'aaaaacgtgcccantggant',\n",
       " 'aaaaagccatctcagttcgg',\n",
       " 'aaaaagccgtcccagtccgg',\n",
       " 'aaaaagtcagtctcagtccg',\n",
       " 'aaaaagtcgaggaggaaatg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total Feature Names: ', len(mhv50.get_feature_names()))\n",
    "mhv50.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at One Document:\n",
    "**After minhashing / fitting, we can see that the first document contains only 50 non-zero values / elements:**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x29733 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mhv50[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is easy to inspect which features / columns were selected in the minhash signature for row 0:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]),\n",
       " array([ 2083, 16967, 18613, 22961,   153,  1913, 15332, 21373,  7380,\n",
       "         2218, 17494, 19082, 29470, 15041, 10563,   823, 21030, 15329,\n",
       "        26364, 13281, 22615,  8860, 26443,  3380, 22843,  5376, 12769,\n",
       "        23940, 23179,  2783, 26228,   491,  5076,  9169, 26138, 24974,\n",
       "        21077,  4041,  1542,  6246, 17844, 21782,  8412, 21179,  3324,\n",
       "         3162, 22374,  5707, 27852,  3493]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mhv50[0,:].nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also see the feature names (individual k-mers in this case) for each feature in the minhash signature:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aattgacggggacccgcaca',\n",
       " 'gcagtggagtatgtggttta',\n",
       " 'ggaaacggatgctaataccc',\n",
       " 'gttcggattgcaggctgcaa',\n",
       " 'aaacggatgctaatacccgg',\n",
       " 'aatcgcggatcagcatgccg',\n",
       " 'gacggggacccgcacaagca',\n",
       " 'ggttttcggatcgaaaagct',\n",
       " 'attgacggggacccgcacaa',\n",
       " 'acaccacgagagtttacaac',\n",
       " 'gcctctgaccgctctagaga',\n",
       " 'ggagtacggtcgcaagactg',\n",
       " 'tttcggatcgaaaagctctg',\n",
       " 'gaattgagtgcagaagagga',\n",
       " 'cctggggagtacggtcgcaa',\n",
       " 'aacgggaagcgaagtcgcga',\n",
       " 'ggtcttgacatgcctctgac',\n",
       " 'gacgggaggcagcagtaggg',\n",
       " 'tgaatgctaggtgttagggg',\n",
       " 'ctctgacgggaggcagcagt',\n",
       " 'gtggcgaaggcgactttctg',\n",
       " 'catgaagtcggaattgctag',\n",
       " 'tgaccgctctagagatagag',\n",
       " 'acgtaggtaacctgcccata',\n",
       " 'gttaacacattaagcattcc',\n",
       " 'aggtgttaggggtttcgata',\n",
       " 'ctaatacccggatacgcgat',\n",
       " 'tacaatggccagtacaacgg',\n",
       " 'gtttcgatacccttggtgcc',\n",
       " 'accggaggaaggtggggatg',\n",
       " 'tctttaggtgacggtacctg',\n",
       " 'aacaccagtggcgaaggcga',\n",
       " 'aggcggttgattaagtctgg',\n",
       " 'ccaatcctcaaaagctggtc',\n",
       " 'tctgtcacttatggatggac',\n",
       " 'tcaaatcatcatgcccctta',\n",
       " 'ggtgatcggccacactgggn',\n",
       " 'agagatagagcttctcttcg',\n",
       " 'aagtccctgcaacgagcgca',\n",
       " 'atagttcgcactggaaactg',\n",
       " 'gcggagcaatctgtcactta',\n",
       " 'gtagggggcaagcgttgtcc',\n",
       " 'cagcaggtagagctgggcac',\n",
       " 'ggtggggatgacgtcaaatc',\n",
       " 'acggtacctgagaagaaagc',\n",
       " 'acgccgcctgagtgatgaag',\n",
       " 'gtgaggtaacggctcaccaa',\n",
       " 'agtggcgaaggcgactttct',\n",
       " 'tggttgaattgagtgcagaa',\n",
       " 'actacgtgccagcagccgcg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all of the feature names\n",
    "f_names = mhv50.get_feature_names()\n",
    "# Use list comprehension to look up feature names for each \n",
    "# non-zero column in the first document's minhash signature \n",
    "[f_names[c_idx] for c_idx in X_mhv50[0,:].nonzero()[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, we can get the column index of the first feature, if needed:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2083"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhv50._tfidf.vocabulary_['aattgacggggacccgcaca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Several Classifiers Using Sklearn's Stratified Cross Validation \n",
    "**The MinhashVectorizer is an Sklearn compliant Transformer.  This means that it can easily work \"out of the box\" with other Sklearn tools such as cross validation, grid search, and pipelines.  In the following example, we:**\n",
    "* Use the minhash vectorized dataset to build models Strand and five other Sklearn classifiers.   \n",
    "* Perform stratified 10-fold cross validation using Sklearn's StratifiedKFold cross validator.\n",
    "* Run cross validation in Parallel using Sklearn's cross_validate function running on all cores. \n",
    "* Use 90% of the data for training  \n",
    "* Use 10% of the data for testing\n",
    "* Score each classifier's cross validation using the accuracy metric.  There are 18 different classification metrics we could have chosen to use with cross_validate here.  In addition, we could have created our own custom scorer to use as well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10,shuffle=True, random_state=42)\n",
    "\n",
    "def stratified_cross_validate(model, X, y, cv=cv):\n",
    "    start = time.time()\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "    elapsed_time = (time.time() - start) \n",
    "    print ('Fold Scores:')\n",
    "    print(' ')\n",
    "    print(cv_results['test_score'])\n",
    "    print(' ')\n",
    "    print('Mean Accuracy: ', cv_results['test_score'].mean())\n",
    "    print('Mean Fit Time: ', cv_results['fit_time'].mean())\n",
    "    print('Mean Score Time: ', cv_results['score_time'].mean())\n",
    "    print('CV Time: ', elapsed_time)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Classifiers\n",
    "**I have selected several Sklearn classifiers that will support multi-class, sparse datasets and run in a reasonable period of time including:** \n",
    "* MultinomialNB()\n",
    "* SGDClassifier() using linear SVM\n",
    "* RandomForestClassifier()\n",
    "* LinearSVC()\n",
    "* LogisticRegression()\n",
    "\n",
    "**These classifiers are compared to the StrandPy Classifiers including:**\n",
    "* StrandSliceClassifier\n",
    "* StrandGiniClassifier\n",
    "* StrandBinaryClassifier\n",
    "\n",
    "**I compare all classifers using RDP Test dataset and k-mers of length 20 using:**\n",
    "* TfidfVectorizer\n",
    "* MinhashVectorizer @ a minhash signature length of 50\n",
    "* MinhashVectorizer @ a minhash signature length of 100\n",
    "* MinhashVectorizer @ a minhash signature length of 250\n",
    "* MinhashVectorizer @ a minhash signature length of 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn Classifiers \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# StrandPy Classifiers\n",
    "from StrandPy import StrandSliceClassifier\n",
    "from StrandPy import StrandGiniClassifier\n",
    "from StrandPy import StrandBinaryClassifier\n",
    "\n",
    "\n",
    "models = [\n",
    "    StrandSliceClassifier(), \n",
    "    StrandGiniClassifier(),\n",
    "    StrandBinaryClassifier(),\n",
    "    MultinomialNB(),\n",
    "    SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None),\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=42),\n",
    "    LinearSVC(random_state=42),\n",
    "    LogisticRegression(random_state=42)\n",
    "]\n",
    "\n",
    "model_names = ['StrandSliceClassifier','StrandGiniClassifier','StrandBinaryClassifier','MultinomialNB','SGDClassifier',\n",
    "               'RandomForestClassifier','LinearSVC','LogisticRegression']\n",
    "\n",
    "\n",
    "def test_models(X, y):\n",
    "    for model, model_name in zip(models,model_names):\n",
    "        print(model_name)\n",
    "        print('--------------------------------')\n",
    "        stratified_cross_validate(model,X,y)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using TfidfVectorizer\n",
    "* All classifiers are tested against the RDP dataset using Sklearn's TfidfVectorizer().\n",
    "* The RDP dataset is vectorized into k-mers of length 20 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied.\n",
    "* Classifiers tested include the StrandPy's Slice, Gini and Binary Classifiers.\n",
    "* These classifiers are optimized for classifying Minhash and Strand Vectorized Data.\n",
    "* Note the fit, score, and Cv times below which reflect total times for various aspects of these stratified, 10-fold cross validations for each individual model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x807185 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6940414 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99164927 0.99582463 0.99582463 0.99582463 0.99791232\n",
      " 0.9958159  0.9958159  0.99372385 1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9956128091124292\n",
      "Mean Fit Time:  0.8757014989852905\n",
      "Mean Score Time:  0.7918919801712037\n",
      "CV Time:  5.1037373542785645\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.98538622 0.98329854 0.98956159 0.98956159 0.9874739  0.98956159\n",
      " 0.99790795 0.9832636  0.9832636  0.99372385]\n",
      " \n",
      "Mean Accuracy:  0.9883002419615481\n",
      "Mean Fit Time:  14.006837224960327\n",
      "Mean Score Time:  10.388650584220887\n",
      "CV Time:  41.83902645111084\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99164927 0.99582463 0.99582463 0.99582463 0.99791232\n",
      " 0.9958159  0.9958159  0.99372385 1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9956128091124292\n",
      "Mean Fit Time:  14.352577137947083\n",
      "Mean Score Time:  7.146070289611816\n",
      "CV Time:  35.8212411403656\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.97912317 0.97703549 0.98121086 0.98329854 0.97912317 0.98121086\n",
      " 0.98953975 0.98117155 0.9790795  0.9748954 ]\n",
      " \n",
      "Mean Accuracy:  0.980568828015129\n",
      "Mean Fit Time:  7.471017217636108\n",
      "Mean Score Time:  0.9655558347702027\n",
      "CV Time:  13.89467978477478\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99582463 0.99373695 0.99582463 0.99582463 0.99582463\n",
      " 0.99372385 0.9832636  0.9916318  0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9937299639241447\n",
      "Mean Fit Time:  45.79448518753052\n",
      "Mean Score Time:  0.9306366920471192\n",
      "CV Time:  69.81998705863953\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.52818372 0.5302714  0.53235908 0.56158664 0.565762   0.55114823\n",
      " 0.541841   0.53974895 0.51464435 0.541841  ]\n",
      " \n",
      "Mean Accuracy:  0.5407386378525694\n",
      "Mean Fit Time:  6.129516911506653\n",
      "Mean Score Time:  11.711891627311706\n",
      "CV Time:  28.546300649642944\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99373695 0.99582463 0.99582463 0.99791232 0.99582463\n",
      " 0.9958159  0.9958159  0.99372385 1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9956128091124292\n",
      "Mean Fit Time:  472.42963695526123\n",
      "Mean Score Time:  0.2812058687210083\n",
      "CV Time:  674.3709959983826\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99582463        nan        nan 0.99791232        nan\n",
      "        nan        nan        nan 1.        ]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  3476.6548734664916\n",
      "Mean Score Time:  2.592789649963379\n",
      "CV Time:  10750.012444257736\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using MinhashVectorizer @ 50\n",
    "* All classifiers are tested against the MinhashVectorizer() with a signature_length == 50\n",
    "* The RDP dataset is vectorized into k-mers of length 20 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied.\n",
    "* Classifiers tested include the Strand Binary and NonBinary Classifiers.\n",
    "* These classifiers are optimized for classifying Minhash and Strand Vectorized Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.6 s\n",
      "Parser   : 299 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x29733 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 239300 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv50 = MinhashVectorizer(signature_length=50, analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_mhv50 = mhv50.fit_transform(X)\n",
    "X_mhv50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99164927 0.99164927 0.99582463 0.98956159 0.99582463\n",
      " 0.99372385 0.98953975 0.98953975 0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9926869960954219\n",
      "Mean Fit Time:  0.3414654016494751\n",
      "Mean Score Time:  0.1367797374725342\n",
      "CV Time:  7.121617794036865\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.97912317 0.97703549 0.97912317 0.98329854 0.97703549 0.97912317\n",
      " 0.99372385 0.97698745 0.98535565 0.9707113 ]\n",
      " \n",
      "Mean Accuracy:  0.9801517282343795\n",
      "Mean Fit Time:  0.42863514423370364\n",
      "Mean Score Time:  0.27215626239776614\n",
      "CV Time:  4.07963490486145\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99164927 0.99164927 0.99582463 0.98956159 0.99582463\n",
      " 0.99372385 0.98953975 0.98953975 0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9926869960954219\n",
      "Mean Fit Time:  0.39969358444213865\n",
      "Mean Score Time:  0.2156224727630615\n",
      "CV Time:  1.060166835784912\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.97286013 0.97703549 0.97494781 0.97286013 0.97494781 0.97703549\n",
      " 0.97698745 0.97280335 0.9748954  0.97280335]\n",
      " \n",
      "Mean Accuracy:  0.974717638734812\n",
      "Mean Fit Time:  0.21438221931457518\n",
      "Mean Score Time:  0.02605128288269043\n",
      "CV Time:  0.4404945373535156\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.98956159 0.99582463 0.99373695 0.99582463 0.99164927 0.99791232\n",
      " 0.9958159  0.98953975 0.9958159  0.9958159 ]\n",
      " \n",
      "Mean Accuracy:  0.994149684227077\n",
      "Mean Fit Time:  0.8070416212081909\n",
      "Mean Score Time:  0.024996328353881835\n",
      "CV Time:  1.4563393592834473\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.50104384 0.43841336 0.46346555 0.48643006 0.46137787 0.49060543\n",
      " 0.47280335 0.46443515 0.5041841  0.44560669]\n",
      " \n",
      "Mean Accuracy:  0.47283654056131585\n",
      "Mean Fit Time:  1.1273291110992432\n",
      "Mean Score Time:  0.10156431198120117\n",
      "CV Time:  2.6049280166625977\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99582463 0.99582463 0.99373695 0.99582463 0.99582463\n",
      " 0.9958159  0.99372385 0.9958159  0.9958159 ]\n",
      " \n",
      "Mean Accuracy:  0.9949856308033649\n",
      "Mean Fit Time:  3.2440505266189574\n",
      "Mean Score Time:  0.004686522483825684\n",
      "CV Time:  5.117568731307983\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99582463 0.99373695 0.99582463 0.99582463 0.99791232\n",
      " 0.9958159  0.9916318  0.9958159  0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9951943990705882\n",
      "Mean Fit Time:  133.73042414188384\n",
      "Mean Score Time:  0.03594527244567871\n",
      "CV Time:  199.85842370986938\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_mhv50, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using MinhashVectorizer @ 100\n",
    "* All classifiers are tested against the MinhashVectorizer() with a signature_length == 100\n",
    "* The RDP dataset is vectorized into k-mers of length 20 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied.\n",
    "* Classifiers tested include the Strand Binary and NonBinary Classifiers.\n",
    "* These classifiers are optimized for classifying Minhash and Strand Vectorized Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x57411 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 478600 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv100 = MinhashVectorizer(signature_length=100, analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_mhv100 = mhv100.fit_transform(X)\n",
    "X_mhv100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99373695 0.99164927 0.99373695 0.99164927 0.99791232\n",
      " 0.9958159  0.9958159  0.9916318  0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9941505577344711\n",
      "Mean Fit Time:  0.14437952041625976\n",
      "Mean Score Time:  0.08788890838623047\n",
      "CV Time:  0.41681599617004395\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.97912317 0.97703549 0.98329854 0.9874739  0.98329854 0.98329854\n",
      " 0.99372385 0.9832636  0.98117155 0.9790795 ]\n",
      " \n",
      "Mean Accuracy:  0.9830766677439924\n",
      "Mean Fit Time:  0.950512146949768\n",
      "Mean Score Time:  0.6677090644836425\n",
      "CV Time:  2.8606722354888916\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99373695 0.99164927 0.99373695 0.99373695 0.99791232\n",
      " 0.9958159  0.9958159  0.9916318  0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9943593260016946\n",
      "Mean Fit Time:  0.8671156167984009\n",
      "Mean Score Time:  0.43750581741333006\n",
      "CV Time:  2.1758153438568115\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.97703549 0.97912317 0.97494781 0.98121086 0.97703549 0.97912317\n",
      " 0.98535565 0.97698745 0.97698745 0.97280335]\n",
      " \n",
      "Mean Accuracy:  0.9780609882862658\n",
      "Mean Fit Time:  0.4121394157409668\n",
      "Mean Score Time:  0.05311474800109863\n",
      "CV Time:  0.8003320693969727\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99373695 0.99582463 0.99582463 0.99582463 0.99582463\n",
      " 0.9958159  0.99372385 0.99372385 0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9951943990705882\n",
      "Mean Fit Time:  1.3018681764602662\n",
      "Mean Score Time:  0.04845328330993652\n",
      "CV Time:  2.293529987335205\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.50313152 0.48434238 0.52400835 0.52818372 0.48434238 0.46555324\n",
      " 0.53974895 0.4623431  0.5251046  0.47280335]\n",
      " \n",
      "Mean Accuracy:  0.4989561586638831\n",
      "Mean Fit Time:  1.3571513414382934\n",
      "Mean Score Time:  0.2234429121017456\n",
      "CV Time:  2.8306212425231934\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99582463 0.99582463 0.99582463 0.99582463 0.99582463\n",
      " 0.9958159  0.9958159  0.99372385 0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9954036040915086\n",
      "Mean Fit Time:  8.067408061027527\n",
      "Mean Score Time:  0.012498569488525391\n",
      "CV Time:  12.2898428440094\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99582463 0.99582463 0.99582463 0.99582463 0.99582463\n",
      " 0.9958159  0.9958159  0.9958159  1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9958220141333497\n",
      "Mean Fit Time:  260.52095544338226\n",
      "Mean Score Time:  0.05624861717224121\n",
      "CV Time:  388.22922348976135\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_mhv100, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using MinhashVectorizer @ 250\n",
    "* All classifiers are tested against the MinhashVectorizer() with a signature_length == 250\n",
    "* The RDP dataset is vectorized into k-mers of length 20 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied.\n",
    "* Classifiers tested include the Strand Binary and NonBinary Classifiers.\n",
    "* These classifiers are optimized for classifying Minhash and Strand Vectorized Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x143336 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1196500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv250 = MinhashVectorizer(signature_length=250, analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_mhv250 = mhv250.fit_transform(X)\n",
    "X_mhv250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99373695 0.99164927 0.99582463 0.99373695 0.99791232\n",
      " 0.9958159  0.9958159  0.99372385 1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9951952725779825\n",
      "Mean Fit Time:  0.20821666717529297\n",
      "Mean Score Time:  0.12408537864685058\n",
      "CV Time:  0.5985853672027588\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.98329854 0.97912317 0.98956159 0.99164927 0.98538622 0.98956159\n",
      " 0.99790795 0.98535565 0.98535565 0.9874477 ]\n",
      " \n",
      "Mean Accuracy:  0.9874647321389576\n",
      "Mean Fit Time:  2.3755683660507203\n",
      "Mean Score Time:  1.696353793144226\n",
      "CV Time:  6.884950160980225\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99373695 0.99164927 0.99582463 0.99373695 0.99791232\n",
      " 0.9958159  0.9958159  0.99372385 1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9951952725779825\n",
      "Mean Fit Time:  2.2723144769668577\n",
      "Mean Score Time:  1.0820468425750733\n",
      "CV Time:  5.837669610977173\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.97912317 0.97703549 0.98329854 0.98121086 0.97912317 0.98329854\n",
      " 0.98953975 0.9790795  0.9790795  0.97280335]\n",
      " \n",
      "Mean Accuracy:  0.9803591862405115\n",
      "Mean Fit Time:  1.05598304271698\n",
      "Mean Score Time:  0.11405258178710938\n",
      "CV Time:  2.022172689437866\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99582463 0.99582463 0.99164927 0.99373695 0.99582463\n",
      " 0.99372385 0.99372385 0.9958159  0.9958159 ]\n",
      " \n",
      "Mean Accuracy:  0.9945676575152209\n",
      "Mean Fit Time:  3.6831480503082275\n",
      "Mean Score Time:  0.12186706066131592\n",
      "CV Time:  5.973276853561401\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.51983299 0.5177453  0.53862213 0.54070981 0.52609603 0.54070981\n",
      " 0.5041841  0.5209205  0.53138075 0.55020921]\n",
      " \n",
      "Mean Accuracy:  0.5290410635826033\n",
      "Mean Fit Time:  1.9677305936813354\n",
      "Mean Score Time:  0.9390707731246948\n",
      "CV Time:  5.046531438827515\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99582463 0.99582463 0.99582463 0.99791232 0.99582463\n",
      " 0.9958159  0.99372385 0.99372385 0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9954031673378114\n",
      "Mean Fit Time:  38.200261521339414\n",
      "Mean Score Time:  0.029687952995300294\n",
      "CV Time:  53.90440344810486\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99582463 0.99582463 0.99582463 0.99582463 0.99791232\n",
      " 0.9958159  0.99372385 0.9958159  1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9958215773796525\n",
      "Mean Fit Time:  673.1109436035156\n",
      "Mean Score Time:  0.2204275369644165\n",
      "CV Time:  997.7528879642487\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_mhv250, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using MinhashVectorizer @ 1000\n",
    "* All classifiers are tested against the MinhashVectorizer() with a signature_length == 1000\n",
    "* The RDP dataset is vectorized into k-mers of length 20 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied.\n",
    "* Classifiers tested include the Strand Binary and NonBinary Classifiers.\n",
    "* These classifiers are optimized for classifying Minhash and Strand Vectorized Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.4 s\n",
      "Parser   : 208 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x568032 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4784594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv1000 = MinhashVectorizer(signature_length=1000, analyzer='char', ngram_range=(20,20), binary=False, use_idf=False, norm=None)\n",
    "X_mhv1000 = mhv1000.fit_transform(X)\n",
    "X_mhv1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99582463 0.99582463 0.99582463 0.99582463 0.99582463\n",
      " 0.9958159  0.9958159  0.99372385 0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.995612372358732\n",
      "Mean Fit Time:  0.5622330904006958\n",
      "Mean Score Time:  0.5203154802322387\n",
      "CV Time:  2.6907591819763184\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.98538622 0.98329854 0.98956159 0.98956159 0.9874739  0.98956159\n",
      " 0.9958159  0.98535565 0.9832636  0.99372385]\n",
      " \n",
      "Mean Accuracy:  0.9883002419615483\n",
      "Mean Fit Time:  9.889858818054199\n",
      "Mean Score Time:  7.251016330718994\n",
      "CV Time:  29.266679763793945\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99373695 0.99582463 0.99582463 0.99582463 0.99582463 0.99582463\n",
      " 0.9958159  0.9958159  0.99372385 0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.995612372358732\n",
      "Mean Fit Time:  9.728548789024353\n",
      "Mean Score Time:  4.926627492904663\n",
      "CV Time:  24.478174448013306\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.97912317 0.97703549 0.98329854 0.98329854 0.97912317 0.98121086\n",
      " 0.98953975 0.98117155 0.9790795  0.97280335]\n",
      " \n",
      "Mean Accuracy:  0.980568391261432\n",
      "Mean Fit Time:  4.647521018981934\n",
      "Mean Score Time:  0.5156163692474365\n",
      "CV Time:  8.83314061164856\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99373695 0.99582463 0.99582463 0.99373695 0.99582463\n",
      " 0.9958159  0.98953975 0.99372385 0.99790795]\n",
      " \n",
      "Mean Accuracy:  0.9943584524943004\n",
      "Mean Fit Time:  24.36133756637573\n",
      "Mean Score Time:  0.5172396421432495\n",
      "CV Time:  37.06350636482239\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.53653445 0.55949896 0.54279749 0.53235908 0.53235908 0.54488518\n",
      " 0.5376569  0.5125523  0.52719665 0.5251046 ]\n",
      " \n",
      "Mean Accuracy:  0.535094469824687\n",
      "Mean Fit Time:  4.5113321304321286\n",
      "Mean Score Time:  6.040672349929809\n",
      "CV Time:  17.005860805511475\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99164927 0.99582463 0.99582463 0.99582463 0.99791232 0.99582463\n",
      " 0.9958159  0.9958159  0.99372385 1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9958215773796525\n",
      "Mean Fit Time:  196.33305370807648\n",
      "Mean Score Time:  0.18124823570251464\n",
      "CV Time:  279.30551767349243\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.99372385 1.        ]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  293.0430881500244\n",
      "Mean Score Time:  0.12326574325561523\n",
      "CV Time:  1182.599416255951\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_mhv1000, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Align all tables left-->\n",
       "<style>\n",
       "table {\n",
       "       table-layout: fixed;\n",
       "       width: 100%;\n",
       "      } \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- Align all tables left-->\n",
    "<style>\n",
    "table {\n",
    "       table-layout: fixed;\n",
    "       width: 100%;\n",
    "      } \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Comparison Results  \n",
    "\n",
    "### TfidfVectorizer Outputs\n",
    "* 4786 rows\n",
    "* 807,185 feature columns\n",
    "* 6,940,414 stored data elements\n",
    "\n",
    "### Classifier Rankings - TfidfVectorizer \n",
    "\n",
    "|Classifier Name         | Cv Time | Rank | Fit Time | Rank | Score Time | Rank | Accuracy | Rank | Rank Sum |\n",
    "|:--                     |     ---:| :---:|      ---:| :---:|        ---:|------|      ---:| :---:|     :---:|\n",
    "StrandSliceClassifier|5.1|1|0.88|1|0.79|2|99.56|1|1.25|\n",
    "MultinomialNB|13.89|2|7.47|3|0.97|4|98.06|6|3.75|\n",
    "StrandBinaryClassifier|35.82|4|14.35|5|7.15|6|99.56|1|4|\n",
    "LinearSVC|674.37|7|472.43|7|0.28|1|99.56|1|4|\n",
    "SGDClassifier|69.82|6|45.79|6|0.93|3|99.37|4|4.75|\n",
    "RandomForestClassifier|28.55|3|6.13|2|11.71|8|54.07|7|5|\n",
    "StrandGiniClassifier|41.84|5|14.01|4|10.39|7|98.83|5|5.25|\n",
    "LogisticRegression|10750.01|9|3476.65|8|2.59|5|NaN|8|7.5|\n",
    "\n",
    "### MinhashVectorizer Outputs  @ Signature Length 1000:\n",
    "* 4786 rows\n",
    "* 568,032 feature columns\n",
    "* 4,784,594 stored data elements\n",
    "\n",
    "\n",
    "### Classifier Rankings - MinhashVectorizer @ Signature Length 1000\n",
    "\n",
    "\n",
    "|Classifier Name         | Cv Time | Rank | Fit Time | Rank | Score Time | Rank | Accuracy | Rank | Rank Sum |\n",
    "|:--                     |     ---:| :---:|      ---:| :---:|        ---:|------|      ---:| :---:|     :---:|\n",
    "StrandSliceClassifier|2.69|1|0.56|1|0.52|5|99.56|2|2.25|\n",
    "RandomForestClassifier|8.83|2|4.65|3|0.52|3|98.06|6|3.5|\n",
    "StrandBinaryClassifier|24.48|4|9.73|4|4.93|6|99.56|2|4|\n",
    "LinearSVC|279.31|7|196.33|7|0.18|2|99.58|1|4.25|\n",
    "MultinomialNB|17.01|3|4.51|2|6.04|7|53.51|7|4.75|\n",
    "SGDClassifier|37.06|6|24.36|6|0.52|4|99.44|4|5|\n",
    "StrandGiniClassifier|29.27|5|9.89|5|7.25|8|98.83|5|5.75|\n",
    "LogisticRegression|1182.6|8|293.04|8|0.12|1|NaN|8|6.25|\n",
    "\n",
    "### MinhashVectorizer Outputs  @ Signature Length 500:\n",
    "* 4786 rows\n",
    "* 143,336 feature columns\n",
    "* 1,196,500 stored data elements\n",
    "\n",
    "\n",
    "### Classifier Rankings - MinhashVectorizer @ Signature Length 500\n",
    "\n",
    "\n",
    "|Classifier Name         | Cv Time | Rank | Fit Time | Rank | Score Time | Rank | Accuracy | Rank | Rank Sum |\n",
    "|:--                     |     ---:| :---:|      ---:| :---:|        ---:|------|      ---:| :---:|     :---:|\n",
    "StrandSliceClassifier|0.6|1|0.21|1|0.12|4|99.52|3|2.25|\n",
    "MultinomialNB|2.02|2|1.06|2|0.11|2|98.04|7|3.25|\n",
    "LinearSVC|53.9|7|38.2|7|0.03|1|99.54|2|4.25|\n",
    "StrandBinaryClassifier|5.84|4|2.27|4|1.08|7|99.52|3|4.5|\n",
    "SGDClassifier|5.97|5|3.68|6|0.12|3|99.46|5|4.75|\n",
    "RandomForestClassifier|5.05|3|1.97|3|0.94|6|52.9|8|5|\n",
    "LogisticRegression|997.75|8|673.11|8|0.22|5|99.58|1|5.5|\n",
    "StrandGiniClassifier|6.88|6|2.38|5|1.7|8|98.75|6|6.25|\n",
    "\n",
    "### MinhashVectorizer Outputs  @ Signature Length 250:\n",
    "* 4786 rows\n",
    "* 143,336 feature columns\n",
    "* 1,196,500 stored data elements\n",
    "\n",
    "\n",
    "### Classifier Rankings - MinhashVectorizer @ Signature Length 250\n",
    "\n",
    "\n",
    "|Classifier Name         | Cv Time | Rank | Fit Time | Rank | Score Time | Rank | Accuracy | Rank | Rank Sum |\n",
    "|:--                     |     ---:| :---:|      ---:| :---:|        ---:|------|      ---:| :---:|     :---:|\n",
    "StrandSliceClassifier|0.6|1|0.21|1|0.12|4|99.52|3|2.25|\n",
    "MultinomialNB|2.02|2|1.06|2|0.11|2|98.04|7|3.25|\n",
    "LinearSVC|53.9|7|38.2|7|0.03|1|99.54|2|4.25|\n",
    "StrandGiniClassifier|5.84|4|2.27|4|1.08|7|99.52|3|4.5|\n",
    "SGDClassifier|5.97|5|3.68|6|0.12|3|99.46|5|4.75|\n",
    "RandomForestClassifier|5.05|3|1.97|3|0.94|6|52.9|8|5|\n",
    "LogisticRegression|997.75|8|673.11|8|0.22|5|99.58|1|5.5|\n",
    "StrandBinaryClassifier|6.88|6|2.38|5|1.7|8|98.75|6|6.25|\n",
    "\n",
    "### MinhashVectorizer Outputs  @ Signature Length 100:\n",
    "* 4786 rows\n",
    "* 57,411 feature columns\n",
    "* 478,600 stored data elements\n",
    "\n",
    "\n",
    "### Classifier Rankings - MinhashVectorizer @ Signature Length 100\n",
    "\n",
    "\n",
    "|Classifier Name         | Cv Time | Rank | Fit Time | Rank | Score Time | Rank | Accuracy | Rank | Rank Sum |\n",
    "|:--                     |     ---:| :---:|      ---:| :---:|        ---:|------|      ---:| :---:|     :---:|\n",
    "StrandSliceClassifier|0.42|1|0.14|1|0.09|5|99.42|5|3|\n",
    "SGDClassifier|2.29|4|1.3|5|0.05|2|99.52|3|3.5|\n",
    "MultinomialNB|0.8|2|0.41|2|0.05|3|97.81|7|3.5|\n",
    "LinearSVC|12.29|7|8.07|7|0.01|1|99.54|2|4.25|\n",
    "StrandBinaryClassifier|2.18|3|0.87|3|0.44|7|99.44|4|4.25|\n",
    "LogisticRegression|388.23|8|260.52|8|0.06|4|99.58|1|5.25|\n",
    "StrandGiniClassifier|2.86|6|0.95|4|0.67|8|98.31|6|6|\n",
    "RandomForestClassifier|2.83|5|1.36|6|0.22|6|49.9|8|6.25|\n",
    "\n",
    "### MinhashVectorizer Outputs  @ Signature Length 50:\n",
    "* 4786 rows\n",
    "* 29,733 feature columns\n",
    "* 239,300 stored data elements\n",
    "\n",
    "\n",
    "### Classifier Rankings - MinhashVectorizer @ Signature Length 50\n",
    "\n",
    "\n",
    "|Classifier Name         | Cv Time | Rank | Fit Time | Rank | Score Time | Rank | Accuracy | Rank | Rank Sum |\n",
    "|:--                     |     ---:| :---:|      ---:| :---:|        ---:|------|      ---:| :---:|     :---:|\n",
    "MultinomialNB|0.44|1|0.21|1|0.03|3|97.47|7|3|\n",
    "SGDClassifier|1.46|3|0.81|5|0.02|2|99.41|3|3.25|\n",
    "LinearSVC|5.12|6|3.24|7|0|1|99.5|2|4|\n",
    "StrandBinaryClassifier|1.06|2|0.4|3|0.22|7|99.27|4|4|\n",
    "StrandSliceClassifier|7.12|7|0.34|2|0.14|6|99.27|4|4.75|\n",
    "LogisticRegression|199.86|8|133.73|9|0.04|4|99.52|1|5.5|\n",
    "StrandGiniClassifier|4.08|5|0.43|4|0.27|8|98.02|6|5.75|\n",
    "RandomForestClassifier|2.6|4|1.13|6|0.1|5|47.28|8|5.75|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization using Pipeline and Grid Search  \n",
    "* Here a Pipeline is used to perform parameter optimization for the MinhashVectorizer and StrandSliceClassifier.\n",
    "* The grid search executes in parallel performing stratified 10-fold cross validation for each combination of parameters in the parameter grid. \n",
    "* 1,200 10-fold cross validations are performed for a total of 12,000 fits.\n",
    "* The grid search identifies the highest cross validation accuracy so far of 96.6448% using the following MinhashVectorizer parameters:\n",
    " * binary: False, \n",
    " * ngram_range: (30, 30)\n",
    " * norm: 'l2' \n",
    " * signature_length: 500\n",
    " * sublinear_tf: True\n",
    " * use_idf': False\n",
    " * smooth_idf: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('MHV',\n",
       "                                        MinhashVectorizer(analyzer='char',\n",
       "                                                          binary=False,\n",
       "                                                          decode_error='strict',\n",
       "                                                          dtype=<class 'numpy.float64'>,\n",
       "                                                          encoding='utf-8',\n",
       "                                                          input='content',\n",
       "                                                          lowercase=True,\n",
       "                                                          max_df=1.0,\n",
       "                                                          max_features=None,\n",
       "                                                          min_df=1,\n",
       "                                                          ngram_range=(1, 1),\n",
       "                                                          norm='l2',\n",
       "                                                          pre...\n",
       "             param_grid=[{'MHV__binary': [True, False],\n",
       "                          'MHV__ngram_range': [(15, 15), (20, 20), (30, 30),\n",
       "                                               (60, 60), (80, 80)],\n",
       "                          'MHV__norm': ['l1', 'l2', None],\n",
       "                          'MHV__signature_length': [50, 100, 250, 500, 1000],\n",
       "                          'MHV__smooth_idf': [True, False],\n",
       "                          'MHV__sublinear_tf': [True, False],\n",
       "                          'MHV__use_idf': [True, False]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# StrandPy  \n",
    "from StrandPy import MinhashVectorizer\n",
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "# Set up our cross validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('MHV', MinhashVectorizer(analyzer='char')),\n",
    "    ('Strand', StrandSliceClassifier())\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'MHV__signature_length': [50,100,250,500,1000],\n",
    "        'MHV__ngram_range': [(15,15),(20,20),(30,30),(60,60),(80,80)],\n",
    "        'MHV__binary': [True, False],\n",
    "        'MHV__use_idf': [True,False],\n",
    "        'MHV__norm': ['l1','l2',None],\n",
    "        'MHV__smooth_idf': [True,False],\n",
    "        'MHV__sublinear_tf': [True,False],\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(pipe, n_jobs=-1, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('MHV',\n",
       "                 MinhashVectorizer(analyzer='char', binary=True,\n",
       "                                   decode_error='strict',\n",
       "                                   dtype=<class 'numpy.float64'>,\n",
       "                                   encoding='utf-8', input='content',\n",
       "                                   lowercase=True, max_df=1.0,\n",
       "                                   max_features=None, min_df=1,\n",
       "                                   ngram_range=(30, 30), norm='l2',\n",
       "                                   preprocessor=None, signature_length=500,\n",
       "                                   smooth_idf=True, stop_words=None,\n",
       "                                   strip_accents=None, sublinear_tf=False,\n",
       "                                   token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                   tokenizer=None, transform_inplace=False,\n",
       "                                   use_idf=False, vocabulary=None)),\n",
       "                ('Strand',\n",
       "                 StrandSliceClassifier(feature_importances=False,\n",
       "                                       noise_thresh=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest CV Mean Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9964483189350197"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Highest CV Mean Accuracy')\n",
    "max(grid_search.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Grid Searches:  1200\n"
     ]
    }
   ],
   "source": [
    "print('Total Grid Searches: ', len(grid_search.cv_results_['params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Grid Search Results\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (20, 20), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.996030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l2', 'MHV__signature_length': 100, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.996030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>{'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>{'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}</td>\n",
       "      <td>0.995822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                   params  \\\n",
       "307      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "909     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "914     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "351     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "906      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "916     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "871    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "954     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "945      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "896       {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "957    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "862     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "865      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "866      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "949     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "273      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "879   {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "265       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "876     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "277     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "872      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "312       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "308       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "313      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "314      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "317     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "353      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "357     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "943    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "302      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "939     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "300       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "231     {'MHV__binary': True, 'MHV__ngram_range': (20, 20), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "275     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "951    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "899     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "953     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "278     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "902     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "897      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "919   {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "315     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "345       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "959   {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "838    {'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "863    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "864       {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "944       {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "354      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "868      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "870     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "274      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "272       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "946      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "269      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "258       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "878    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "319    {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "264        {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "875    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "344        {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "918    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "792      {'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "908      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "907     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "915    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "910     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "350      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "337       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "305       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "955    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "349      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "390      {'MHV__binary': True, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l1', 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "296        {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "938      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "340       {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "347      {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "359    {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "833     {'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "358     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "903    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "304        {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "794     {'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "192       {'MHV__binary': True, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "740      {'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "1016      {'MHV__binary': False, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "1023   {'MHV__binary': False, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "759   {'MHV__binary': False, 'MHV__ngram_range': (20, 20), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "421      {'MHV__binary': True, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l2', 'MHV__signature_length': 250, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "1009     {'MHV__binary': False, 'MHV__ngram_range': (60, 60), 'MHV__norm': 'l2', 'MHV__signature_length': 100, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "877    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "912      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "256        {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 250, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "913     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "874     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l1', 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "958    {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': False, 'MHV__use_idf': True}   \n",
       "355     {'MHV__binary': True, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 1000, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "947     {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': False, 'MHV__use_idf': False}   \n",
       "948      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': None, 'MHV__signature_length': 500, 'MHV__smooth_idf': False, 'MHV__sublinear_tf': True, 'MHV__use_idf': True}   \n",
       "905      {'MHV__binary': False, 'MHV__ngram_range': (30, 30), 'MHV__norm': 'l2', 'MHV__signature_length': 500, 'MHV__smooth_idf': True, 'MHV__sublinear_tf': True, 'MHV__use_idf': False}   \n",
       "\n",
       "      mean_test_score  \n",
       "307          0.996448  \n",
       "909          0.996448  \n",
       "914          0.996240  \n",
       "351          0.996240  \n",
       "906          0.996240  \n",
       "916          0.996240  \n",
       "871          0.996240  \n",
       "954          0.996240  \n",
       "945          0.996240  \n",
       "896          0.996240  \n",
       "957          0.996240  \n",
       "862          0.996240  \n",
       "865          0.996240  \n",
       "866          0.996240  \n",
       "949          0.996240  \n",
       "273          0.996240  \n",
       "879          0.996240  \n",
       "265          0.996240  \n",
       "876          0.996240  \n",
       "277          0.996240  \n",
       "872          0.996240  \n",
       "312          0.996240  \n",
       "308          0.996240  \n",
       "313          0.996240  \n",
       "314          0.996240  \n",
       "317          0.996240  \n",
       "353          0.996240  \n",
       "357          0.996240  \n",
       "943          0.996239  \n",
       "302          0.996239  \n",
       "939          0.996031  \n",
       "300          0.996031  \n",
       "231          0.996031  \n",
       "275          0.996031  \n",
       "951          0.996031  \n",
       "899          0.996031  \n",
       "953          0.996031  \n",
       "278          0.996031  \n",
       "902          0.996031  \n",
       "897          0.996031  \n",
       "919          0.996031  \n",
       "315          0.996031  \n",
       "345          0.996031  \n",
       "959          0.996031  \n",
       "838          0.996031  \n",
       "863          0.996031  \n",
       "864          0.996031  \n",
       "944          0.996031  \n",
       "354          0.996031  \n",
       "868          0.996031  \n",
       "870          0.996031  \n",
       "274          0.996031  \n",
       "272          0.996031  \n",
       "946          0.996031  \n",
       "269          0.996031  \n",
       "258          0.996031  \n",
       "878          0.996031  \n",
       "319          0.996031  \n",
       "264          0.996031  \n",
       "875          0.996031  \n",
       "344          0.996031  \n",
       "918          0.996031  \n",
       "792          0.996031  \n",
       "908          0.996031  \n",
       "907          0.996031  \n",
       "915          0.996031  \n",
       "910          0.996031  \n",
       "350          0.996031  \n",
       "337          0.996031  \n",
       "305          0.996031  \n",
       "955          0.996031  \n",
       "349          0.996031  \n",
       "390          0.996031  \n",
       "296          0.996031  \n",
       "938          0.996031  \n",
       "340          0.996031  \n",
       "347          0.996031  \n",
       "359          0.996031  \n",
       "833          0.996031  \n",
       "358          0.996031  \n",
       "903          0.996031  \n",
       "304          0.996031  \n",
       "794          0.996030  \n",
       "192          0.996030  \n",
       "740          0.996030  \n",
       "1016         0.996030  \n",
       "1023         0.996030  \n",
       "759          0.996030  \n",
       "421          0.996030  \n",
       "1009         0.996030  \n",
       "877          0.995822  \n",
       "912          0.995822  \n",
       "256          0.995822  \n",
       "913          0.995822  \n",
       "874          0.995822  \n",
       "958          0.995822  \n",
       "355          0.995822  \n",
       "947          0.995822  \n",
       "948          0.995822  \n",
       "905          0.995822  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print('All Grid Search Results\\n')\n",
    "data = {'params': grid_search.cv_results_['params'], 'mean_test_score': grid_search.cv_results_['mean_test_score'] }\n",
    "df = pd.DataFrame(data)\n",
    "df.sort_values(['mean_test_score'],ascending=False)[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:/StrandPy/RDP_MHV_GridSearch_Params_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validated Feature Elimination \n",
    "* Here we use the StrandPy CVFE tool for selecting the best features from a sparse matrix / dataset created using the MinhashVectorizer.  \n",
    "* The CVFE tool is optimized to quickly eliminate low value features from sparse datasets while maintaining the model's original level of accuracy.\n",
    "* The tool will also work using any Sklearn model or datasets.\n",
    "* Sparse datasets created using Minhash or Tfidf Vectorizers typically have a very large number of features.\n",
    "* The CVFE tool can drastically reduce the overall number of features with no impact to the predictive model used during processing.   \n",
    "\n",
    "### Here we create a sparse matrix / dataset created using MinhashVectorizer and the RDP gene sequence dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x367455 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1196500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from StrandPy import MinhashVectorizer\n",
    "\n",
    "mhv = MinhashVectorizer(analyzer='char', binary=False, ngram_range=(60, 60), norm='l2',signature_length=250,\n",
    "                                   smooth_idf=False, sublinear_tf=False, use_idf=False)\n",
    "X_mhv = mhv.fit_transform(X)\n",
    "X_mhv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Baseline Cross Validation is Performed \n",
    "* Here we create a Stratified 3-fold cross validation against the X_mhv sparse dataset we created above.  \n",
    "* The cross validation is performed using the StrandSliceClassifier\n",
    "* The classifier achieves an average of 99.6% during cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9964482784809463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99498747, 0.9968652 , 0.99749216])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn Tools\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# StandPy Tools \n",
    "from StrandSliceClassifier import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cvs = cross_val_score(strand,X_mhv, y, cv=cv, n_jobs=-1)\n",
    "print('mean:', np.mean(cvs))\n",
    "cvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strand Slice Classifier Feature Importances\n",
    "* Since creating feature importance rankings adds extra time to training processes, a \"feature_importances\" parameter is added to the Strand Slice Classifier.\n",
    "* When set to True, feature_importances are generated during the a call to the fit() function. \n",
    "* Strand Slice Classifier feature importances are first approximated by class using class and overall feature non-zero counts. * Finally, the mean of all class importances is taken to determine a blended feature importance. \n",
    "* This measures each feature's average class purity which is weighted by the total amount of information the feature provides. * For example, a feature containing only 1 value is 100% pure.  However, it does not provide much information in a 5000 record dataset.  \n",
    "\n",
    "### Strand Slice Classifier Feature Importance Performance\n",
    "* Using the sparse matrix non-zero counts to generate feature importances is very fast.\n",
    "* For comparison below, we are using a MinhashVectorizer dataset X_mhv with:\n",
    " * 4786 rows\n",
    " * 367,614 columns \n",
    " * 1,196,500 stored data elements \n",
    "* This dataset was created using kmers / gene sequence chunks of length 60 and a minhash signature of length 250.  \n",
    "* In the example below using the same X_mhv dataset, we see that: \n",
    " * The StrandSliceClassifier creates a model in 125ms.\n",
    " * The StrandSliceClassifier creates a model and generates feature importances in 5.59s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 133 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StrandSliceClassifier(feature_importances=False, noise_thresh=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get feature importances\n",
    "strand = StrandSliceClassifier(feature_importances=False)\n",
    "strand.fit(X_mhv,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get feature importances\n",
    "strand = StrandSliceClassifier(feature_importances=True)\n",
    "strand.fit(X_mhv,y)\n",
    "feature_importances = strand.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeding up Cross Validated Feature Elimination by Providing Feature Importances One Time\n",
    "* Since we now have a list of feature_importances (above)\n",
    "* We may run CVFE using a StrandSliceClassifier with feature_importances == False. \n",
    "* This speeds up the process exponentially, since cross validation is used each time features are removed to ensure that there is no loss in the model's accruacy.\n",
    "* In the example below:\n",
    " * A total of 3,747 3-fold cross validations are performed. \n",
    " * 3,747 * 3 = 11,241 calls to the fit() function.\n",
    " * Each of these calls would run at ~133ms vs. 5.59s, since feature_importances may be turned off during CVFE while using the StrandSliceClassifier. \n",
    " \n",
    "### CVFE Performance\n",
    "**The MinhashVectorizer dataset X_mhv began with:**\n",
    " * 4786 rows\n",
    " * 367,614 columns \n",
    " * 1,196,500 stored data elements\n",
    "\n",
    "**After CVFE Processing the MinhashVectorizer dataset X_mhv was reduced to:**\n",
    " * 4786 rows\n",
    " * 301 columns \n",
    " * 32,012 stored data elements\n",
    " \n",
    "**Processing Time: 8min 09s** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (4786, 367455)\n",
      "-----------------------------------------------------\n",
      "Remove Low Nonzero Features...\n",
      "X Shape: (4786, 367455)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  287852\n",
      "Total Features Removed:  287852\n",
      "Cross Validations:  163\n",
      "-----------------------------------------------------\n",
      "Remove Features by Importances...\n",
      "X Shape: (4786, 79603)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  55510\n",
      "Total Features Removed:  343362\n",
      "Cross Validations:  317\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 24093)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  1\n",
      "Total Features Removed:  343363\n",
      "Cross Validations:  320\n",
      "Step size:  12046\n",
      "Step Blocks removed: 8.301510874979246e-05\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 24092)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  3010\n",
      "Total Features Removed:  346373\n",
      "Cross Validations:  329\n",
      "Step size:  3010\n",
      "Step Blocks removed: 1.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 21082)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  4506\n",
      "Total Features Removed:  350879\n",
      "Cross Validations:  358\n",
      "Step size:  751\n",
      "Step Blocks removed: 6.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 16576)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  6138\n",
      "Total Features Removed:  357017\n",
      "Cross Validations:  448\n",
      "Step size:  186\n",
      "Step Blocks removed: 33.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 10438)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  5850\n",
      "Total Features Removed:  362867\n",
      "Cross Validations:  680\n",
      "Step size:  45\n",
      "Step Blocks removed: 130.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 4588)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  2940\n",
      "Total Features Removed:  365807\n",
      "Cross Validations:  1139\n",
      "Step size:  10\n",
      "Step Blocks removed: 294.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 1648)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  1293\n",
      "Total Features Removed:  367100\n",
      "Cross Validations:  2787\n",
      "Step size:  1\n",
      "Step Blocks removed: 1293.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 355)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  51\n",
      "Total Features Removed:  367151\n",
      "Cross Validations:  3142\n",
      "Step size:  1\n",
      "Step Blocks removed: 51.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 304)\n",
      "Current Base Score:  0.99645\n",
      "Step Features Removed:  3\n",
      "Total Features Removed:  367154\n",
      "Cross Validations:  3446\n",
      "Step size:  1\n",
      "Step Blocks removed: 3.0\n",
      "-----------------------------------------------------\n",
      "Final Base Score:  0.99645\n",
      "Total Features Removed:  367154\n",
      "Cross Validations:  3747\n",
      "Wall time: 8min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CVFE(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "     estimator=StrandSliceClassifier(feature_importances=False,\n",
       "                                     noise_thresh=None),\n",
       "     feature_importances=array([0.0080819 , 0.00829221, 0.00807292, ..., 0.00782851, 0.00793651,\n",
       "       0.00796875]),\n",
       "     min_step_size=1, n_jobs=-1, preserve_increases=False, scoring='accuracy',\n",
       "     verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "from StrandPy import CVFE\n",
    "# Sklean Tools \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create faster, no-feature_importances strand object \n",
    "strand = StrandSliceClassifier()\n",
    "\n",
    "# Use Sklearn's StratifiedKFold to manage cross validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Create CVFE object using feature_importances created earlier \n",
    "cvfe = CVFE(strand, cv, n_jobs=-1, min_step_size=1, scoring='accuracy',\n",
    "            preserve_increases=False, feature_importances=feature_importances, verbose=True)\n",
    "\n",
    "cvfe.fit(X_mhv,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVFE Dataset Validation\n",
    "**Using the cvfe.transform() confirms that the new dataset has:**\n",
    " * 4786 rows\n",
    " * 301 columns \n",
    " * 32,012 stored data elements\n",
    " \n",
    "**The original dataset had:**\n",
    " * 4786 rows\n",
    " * 367,614 columns \n",
    " * 1,196,500 stored data elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.98 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x301 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32012 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Take a look at the new features selected by CVFE\n",
    "X_mhv_cvfe = cvfe.transform(X_mhv)\n",
    "X_mhv_cvfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVFE Baseline Validation\n",
    "* Performing the exact same cross validation once again on the new CVFE reduced dataset X_mhv_cvfe shows that the same cross validation accuracy may be achieved using only 301 out of 367,614 columns.\n",
    "* Likewise, only 32,012 out of 1,196,500 stored data elements were required. \n",
    "* These features were identified using CVFE in only 8min 09s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9964482784809463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99498747, 0.9968652 , 0.99749216])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn Tools\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# StandPy Tools \n",
    "from StrandSliceClassifier import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cvs = cross_val_score(strand,X_mhv_cvfe, y, cv=cv, n_jobs=-1)\n",
    "print('mean:', np.mean(cvs))\n",
    "cvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Sklearn's Recursive Feature Elimination\n",
    "**Here we compare the results above to a similar tool available within Sklearn using the same dataset X_mhv:**\n",
    "* Sklearn offers the Recursive Feature Elimination tool [RFECV](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html).\n",
    "* This tool offers \"feature ranking with recursive feature elimination and cross-validated selection of the best number of features\".\n",
    "* Below we use the same model (Strand) and cross validation to compare performance and results. \n",
    "* Unlike CVFS however, RFECV requires a model with feature_importances to be provided.\n",
    "\n",
    "### RFECV Tests performed\n",
    "* Choosing a step == 1 for RFECV caused the tool to run > 24 hours, possibly indefinitely, removing 1 feature at time and performing cross validation at each step.  \n",
    " * **Outcome** - This process was eventually terminated after almost 2 days.    \n",
    "* Next, I choose a step equal to 0.75, recursively attempting removal for 75% of features at each iteration. I believed this step value mirrors the behavior of CVFE processing as closely as possbile.\n",
    " * **Outcome** - This process executed in 23.5s and removed 0 features.  \n",
    "* Step = 0.5\n",
    " * **Outcome** - This process executed in 26.9s and removed 0 features.\n",
    "* Step = 0.25\n",
    " * **Outcome** - This process executed in 38.3s and resulted in a 4786 x 275,592 matrix with 1,092,216 stored elements.\n",
    "* Step = 0.1\n",
    " * **Outcome** - This process executed in 1min 16s and resulted in a 4786 x 220,475 matrix with 1,030,712 stored elements.\n",
    "* Step = 0.01\n",
    " * **Outcome** - This process executed in 10min 24s and resulted in a 4786 x 231,517 matrix with 1,044,394 stored elements.\n",
    " \n",
    "**Finally, I took the total number of X_mhv features (367,455) / the total number of CVFE cross validation above (3747) = 98.066 and set the RFCEV step == 98.**\n",
    "*  This means that the RFECV process would remove 98 features at each recursive iteration. \n",
    "* **Outcome** - This process executed in 6h 10min 9s and resulted in a 4,786 x 229,079 matrix with 1,039,316 stored elements.\n",
    "* Detailed results are below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6h 10min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "      estimator=StrandSliceClassifier(feature_importances=True,\n",
       "                                      noise_thresh=None),\n",
       "      min_features_to_select=1, n_jobs=-1, scoring='accuracy', step=98,\n",
       "      verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandSliceClassifier import StrandSliceClassifier\n",
    "# Sklearn Tools\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Create a strand object with feature_importances (required by RFECV)\n",
    "strand = StrandSliceClassifier(feature_importances=True)\n",
    "\n",
    "rfecv = RFECV(estimator=strand, step=98, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X_mhv, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x229079 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1039316 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Take a look at the new features selected by CVFE\n",
    "X_mhv_rfecv = rfecv.transform(X_mhv)\n",
    "X_mhv_rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9964482784809463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99498747, 0.9968652 , 0.99749216])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn Tools\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# StandPy Tools \n",
    "from StrandSliceClassifier import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cvs = cross_val_score(strand,X_mhv_rfecv, y, cv=cv, n_jobs=-1)\n",
    "print('mean:', np.mean(cvs))\n",
    "cvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Minhashed Samples from the Same Dataset\n",
    "* This example shows how to perform feature stacking column-wise using multiple MinhashVectorizer signatures. \n",
    "* We sample:\n",
    " * 2,392,624 10 character elements at a signature length of 500\n",
    " * 2,392,584 30 character elements at a signature length of 500\n",
    " * 2,392,524 60 character elements at a signature length of 500\n",
    " * 2,392,484 80 character elements at a signature length of 500\n",
    "* The combined matrix contains:\n",
    " * 4786 x 2,143,537 with 9,570,216 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StrandPy import MinhashVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x104013 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2392624 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mhv = MinhashVectorizer(analyzer='char', binary=False, ngram_range=(10, 10), norm='l2',signature_length=500,\n",
    "                                   smooth_idf=False, sublinear_tf=False, use_idf=False)\n",
    "X_mhv_10 = mhv.fit_transform(X)\n",
    "X_mhv_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x419012 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2392584 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mhv = MinhashVectorizer(analyzer='char', binary=False, ngram_range=(30, 30), norm='l2',signature_length=500,\n",
    "                                   smooth_idf=False, sublinear_tf=False, use_idf=False)\n",
    "X_mhv_30 = mhv.fit_transform(X)\n",
    "X_mhv_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x729982 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2392524 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mhv = MinhashVectorizer(analyzer='char', binary=False, ngram_range=(60, 60), norm='l2',signature_length=500,\n",
    "                                   smooth_idf=False, sublinear_tf=False, use_idf=False)\n",
    "X_mhv_60 = mhv.fit_transform(X)\n",
    "X_mhv_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4786x890530 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2392484 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mhv = MinhashVectorizer(analyzer='char', binary=False, ngram_range=(80, 80), norm='l2',signature_length=500,\n",
    "                                   smooth_idf=False, sublinear_tf=False, use_idf=False)\n",
    "X_mhv_80 = mhv.fit_transform(X)\n",
    "X_mhv_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4786x2143537 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9570216 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_mhv_10_80 = hstack([X_mhv_10,X_mhv_30,X_mhv_60,X_mhv_80])\n",
    "X_mhv_10_80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CVFE to Find the Best Combined Features\n",
    "* Once again, we use the CVFE tool to search for the best features from a total of 2,143,537 columns. \n",
    "* CVFE reduces the X_mhv_10_80 data to only 126 features and 76,774 elements. \n",
    "* The CVFE processed 2,143,537 columns in 34min 49s.\n",
    "* I also use the CVFE's tool preserve_increases=True parameter to retain any increases in cross validation accuracy during the feature elimination. \n",
    "* CVFE finds 126 features producing **97.7% accuracy** using the same cross validation strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "# Get feature importances\n",
    "strand = StrandSliceClassifier(feature_importances=True)\n",
    "strand.fit(X_mhv_10_80,y)\n",
    "feature_importances = strand.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (4786, 2143537)\n",
      "-----------------------------------------------------\n",
      "Remove Low Nonzero Features...\n",
      "X Shape: (4786, 2143537)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  1706218\n",
      "Total Features Removed:  1706218\n",
      "Cross Validations:  486\n",
      "-----------------------------------------------------\n",
      "Remove Features by Importances...\n",
      "X Shape: (4786, 437319)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  347873\n",
      "Total Features Removed:  2054091\n",
      "Cross Validations:  874\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 89446)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  14\n",
      "Total Features Removed:  2054105\n",
      "Cross Validations:  885\n",
      "Step size:  11179\n",
      "Step Blocks removed: 0.0012523481527864746\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 89432)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  36309\n",
      "Total Features Removed:  2090414\n",
      "Cross Validations:  918\n",
      "Step size:  2793\n",
      "Step Blocks removed: 13.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 53123)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  23698\n",
      "Total Features Removed:  2114112\n",
      "Cross Validations:  995\n",
      "Step size:  697\n",
      "Step Blocks removed: 34.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 29425)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  17661\n",
      "Total Features Removed:  2131773\n",
      "Cross Validations:  1166\n",
      "Step size:  173\n",
      "Step Blocks removed: 102.08670520231213\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 11764)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  7732\n",
      "Total Features Removed:  2139505\n",
      "Cross Validations:  1447\n",
      "Step size:  42\n",
      "Step Blocks removed: 184.0952380952381\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 4032)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  2934\n",
      "Total Features Removed:  2142439\n",
      "Cross Validations:  1895\n",
      "Step size:  9\n",
      "Step Blocks removed: 326.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 1098)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  865\n",
      "Total Features Removed:  2143304\n",
      "Cross Validations:  2993\n",
      "Step size:  1\n",
      "Step Blocks removed: 865.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 233)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  83\n",
      "Total Features Removed:  2143387\n",
      "Cross Validations:  3226\n",
      "Step size:  1\n",
      "Step Blocks removed: 83.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 150)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  17\n",
      "Total Features Removed:  2143404\n",
      "Cross Validations:  3376\n",
      "Step size:  1\n",
      "Step Blocks removed: 17.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 133)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  6\n",
      "Total Features Removed:  2143410\n",
      "Cross Validations:  3509\n",
      "Step size:  1\n",
      "Step Blocks removed: 6.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (4786, 127)\n",
      "Current Base Score:  0.99708\n",
      "Step Features Removed:  1\n",
      "Total Features Removed:  2143411\n",
      "Cross Validations:  3636\n",
      "Step size:  1\n",
      "Step Blocks removed: 1.0\n",
      "-----------------------------------------------------\n",
      "Final Base Score:  0.99708\n",
      "Total Features Removed:  2143411\n",
      "Cross Validations:  3762\n",
      "Wall time: 34min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CVFE(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "     estimator=StrandSliceClassifier(feature_importances=False,\n",
       "                                     noise_thresh=None),\n",
       "     feature_importances=array([0.0080819 , 0.00794956, 0.00878906, ..., 0.0078745 , 0.00796875,\n",
       "       0.00785319]),\n",
       "     min_step_size=1, n_jobs=-1, preserve_increases=True, scoring='accuracy',\n",
       "     verbose=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "from StrandPy import CVFE\n",
    "# Sklean Tools \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create faster, no-feature_importances strand object \n",
    "strand = StrandSliceClassifier()\n",
    "\n",
    "# Use Sklearn's StratifiedKFold to manage cross validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Create CVFE object using feature_importances created earlier \n",
    "cvfe = CVFE(strand, cv, n_jobs=-1, min_step_size=1, scoring='accuracy',\n",
    "            preserve_increases=True, feature_importances=feature_importances, verbose=True)\n",
    "\n",
    "cvfe.fit(X_mhv_10_80,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4786x126 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 76774 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mhv_10_80_cvfe = cvfe.transform(X_mhv_10_80)\n",
    "X_mhv_10_80_cvfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.99498747 0.99811912 0.99811912]\n",
      " \n",
      "Mean Accuracy:  0.9970752377285952\n",
      "Mean Fit Time:  0.05066974957784017\n",
      "Mean Score Time:  0.042997280756632485\n",
      "CV Time:  0.11998367309570312\n"
     ]
    }
   ],
   "source": [
    "# StandPy Tools \n",
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "stratified_cross_validate(strand, X_mhv_10_80_cvfe, y, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhashing Text Documents \n",
    "* The sklean.dataset '20 newgroups' is used for document classification.  \n",
    "* Word n-grams of lengths 1 to 3 are created from each document. \n",
    "* TfidfVectorizer and the MinhashVectorizer are compared. \n",
    "\n",
    "### Load the 20 News Groups Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: 3803\n",
      "target shape: (3803,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'comp.sys.ibm.pc.hardware',\n",
    "    'misc.forsale',\n",
    "    'rec.autos',\n",
    "    'sci.space',\n",
    "    'talk.religion.misc',\n",
    "]\n",
    "\n",
    "data, target = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                 return_X_y=True)\n",
    "\n",
    "X = data\n",
    "y = target\n",
    "\n",
    "print('features shape:', len(X)) \n",
    "print('target shape:', y.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the data look like?\n",
    "**Below I show the first record of the dataset and the category / target value assigned to that record.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talk.religion.misc\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Subject: Re: Christian Daemons? [Biblical Demons, the u\\nFrom: stigaard@mhd.moorhead.msus.edu\\nReply-To: stigaard@mhd.moorhead.msus.edu\\nOrganization: Moorhead State University, Moorhead, MN\\nNntp-Posting-Host: 134.29.97.2\\nLines: 23\\n\\n>>>667\\n>>>the neighbor of the beast\\n>>\\n>>No, 667 is across the street from the beast.  664 and 668 are the\\n>>neighbors of the beast.\\n>\\n>I think some people are still not clear on this:\\n>667 is *not* the neighbor of the beast, but, rather, across the\\n>street. It is, in fact, 668 which is the neighbor of the beast.\\n\\nno, sheesh, didn\\'t you know 666 is the beast\\'s apartment?  667 is across the\\nhall from the beast, and is his neighbor along with the rest of the 6th floor.\\n\\n>Justin (still trying to figure out what this has to do with alt.discordia)\\n\\nThis doesn\\'t seem discordant to you?\\n\\n-----------------------     ----------------------     -----------------------\\n\\t-Paul W. Stigaard, Lokean Discordian Libertarian\\n  !XOA!\\t\\tinternet:  stigaard@mhd1.moorhead.msus.edu\\n (fnord)       Episkopos and Chair, Moorhead State University Campus Discordians\\n\\t\\tRectal neufotomist at large\\n     \"If I left a quote here, someone would think it meant something.\"\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(categories[y[0]])\n",
    "print('------------------------------------------')\n",
    "X[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using TfidfVectorizer\n",
    "* All classifiers are tested against 20 news groups using TfidfVectorizer().\n",
    "* The dataset is vectorized into binary n-grams of lengths 1 to 3 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3803x1039787 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2279387 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), binary=False, use_idf=False, norm=None)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.91863517 0.93700787 0.91863517 0.91578947 0.89736842 0.90789474\n",
      " 0.92894737 0.90263158 0.93684211 0.91052632]\n",
      " \n",
      "Mean Accuracy:  0.9174278215223097\n",
      "Mean Fit Time:  0.2799067974090576\n",
      "Mean Score Time:  0.15270018577575684\n",
      "CV Time:  2.681272029876709\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.91338583 0.93963255 0.92650919 0.91578947 0.90789474 0.91052632\n",
      " 0.92631579 0.91842105 0.92368421 0.91842105]\n",
      " \n",
      "Mean Accuracy:  0.9200580190634066\n",
      "Mean Fit Time:  5.074514555931091\n",
      "Mean Score Time:  1.1157909631729126\n",
      "CV Time:  10.842615127563477\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90026247 0.9343832  0.92125984 0.92105263 0.89473684 0.91052632\n",
      " 0.92631579 0.90526316 0.92368421 0.90789474]\n",
      " \n",
      "Mean Accuracy:  0.9145379196021551\n",
      "Mean Fit Time:  6.59239935874939\n",
      "Mean Score Time:  0.7086002349853515\n",
      "CV Time:  12.201999187469482\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90288714 0.92650919 0.92913386 0.90789474 0.91052632 0.92368421\n",
      " 0.92894737 0.91578947 0.93157895 0.92894737]\n",
      " \n",
      "Mean Accuracy:  0.9205898604779665\n",
      "Mean Fit Time:  0.7887038946151733\n",
      "Mean Score Time:  0.09849801063537597\n",
      "CV Time:  1.6339988708496094\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90026247 0.88451444 0.89238845 0.90526316 0.89210526 0.90263158\n",
      " 0.88947368 0.88684211 0.92368421 0.88947368]\n",
      " \n",
      "Mean Accuracy:  0.8966639038541236\n",
      "Mean Fit Time:  1.9100080013275147\n",
      "Mean Score Time:  0.09479501247406005\n",
      "CV Time:  3.2320022583007812\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.62729659 0.66404199 0.65091864 0.64736842 0.67631579 0.69736842\n",
      " 0.71315789 0.66052632 0.68157895 0.66315789]\n",
      " \n",
      "Mean Accuracy:  0.6681730902058295\n",
      "Mean Fit Time:  5.324421858787536\n",
      "Mean Score Time:  4.463149666786194\n",
      "CV Time:  16.311115980148315\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90813648 0.92650919 0.93175853 0.93157895 0.90789474 0.92105263\n",
      " 0.92368421 0.92894737 0.93421053 0.91578947]\n",
      " \n",
      "Mean Accuracy:  0.9229562094211907\n",
      "Mean Fit Time:  53.73234751224518\n",
      "Mean Score Time:  0.0270031213760376\n",
      "CV Time:  78.8016266822815\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.88976378 0.92388451 0.92388451 0.92631579 0.90526316 0.92105263\n",
      " 0.91842105 0.91052632 0.93684211 0.91578947]\n",
      " \n",
      "Mean Accuracy:  0.917174333471474\n",
      "Mean Fit Time:  560.2967879533768\n",
      "Mean Score Time:  0.11859939098358155\n",
      "CV Time:  831.9404053688049\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using MinhashVectorizer @ 50\n",
    "* All classifiers are tested against the MinhashVectorizer() with a signature_length == 50\n",
    "* The dataset is vectorized into n-grams of lengths 1 to 3 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3803x92110 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 190139 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv50 = MinhashVectorizer(signature_length=50, analyzer='word', ngram_range=(1,3), binary=False, use_idf=False, norm=None)\n",
    "X_mhv50 = mhv50.fit_transform(X)\n",
    "X_mhv50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.88188976 0.84776903 0.90288714 0.87631579 0.85       0.88947368\n",
      " 0.87105263 0.84210526 0.90263158 0.86842105]\n",
      " \n",
      "Mean Accuracy:  0.873254593175853\n",
      "Mean Fit Time:  0.029696154594421386\n",
      "Mean Score Time:  0.017649579048156738\n",
      "CV Time:  1.976628065109253\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.87926509 0.88976378 0.90026247 0.90263158 0.87368421 0.89736842\n",
      " 0.87631579 0.86578947 0.90263158 0.88421053]\n",
      " \n",
      "Mean Accuracy:  0.8871922917530046\n",
      "Mean Fit Time:  0.4137131690979004\n",
      "Mean Score Time:  0.10207176208496094\n",
      "CV Time:  0.9014890193939209\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.87401575 0.86351706 0.89501312 0.87631579 0.85789474 0.88421053\n",
      " 0.86052632 0.84473684 0.90263158 0.85      ]\n",
      " \n",
      "Mean Accuracy:  0.8708861721232214\n",
      "Mean Fit Time:  0.4416168689727783\n",
      "Mean Score Time:  0.060761332511901855\n",
      "CV Time:  0.8957390785217285\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.83727034 0.8687664  0.87401575 0.85526316 0.86315789 0.86052632\n",
      " 0.83947368 0.86052632 0.87631579 0.86578947]\n",
      " \n",
      "Mean Accuracy:  0.8601105125017268\n",
      "Mean Fit Time:  0.06540050506591796\n",
      "Mean Score Time:  0.00819857120513916\n",
      "CV Time:  0.15800094604492188\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.81627297 0.78740157 0.80314961 0.82105263 0.79736842 0.82894737\n",
      " 0.80263158 0.76842105 0.85789474 0.81052632]\n",
      " \n",
      "Mean Accuracy:  0.8093666252244786\n",
      "Mean Fit Time:  0.13085200786590576\n",
      "Mean Score Time:  0.01045985221862793\n",
      "CV Time:  0.29556727409362793\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.49606299 0.5328084  0.55380577 0.51315789 0.53947368 0.57368421\n",
      " 0.50263158 0.52368421 0.53421053 0.53157895]\n",
      " \n",
      "Mean Accuracy:  0.5301098217985909\n",
      "Mean Fit Time:  1.5993009805679321\n",
      "Mean Score Time:  0.11763899326324463\n",
      "CV Time:  3.108259677886963\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.8503937  0.86614173 0.87926509 0.87894737 0.85       0.87894737\n",
      " 0.86578947 0.84210526 0.88684211 0.87105263]\n",
      " \n",
      "Mean Accuracy:  0.86694847354607\n",
      "Mean Fit Time:  9.389935159683228\n",
      "Mean Score Time:  0.0032022714614868162\n",
      "CV Time:  13.544325351715088\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.82152231 0.84514436 0.84514436 0.84210526 0.82894737 0.86052632\n",
      " 0.81052632 0.80263158 0.86052632 0.84736842]\n",
      " \n",
      "Mean Accuracy:  0.8364442602569415\n",
      "Mean Fit Time:  52.131214189529416\n",
      "Mean Score Time:  0.0199021577835083\n",
      "CV Time:  76.73734188079834\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_mhv50, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using MinhashVectorizer @ 100\n",
    "* All classifiers are tested against the MinhashVectorizer() with a signature_length == 100\n",
    "* The dataset is vectorized into n-grams of lengths 1 to 3 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3803x182842 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 379356 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv100 = MinhashVectorizer(signature_length=100, analyzer='word', ngram_range=(1,3), binary=False, use_idf=False, norm=None)\n",
    "X_mhv100 = mhv100.fit_transform(X)\n",
    "X_mhv100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.88976378 0.90026247 0.9160105  0.90526316 0.89210526 0.90263158\n",
      " 0.90526316 0.89736842 0.91578947 0.9       ]\n",
      " \n",
      "Mean Accuracy:  0.9024457798038403\n",
      "Mean Fit Time:  0.048397946357727054\n",
      "Mean Score Time:  0.02590792179107666\n",
      "CV Time:  0.1571044921875\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.89501312 0.91863517 0.92388451 0.92631579 0.9        0.91578947\n",
      " 0.90526316 0.90263158 0.91842105 0.92631579]\n",
      " \n",
      "Mean Accuracy:  0.9132269650504213\n",
      "Mean Fit Time:  0.8808829545974731\n",
      "Mean Score Time:  0.18002753257751464\n",
      "CV Time:  1.8376317024230957\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.87664042 0.90813648 0.9160105  0.91052632 0.88684211 0.9\n",
      " 0.90789474 0.89736842 0.90789474 0.89473684]\n",
      " \n",
      "Mean Accuracy:  0.900605055946954\n",
      "Mean Fit Time:  0.9504050493240357\n",
      "Mean Score Time:  0.11810381412506103\n",
      "CV Time:  1.9050369262695312\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.86089239 0.89238845 0.8976378  0.89473684 0.89210526 0.89210526\n",
      " 0.90526316 0.89210526 0.89473684 0.90263158]\n",
      " \n",
      "Mean Accuracy:  0.8924602845696918\n",
      "Mean Fit Time:  0.13945183753967286\n",
      "Mean Score Time:  0.015762019157409667\n",
      "CV Time:  0.28870391845703125\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.80839895 0.8687664  0.79002625 0.83684211 0.85526316 0.87368421\n",
      " 0.85263158 0.82894737 0.86315789 0.86315789]\n",
      " \n",
      "Mean Accuracy:  0.8440875811576184\n",
      "Mean Fit Time:  0.2852082967758179\n",
      "Mean Score Time:  0.01759331226348877\n",
      "CV Time:  0.5030012130737305\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.58267717 0.59055118 0.57742782 0.58684211 0.56315789 0.67894737\n",
      " 0.58421053 0.59210526 0.61842105 0.56315789]\n",
      " \n",
      "Mean Accuracy:  0.593749827324216\n",
      "Mean Fit Time:  1.8838977336883544\n",
      "Mean Score Time:  0.632204246520996\n",
      "CV Time:  4.478461503982544\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.87139108 0.88976378 0.90288714 0.89210526 0.88684211 0.91578947\n",
      " 0.91315789 0.88157895 0.90789474 0.89210526]\n",
      " \n",
      "Mean Accuracy:  0.8953515678961181\n",
      "Mean Fit Time:  20.57378234863281\n",
      "Mean Score Time:  0.004606437683105469\n",
      "CV Time:  28.6807541847229\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.832021   0.88713911 0.87664042 0.87368421 0.86052632 0.88684211\n",
      " 0.88947368 0.85263158 0.89736842 0.86315789]\n",
      " \n",
      "Mean Accuracy:  0.8719484735460699\n",
      "Mean Fit Time:  99.65672781467438\n",
      "Mean Score Time:  0.026778030395507812\n",
      "CV Time:  147.93687438964844\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_mhv100, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using MinhashVectorizer @ 250\n",
    "* All classifiers are tested against the MinhashVectorizer() with a signature_length == 250\n",
    "* The dataset is vectorized into n-grams of lengths 1 to 3 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3803x412905 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 893857 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from StrandPy import MinhashVectorizer\n",
    "mhv250 = MinhashVectorizer(signature_length=250, analyzer='word', ngram_range=(1,3), binary=False, use_idf=False, norm=None)\n",
    "X_mhv250 = mhv250.fit_transform(X)\n",
    "X_mhv250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.91863517 0.91863517 0.91338583 0.92105263 0.91315789 0.92368421\n",
      " 0.91052632 0.90526316 0.92894737 0.91842105]\n",
      " \n",
      "Mean Accuracy:  0.9171708799557952\n",
      "Mean Fit Time:  0.10983107089996338\n",
      "Mean Score Time:  0.05470883846282959\n",
      "CV Time:  0.33112239837646484\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.91076115 0.92650919 0.91338583 0.92368421 0.90789474 0.92894737\n",
      " 0.93684211 0.90789474 0.92631579 0.92368421]\n",
      " \n",
      "Mean Accuracy:  0.920591932587374\n",
      "Mean Fit Time:  2.0541253328323363\n",
      "Mean Score Time:  0.42420387268066406\n",
      "CV Time:  4.283662796020508\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90026247 0.9160105  0.91076115 0.92105263 0.91052632 0.92631579\n",
      " 0.91842105 0.9        0.92368421 0.91578947]\n",
      " \n",
      "Mean Accuracy:  0.9142823594419118\n",
      "Mean Fit Time:  2.316996955871582\n",
      "Mean Score Time:  0.2872056245803833\n",
      "CV Time:  4.503997802734375\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.89501312 0.91076115 0.9160105  0.91842105 0.90526316 0.92105263\n",
      " 0.91052632 0.90789474 0.91315789 0.91315789]\n",
      " \n",
      "Mean Accuracy:  0.9111258461113415\n",
      "Mean Fit Time:  0.3156043767929077\n",
      "Mean Score Time:  0.03929765224456787\n",
      "CV Time:  0.6230003833770752\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.8503937  0.91076115 0.88713911 0.88684211 0.87105263 0.89473684\n",
      " 0.87894737 0.88947368 0.90263158 0.88157895]\n",
      " \n",
      "Mean Accuracy:  0.8853557121149329\n",
      "Mean Fit Time:  0.7054033517837525\n",
      "Mean Score Time:  0.041598272323608396\n",
      "CV Time:  1.154998540878296\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.59580052 0.60892388 0.63254593 0.55526316 0.63684211 0.70526316\n",
      " 0.61842105 0.61052632 0.65       0.58684211]\n",
      " \n",
      "Mean Accuracy:  0.6200428235944192\n",
      "Mean Fit Time:  2.9744497776031493\n",
      "Mean Score Time:  1.5242947578430175\n",
      "CV Time:  7.908731937408447\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.89501312 0.92388451 0.9160105  0.92631579 0.90526316 0.92894737\n",
      " 0.91052632 0.92631579 0.92368421 0.90526316]\n",
      " \n",
      "Mean Accuracy:  0.9161223925956625\n",
      "Mean Fit Time:  70.78196640014649\n",
      "Mean Score Time:  0.010900211334228516\n",
      "CV Time:  97.15157413482666\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.87139108 0.90288714 0.90026247 0.90789474 0.87368421 0.93157895\n",
      " 0.90789474 0.91578947 0.91578947 0.89210526]\n",
      " \n",
      "Mean Accuracy:  0.9019277524519962\n",
      "Mean Fit Time:  228.70537347793578\n",
      "Mean Score Time:  0.07089791297912598\n",
      "CV Time:  339.33192467689514\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_mhv250, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifiers using MinhashVectorizer @ 1000\n",
    "* All classifiers are tested against the MinhashVectorizer() with a signature_length == 1000\n",
    "* The dataset is vectorized into n-grams of lengths 1 to 3 which are counted.\n",
    "* No tfidf, normalization, or smoothing are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3803x794600 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1820342 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mhv1000 = MinhashVectorizer(signature_length=1000, analyzer='word', ngram_range=(1,3), binary=False, use_idf=False, norm=None)\n",
    "X_mhv1000 = mhv1000.fit_transform(X)\n",
    "X_mhv1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.91863517 0.93963255 0.9160105  0.91842105 0.91315789 0.91315789\n",
      " 0.92631579 0.91842105 0.93421053 0.92894737]\n",
      " \n",
      "Mean Accuracy:  0.9226909794170466\n",
      "Mean Fit Time:  0.231306791305542\n",
      "Mean Score Time:  0.10359866619110107\n",
      "CV Time:  0.7320041656494141\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90551181 0.9343832  0.91863517 0.92105263 0.91578947 0.91842105\n",
      " 0.92368421 0.92105263 0.93947368 0.92368421]\n",
      " \n",
      "Mean Accuracy:  0.9221688078463876\n",
      "Mean Fit Time:  4.1017955303192135\n",
      "Mean Score Time:  0.8934034585952759\n",
      "CV Time:  8.875982284545898\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90813648 0.94488189 0.92388451 0.91578947 0.91052632 0.91315789\n",
      " 0.92105263 0.91578947 0.92894737 0.91842105]\n",
      " \n",
      "Mean Accuracy:  0.9200587097665422\n",
      "Mean Fit Time:  5.352102923393249\n",
      "Mean Score Time:  0.6152001619338989\n",
      "CV Time:  10.059017896652222\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.91338583 0.92388451 0.92388451 0.93157895 0.90263158 0.92894737\n",
      " 0.92368421 0.91842105 0.93947368 0.93947368]\n",
      " \n",
      "Mean Accuracy:  0.9245365381958834\n",
      "Mean Fit Time:  0.629008674621582\n",
      "Mean Score Time:  0.07230179309844971\n",
      "CV Time:  1.2940003871917725\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90551181 0.90551181 0.87401575 0.85789474 0.88947368 0.89210526\n",
      " 0.90789474 0.91315789 0.91842105 0.90526316]\n",
      " \n",
      "Mean Accuracy:  0.896924989639453\n",
      "Mean Fit Time:  1.489511489868164\n",
      "Mean Score Time:  0.08219585418701172\n",
      "CV Time:  2.5059211254119873\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.65354331 0.65091864 0.6351706  0.62105263 0.65       0.68684211\n",
      " 0.68947368 0.7        0.68421053 0.67105263]\n",
      " \n",
      "Mean Accuracy:  0.6642264124879127\n",
      "Mean Fit Time:  4.177504825592041\n",
      "Mean Score Time:  3.7058963537216187\n",
      "CV Time:  13.557990312576294\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.90813648 0.92913386 0.92913386 0.92368421 0.91315789 0.92105263\n",
      " 0.91578947 0.92368421 0.93947368 0.91842105]\n",
      " \n",
      "Mean Accuracy:  0.9221667357369803\n",
      "Mean Fit Time:  57.37034296989441\n",
      "Mean Score Time:  0.02306821346282959\n",
      "CV Time:  81.81817722320557\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.88976378 0.9160105  0.91863517 0.92368421 0.91052632 0.92105263\n",
      " 0.91578947 0.91842105 0.93157895 0.91842105]\n",
      " \n",
      "Mean Accuracy:  0.9163883133029425\n",
      "Mean Fit Time:  442.2782554864883\n",
      "Mean Score Time:  0.11185970306396484\n",
      "CV Time:  658.8238625526428\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_mhv1000, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CVFE to Find the Best Combined Features\n",
    "* Below we see that after using StrandPy's MinhashVectorizer the 20 newsgroups dataset contains:\n",
    " * 3803 rows\n",
    " * 415,924 columns \n",
    " * 893,857 stored elements\n",
    " * This dataset achieves 90.24% accuracy during 3-fold cross validation\n",
    "* StrandPy's CVFE tool is used to reduce the dataset above to:\n",
    " * 3803 rows\n",
    " * 1,344 columns \n",
    " * 14,381 stored elements \n",
    " * This dataset now achieves **97.13% accuracy** during 3-fold cross validation\n",
    "* In this example, we use CVFE's preserve_increases=True parameter to favor accuracy over the largest possbile reduction in features. \n",
    "* When CVFE's preserve_increases parameter is set to False, more features would be removed while only maintaining the original cross validation baseline accruacy of 90.24%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3803x415924 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 893857 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mhv250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.89905363 0.90378549 0.90449882]\n",
      " \n",
      "Mean Accuracy:  0.9024459776067563\n",
      "Mean Fit Time:  0.06402309735616048\n",
      "Mean Score Time:  0.04797593752543131\n",
      "CV Time:  0.15399742126464844\n"
     ]
    }
   ],
   "source": [
    "# StandPy Tools \n",
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "stratified_cross_validate(strand, X_mhv250, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "# Get feature importances\n",
    "strand = StrandSliceClassifier(feature_importances=True)\n",
    "strand.fit(X_mhv250,y)\n",
    "feature_importances = strand.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (3803, 415924)\n",
      "-----------------------------------------------------\n",
      "Remove Low Nonzero Features...\n",
      "X Shape: (3803, 415924)\n",
      "Current Base Score:  0.90744\n",
      "Step Features Removed:  315396\n",
      "Total Features Removed:  315396\n",
      "Cross Validations:  113\n",
      "-----------------------------------------------------\n",
      "Remove Features by Importances...\n",
      "X Shape: (3803, 100528)\n",
      "Current Base Score:  0.94084\n",
      "Step Features Removed:  16808\n",
      "Total Features Removed:  332204\n",
      "Cross Validations:  251\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 83720)\n",
      "Current Base Score:  0.9432\n",
      "Step Features Removed:  10472\n",
      "Total Features Removed:  342676\n",
      "Cross Validations:  262\n",
      "Step size:  10464\n",
      "Step Blocks removed: 1.0007645259938838\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 73248)\n",
      "Current Base Score:  0.95214\n",
      "Step Features Removed:  13103\n",
      "Total Features Removed:  355779\n",
      "Cross Validations:  291\n",
      "Step size:  2615\n",
      "Step Blocks removed: 5.010707456978968\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 60145)\n",
      "Current Base Score:  0.96108\n",
      "Step Features Removed:  12549\n",
      "Total Features Removed:  368328\n",
      "Cross Validations:  384\n",
      "Step size:  652\n",
      "Step Blocks removed: 19.246932515337424\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 47596)\n",
      "Current Base Score:  0.96345\n",
      "Step Features Removed:  17658\n",
      "Total Features Removed:  385986\n",
      "Cross Validations:  678\n",
      "Step size:  162\n",
      "Step Blocks removed: 109.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 29938)\n",
      "Current Base Score:  0.96608\n",
      "Step Features Removed:  14079\n",
      "Total Features Removed:  400065\n",
      "Cross Validations:  1446\n",
      "Step size:  39\n",
      "Step Blocks removed: 361.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 15859)\n",
      "Current Base Score:  0.96713\n",
      "Step Features Removed:  9627\n",
      "Total Features Removed:  409692\n",
      "Cross Validations:  3429\n",
      "Step size:  8\n",
      "Step Blocks removed: 1203.375\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 6232)\n",
      "Current Base Score:  0.97134\n",
      "Step Features Removed:  4604\n",
      "Total Features Removed:  414296\n",
      "Cross Validations:  9661\n",
      "Step size:  1\n",
      "Step Blocks removed: 4604.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 1628)\n",
      "Current Base Score:  0.97134\n",
      "Step Features Removed:  266\n",
      "Total Features Removed:  414562\n",
      "Cross Validations:  11289\n",
      "Step size:  1\n",
      "Step Blocks removed: 266.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 1362)\n",
      "Current Base Score:  0.97134\n",
      "Step Features Removed:  16\n",
      "Total Features Removed:  414578\n",
      "Cross Validations:  12651\n",
      "Step size:  1\n",
      "Step Blocks removed: 16.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (3803, 1346)\n",
      "Current Base Score:  0.97134\n",
      "Step Features Removed:  2\n",
      "Total Features Removed:  414580\n",
      "Cross Validations:  13997\n",
      "Step size:  1\n",
      "Step Blocks removed: 2.0\n",
      "-----------------------------------------------------\n",
      "Final Base Score:  0.97134\n",
      "Total Features Removed:  414580\n",
      "Cross Validations:  15341\n",
      "Wall time: 7min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CVFE(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "     estimator=StrandSliceClassifier(feature_importances=False,\n",
       "                                     noise_thresh=None),\n",
       "     feature_importances=array([0.07929676, 0.07179487, 0.07155067, ..., 0.07161804, 0.07161804,\n",
       "       0.07161804]),\n",
       "     min_step_size=1, n_jobs=-1, preserve_increases=True, scoring='accuracy',\n",
       "     verbose=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "from StrandPy import CVFE\n",
    "# Sklean Tools \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create faster, no-feature_importances strand object \n",
    "strand = StrandSliceClassifier()\n",
    "\n",
    "# Use Sklearn's StratifiedKFold to manage cross validation\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Create CVFE object using feature_importances created earlier \n",
    "cvfe = CVFE(strand, cv, n_jobs=-1, min_step_size=1, scoring='accuracy',\n",
    "            preserve_increases=True, feature_importances=feature_importances, verbose=True)\n",
    "\n",
    "cvfe.fit(X_mhv250,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.97476341 0.96293375 0.97632202]\n",
      " \n",
      "Mean Accuracy:  0.971339727134732\n",
      "Mean Fit Time:  0.01000197728474935\n",
      "Mean Score Time:  0.014339288075764975\n",
      "CV Time:  0.03499555587768555\n"
     ]
    }
   ],
   "source": [
    "# StandPy Tools \n",
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "stratified_cross_validate(strand, X_mhv250_cvfe, y, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strand Vectorizer \n",
    "**The StrandVectorizer implements all MinhashVectorizer functionality and extends this tool to support both text and numeric data.**\n",
    "* StrandVectorizer bins numeric features in such a way to ensure that all feature bins are \"locality sensitive\".\n",
    "* This means that StrandVectorizer consistently maps continuous numeric features into bins ensuring that similar feature values map into the same bins.  \n",
    "* StrandVectorizer adds the \"trucate_to\" parameter giving users control of the bin sizes / sensitivity for each numeric field in the dataset.\n",
    "* It also processes categorical variables as well via one hot encoding.\n",
    "* Text variables are treated the same allowing users to provide a tokenization strategy prior to minhashing. \n",
    "* StrandVectorizer is highly sensitive to the data types within each dataset proecssed vectorizing each data type differently:\n",
    " * Numeric - Bins data based on the parameters provided by the user, then vectorizes as specified.\n",
    " * String - Tokenizes data based on the parameters provided by the user, then vectorizes as specified.\n",
    " * Categories - One hot encodes categorical data types, then vectorizes as specified.\n",
    "* After all features have been vectorized, minhashing and any other TfidfVectorizer transformation, may also be applied to the vectorized dataset. \n",
    "\n",
    "### Advantages Over Sklearn's TfidfVectorizer and StrandPy's MinhashVectorizer\n",
    "* Both Sklearn's TfidfVectorizer and StrandPy's MinhashVectorizer are designed to tokenize and process string data only. \n",
    "* The StrandVectorizer is a system and method to process a dataset with one or more text documents as column / features along side any number of numeric and categorical features.  \n",
    "* In addition, it provides all the features of the MinhashVectorizer adding a dimensionality reduction layer to the tool.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn's Breast Cancer Dataset\n",
    "**This is a dense dataset where every row and column has a value. In this dataset there are:**\n",
    "* 569 rows\n",
    "* 30 columns \n",
    "* 569 * 30 = 17,070 stored data elements\n",
    "* All data is encoded as a 64 bit floating point decimal (float64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (569, 30)\n",
      "target shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "ds = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(ds.data, columns=ds.feature_names)\n",
    "y = ds.target\n",
    "\n",
    "print('features shape:', X.shape) \n",
    "print('target shape:', y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upon inspecting individual fields, we can see that each feature has differing levels of precision.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \n",
       "0           0.27760          0.3001              0.14710         0.2419  \n",
       "1           0.07864          0.0869              0.07017         0.1812  \n",
       "2           0.15990          0.1974              0.12790         0.2069  \n",
       "3           0.28390          0.2414              0.10520         0.2597  \n",
       "4           0.13280          0.1980              0.10430         0.1809  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "X.iloc[0:5, 0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius error  texture error  perimeter error  area error  smoothness error  \\\n",
       "0        1.0950         0.9053            8.589      153.40          0.006399   \n",
       "1        0.5435         0.7339            3.398       74.08          0.005225   \n",
       "2        0.7456         0.7869            4.585       94.03          0.006150   \n",
       "3        0.4956         1.1560            3.445       27.23          0.009110   \n",
       "4        0.7572         0.7813            5.438       94.44          0.011490   \n",
       "\n",
       "   compactness error  concavity error  concave points error  symmetry error  \n",
       "0            0.04904          0.05373               0.01587         0.03003  \n",
       "1            0.01308          0.01860               0.01340         0.01389  \n",
       "2            0.04006          0.03832               0.02058         0.02250  \n",
       "3            0.07458          0.05661               0.01867         0.05963  \n",
       "4            0.02461          0.05688               0.01885         0.01756  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0:5, 10:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \n",
       "0             0.6656           0.7119                0.2654          0.4601  \n",
       "1             0.1866           0.2416                0.1860          0.2750  \n",
       "2             0.4245           0.4504                0.2430          0.3613  \n",
       "3             0.8663           0.6869                0.2575          0.6638  \n",
       "4             0.2050           0.4000                0.1625          0.2364  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0:5, 20:29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a base level accuracy for the dataset\n",
    "**Since Strand is a text classifier, it would treat each exact value in the dataset as a token and be unable to make accurate classifications without some transformation of the data.**\n",
    "* The RandomForestClassifier performs best on this dataset with a 10-fold cross validation accuracy of 94% in 1.02s\n",
    "* LogisticRegression also does well with a 10-fold cross validation accuracy of 94% in 0.093s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.002899837493896484\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.03399085998535156\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.002300572395324707\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.023999452590942383\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.0021003961563110353\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.02699875831604004\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.9122807  0.9122807  0.9122807  0.84210526 0.89473684 0.84210526\n",
      " 0.87719298 0.98245614 0.92982456 0.875     ]\n",
      " \n",
      "Mean Accuracy:  0.8980263157894737\n",
      "Mean Fit Time:  0.006303644180297852\n",
      "Mean Score Time:  0.0011988639831542968\n",
      "CV Time:  0.0330049991607666\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.49122807 0.94736842 0.96491228 0.73684211 0.64912281 0.80701754\n",
      " 0.94736842 0.70175439 0.94736842 0.76785714]\n",
      " \n",
      "Mean Accuracy:  0.7960839598997494\n",
      "Mean Fit Time:  0.003125\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.07201552391052246\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.94736842 0.98245614 0.96491228 0.87719298 0.94736842 0.94736842\n",
      " 0.94736842 0.94736842 0.92982456 1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9491228070175438\n",
      "Mean Fit Time:  0.5106701612472534\n",
      "Mean Score Time:  0.02809910774230957\n",
      "CV Time:  1.0265285968780518\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.87719298 0.9122807  0.96491228 0.84210526 0.9122807  0.89473684\n",
      " 0.87719298 0.96491228 0.94736842 0.91071429]\n",
      " \n",
      "Mean Accuracy:  0.9103696741854638\n",
      "Mean Fit Time:  0.05689802169799805\n",
      "Mean Score Time:  0.0014002799987792968\n",
      "CV Time:  0.11899709701538086\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.94736842 0.94736842 0.94736842 0.87719298 0.92982456 0.92982456\n",
      " 0.94736842 0.94736842 0.94736842 1.        ]\n",
      " \n",
      "Mean Accuracy:  0.9421052631578947\n",
      "Mean Fit Time:  0.045200562477111815\n",
      "Mean Score Time:  0.0019002437591552734\n",
      "CV Time:  0.0950009822845459\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strand Vectorizing the Breast Cancer Dataset\n",
    "* Here we arbitrarily set all 30 numeric column's truncate_to parameter to 10. \n",
    "* This creates a sparse matrix with:\n",
    " * 569 rows\n",
    " * 15,340 columns \n",
    " * 17,070 stored elements\n",
    "* Note that we have the same number of data elements as in the original dataset.\n",
    "* However, we have spread them across far feature columns going from 30 to 15,340\n",
    "* Currently we do not know, if this is an optimal number of feature bins to best isolate the dataset's target classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<569x15340 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17070 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from StrandPy import StrandVectorizer\n",
    "\n",
    "sv = StrandVectorizer(truncate_to=10,signature_length=None, analyzer='word', ngram_range=(1,1)\n",
    "                      , binary=False, use_idf=False, norm=None)\n",
    "X_sv = sv.fit_transform(X)\n",
    "X_sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Strand Vectorized Dataset for a Baseline Accuracy\n",
    "* This version of the Strand Vectorized dataset produces 73% accuracy during 10-fold cross validation. \n",
    "* Currently the Strand classifier is below the best classifiers tested which were at 94%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.73684211 0.84210526 0.77192982 0.71929825 0.68421053 0.64912281\n",
      " 0.73684211 0.71929825 0.75438596 0.71428571]\n",
      " \n",
      "Mean Accuracy:  0.7328320802005013\n",
      "Mean Fit Time:  0.0049000740051269535\n",
      "Mean Score Time:  0.004999995231628418\n",
      "CV Time:  0.03298640251159668\n"
     ]
    }
   ],
   "source": [
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stratified_cross_validate(strand, X_sv, y, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best truncate_to Parameters for the Breast Cancer Dataset\n",
    "**Below, I check each column for the best truncate_to parameters**\n",
    "* This process is experimental and took 37.1s\n",
    "* We can see when looking at each of the individual trun_parms that different values are required to find the best separation of the classes.\n",
    "* This is a feature that could easily be incorporated into the StrandVectorizer once it is perfected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 3, 3, 1, 4, 3, 2, 2, 2, 0, 5, 5, 4, 1, 5, 2, 0,\n",
       "       3, 2, 3, 3, 4, 3, 2, 5])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create one truncate parameter for each of the 30 continuous fields\n",
    "# Each value starts at 10 \n",
    "trun_parms = [10] * 30 \n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Test the trunc value for each column \n",
    "for c in range(30):\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        # Test possible truncate_to values for each individual column\n",
    "        trun_parms[c] = i\n",
    "        sv = StrandVectorizer(truncate_to=trun_parms,signature_length=None, analyzer='word', ngram_range=(1,1)\n",
    "                          , binary=False, use_idf=False, norm=None)\n",
    "        X_sv = sv.fit_transform(X)\n",
    "        # Perform cross validation to find the best value parameter for each column \n",
    "        estimator = StrandSliceClassifier()\n",
    "        scores.append(np.mean(cross_val_score(estimator, X_sv, y, cv=cv, n_jobs=-1, scoring='accuracy')))\n",
    "        \n",
    "    # Find the parm with the max score\n",
    "    best_parm = scores.index(max(scores))\n",
    "    #Use this parameter for this column\n",
    "    trun_parms[c] = best_parm \n",
    "    \n",
    "np.array(trun_parms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the New trun_parms During Cross Validation\n",
    "**Using these trun_parms with the StrandVectorizer increases cross validation accuracy to 94.03%.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<569x6802 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17070 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = StrandVectorizer(truncate_to=trun_parms,signature_length=None, analyzer='word', ngram_range=(1,1)\n",
    "                          , binary=False, use_idf=False, norm=None)\n",
    "X_sv = sv.fit_transform(X)\n",
    "X_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.96491228 0.96491228 0.98245614 0.87719298 0.89473684 0.98245614\n",
      " 0.92982456 0.92982456 0.89473684 0.98214286]\n",
      " \n",
      "Mean Accuracy:  0.9403195488721806\n",
      "Mean Fit Time:  0.0050013065338134766\n",
      "Mean Score Time:  0.0055992364883422855\n",
      "CV Time:  0.03600335121154785\n"
     ]
    }
   ],
   "source": [
    "stratified_cross_validate(strand, X_sv, y, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the CVFE tool to Eliminate Low Value Features\n",
    "* CVFE increases 10-fold cross validation to **98.06% accuracy** \n",
    "* The CVFE tool takes 15.2s to process the Strand Vectorized Breast Cancer Dataset.\n",
    "* The new CVFE dataset contains:\n",
    " * 569 rows\n",
    " * Feature columns are reduced from 6,802 to only 173 columns.\n",
    " * Stored elements are reduced from 17,070 to 454. \n",
    "* It appears that moving the Breast Cancer dataset into a Strand Vectorized feature space expands the 30 column dataset into well over 6,000 features.  \n",
    "* The StrandSliceClassifier is able to rapidly differentiate between the target classes with the highest degree of accuracy once the best features have been selected.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (569, 6802)\n",
      "-----------------------------------------------------\n",
      "Remove Low Nonzero Features...\n",
      "X Shape: (569, 6802)\n",
      "Current Base Score:  0.94032\n",
      "Step Features Removed:  5036\n",
      "Total Features Removed:  5036\n",
      "Cross Validations:  26\n",
      "-----------------------------------------------------\n",
      "Remove Features by Importances...\n",
      "X Shape: (569, 1766)\n",
      "Current Base Score:  0.97719\n",
      "Step Features Removed:  363\n",
      "Total Features Removed:  5399\n",
      "Cross Validations:  33\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 1403)\n",
      "Current Base Score:  0.98067\n",
      "Step Features Removed:  702\n",
      "Total Features Removed:  6101\n",
      "Cross Validations:  36\n",
      "Step size:  701\n",
      "Step Blocks removed: 1.0014265335235377\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 701)\n",
      "Current Base Score:  0.98067\n",
      "Step Features Removed:  5\n",
      "Total Features Removed:  6106\n",
      "Cross Validations:  41\n",
      "Step size:  174\n",
      "Step Blocks removed: 0.028735632183908046\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 696)\n",
      "Current Base Score:  0.98067\n",
      "Step Features Removed:  192\n",
      "Total Features Removed:  6298\n",
      "Cross Validations:  58\n",
      "Step size:  42\n",
      "Step Blocks removed: 4.571428571428571\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 504)\n",
      "Current Base Score:  0.98067\n",
      "Step Features Removed:  135\n",
      "Total Features Removed:  6433\n",
      "Cross Validations:  114\n",
      "Step size:  9\n",
      "Step Blocks removed: 15.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 369)\n",
      "Current Base Score:  0.98067\n",
      "Step Features Removed:  196\n",
      "Total Features Removed:  6629\n",
      "Cross Validations:  483\n",
      "Step size:  1\n",
      "Step Blocks removed: 196.0\n",
      "-----------------------------------------------------\n",
      "Final Base Score:  0.98067\n",
      "Total Features Removed:  6629\n",
      "Cross Validations:  656\n",
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CVFE(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "     estimator=StrandSliceClassifier(feature_importances=False,\n",
       "                                     noise_thresh=None),\n",
       "     feature_importances=array([0.2780112 , 0.31586267, 0.34166072, ..., 0.25117925, 0.74882075,\n",
       "       0.25117925]),\n",
       "     min_step_size=1, n_jobs=-1, preserve_increases=True, scoring='accuracy',\n",
       "     verbose=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "from StrandPy import CVFE\n",
    "# Sklean Tools \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Get feature importances\n",
    "strand = StrandSliceClassifier(feature_importances=True)\n",
    "strand.fit(X_sv,y)\n",
    "feature_importances = strand.feature_importances_\n",
    "\n",
    "# Create faster, no-feature_importances strand object \n",
    "strand = StrandSliceClassifier()\n",
    "\n",
    "# Use Sklearn's StratifiedKFold to manage cross validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Create CVFE object using feature_importances created earlier \n",
    "cvfe = CVFE(strand, cv, n_jobs=-1, min_step_size=1, scoring='accuracy',\n",
    "            preserve_increases=True, feature_importances=feature_importances, verbose=True)\n",
    "\n",
    "cvfe.fit(X_sv,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<569x173 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 454 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sv_cvfe = cvfe.transform(X_sv)\n",
    "X_sv_cvfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[1.         0.94736842 1.         1.         0.98245614 0.98245614\n",
      " 0.98245614 0.94736842 0.98245614 0.98214286]\n",
      " \n",
      "Mean Accuracy:  0.9806704260651629\n",
      "Mean Fit Time:  0.003201007843017578\n",
      "Mean Score Time:  0.004301881790161133\n",
      "CV Time:  0.031003475189208984\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "stratified_cross_validate(strand, X_sv_cvfe, y, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Final CVFE reduced Breast Cancer Dataset Using Other Classifiers\n",
    "* Observe that the other classifiers do not appear to perform well in the Strand Vectorized feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[1.         0.94736842 1.         1.         0.98245614 0.98245614\n",
      " 0.98245614 0.94736842 0.98245614 0.98214286]\n",
      " \n",
      "Mean Accuracy:  0.9806704260651629\n",
      "Mean Fit Time:  0.004687666893005371\n",
      "Mean Score Time:  0.007813715934753418\n",
      "CV Time:  1.790693998336792\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[1.         0.92982456 0.98245614 0.98245614 0.96491228 0.96491228\n",
      " 0.96491228 0.92982456 0.98245614 0.96428571]\n",
      " \n",
      "Mean Accuracy:  0.9666040100250626\n",
      "Mean Fit Time:  0.0031246662139892576\n",
      "Mean Score Time:  0.0015623331069946288\n",
      "CV Time:  0.015623331069946289\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[1.         0.92982456 0.98245614 0.98245614 0.96491228 0.96491228\n",
      " 0.96491228 0.92982456 0.98245614 0.96428571]\n",
      " \n",
      "Mean Accuracy:  0.9666040100250626\n",
      "Mean Fit Time:  0.0019997119903564452\n",
      "Mean Score Time:  0.000899648666381836\n",
      "CV Time:  0.03310418128967285\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.47368421 0.38596491 0.52631579 0.52631579 0.50877193 0.35087719\n",
      " 0.49122807 0.38596491 0.50877193 0.46428571]\n",
      " \n",
      "Mean Accuracy:  0.462218045112782\n",
      "Mean Fit Time:  0.0015996932983398438\n",
      "Mean Score Time:  0.0004004240036010742\n",
      "CV Time:  0.018999576568603516\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.77192982 0.80701754 0.84210526 0.9122807  0.80701754 0.80701754\n",
      " 0.73684211 0.84210526 0.87719298 0.80357143]\n",
      " \n",
      "Mean Accuracy:  0.8207080200501252\n",
      "Mean Fit Time:  0.0046882152557373045\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.06284403800964355\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.61403509 0.61403509 0.63157895 0.63157895 0.63157895 0.63157895\n",
      " 0.63157895 0.63157895 0.63157895 0.625     ]\n",
      " \n",
      "Mean Accuracy:  0.6274122807017544\n",
      "Mean Fit Time:  0.4039220094680786\n",
      "Mean Score Time:  0.023210906982421876\n",
      "CV Time:  0.8245813846588135\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.77192982 0.80701754 0.84210526 0.9122807  0.80701754 0.80701754\n",
      " 0.71929825 0.84210526 0.87719298 0.80357143]\n",
      " \n",
      "Mean Accuracy:  0.8189536340852129\n",
      "Mean Fit Time:  0.001563262939453125\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.018929719924926758\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.61403509 0.61403509 0.63157895 0.63157895 0.63157895 0.63157895\n",
      " 0.63157895 0.63157895 0.63157895 0.625     ]\n",
      " \n",
      "Mean Accuracy:  0.6274122807017544\n",
      "Mean Fit Time:  0.014065361022949219\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.031263113021850586\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X_sv_cvfe,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Likewise, the CVFE tool does not dramatically improve the performance of the other classifiers once the data is transformed into the Strand Vectorized feature space.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (569, 6802)\n",
      "-----------------------------------------------------\n",
      "Remove Low Nonzero Features...\n",
      "X Shape: (569, 6802)\n",
      "Current Base Score:  0.6292\n",
      "Step Features Removed:  5948\n",
      "Total Features Removed:  5948\n",
      "Cross Validations:  26\n",
      "-----------------------------------------------------\n",
      "Remove Features by Importances...\n",
      "X Shape: (569, 854)\n",
      "Current Base Score:  0.64151\n",
      "Step Features Removed:  629\n",
      "Total Features Removed:  6577\n",
      "Cross Validations:  27\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 225)\n",
      "Current Base Score:  0.65905\n",
      "Step Features Removed:  112\n",
      "Total Features Removed:  6689\n",
      "Cross Validations:  30\n",
      "Step size:  112\n",
      "Step Blocks removed: 1.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 113)\n",
      "Current Base Score:  0.69596\n",
      "Step Features Removed:  86\n",
      "Total Features Removed:  6775\n",
      "Cross Validations:  35\n",
      "Step size:  27\n",
      "Step Blocks removed: 3.185185185185185\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 27)\n",
      "Current Base Score:  0.70301\n",
      "Step Features Removed:  2\n",
      "Total Features Removed:  6777\n",
      "Cross Validations:  98\n",
      "Step size:  1\n",
      "Step Blocks removed: 2.0\n",
      "-----------------------------------------------------\n",
      "Final Base Score:  0.70301\n",
      "Total Features Removed:  6777\n",
      "Cross Validations:  123\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CVFE(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "     estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                      class_weight=None, criterion='gini',\n",
       "                                      max_depth=3, max_features='auto',\n",
       "                                      max_leaf_nodes=None, max_samples=None,\n",
       "                                      min_impurity_decrease=0.0,\n",
       "                                      min_impurity_split=None,\n",
       "                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                      min_weight_fraction_leaf=0.0,\n",
       "                                      n_estimators=200, n_jobs=None,\n",
       "                                      oob_score=False, random_state=42,\n",
       "                                      verbose=0, warm_start=False),\n",
       "     feature_importances=array([0.00697188, 0.01031996, 0.01377781, ..., 0.        , 0.0006246 ,\n",
       "       0.        ]),\n",
       "     min_step_size=1, n_jobs=-1, preserve_increases=True, scoring='accuracy',\n",
       "     verbose=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "from StrandPy import CVFE\n",
    "# Sklean Tools \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# We create no feature importances for Random Forest since they are created \n",
    "# regardless during any call to fit.  This will make the CVFE tool run \n",
    "# longer than it would, if the feature_importances could be turned on and off.\n",
    "\n",
    "# Get feature importances\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=42)\n",
    "rf.fit(X_sv,y)\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Use Sklearn's StratifiedKFold to manage cross validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Create CVFE object using feature_importances created earlier \n",
    "cvfe = CVFE(rf, cv, n_jobs=-1, min_step_size=1, scoring='accuracy',\n",
    "            preserve_increases=True, feature_importances=feature_importances, verbose=True)\n",
    "\n",
    "cvfe.fit(X_sv,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (569, 30)\n",
      "target shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "ds = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(ds.data, columns=ds.feature_names)\n",
    "y = ds.target\n",
    "\n",
    "print('features shape:', X.shape) \n",
    "print('target shape:', y.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, the results below show that:**\n",
    "* When the CVFE tool is applied to the original breast cancer dataset, it removes a total of 7 features. \n",
    "* This brings the cross validation performance of the RandomForestClassifier up to 95.43% from the original baseline of 94.91%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (569, 30)\n",
      "-----------------------------------------------------\n",
      "Remove Low Nonzero Features...\n",
      "Remove Features by Importances...\n",
      "X Shape: (569, 30)\n",
      "Current Base Score:  0.94912\n",
      "Step Features Removed:  2\n",
      "Total Features Removed:  2\n",
      "Cross Validations:  19\n",
      "Step size:  2\n",
      "Step Blocks removed: 1.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 28)\n",
      "Current Base Score:  0.95263\n",
      "Step Features Removed:  4\n",
      "Total Features Removed:  6\n",
      "Cross Validations:  47\n",
      "Step size:  1\n",
      "Step Blocks removed: 4.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (569, 24)\n",
      "Current Base Score:  0.95439\n",
      "Step Features Removed:  1\n",
      "Total Features Removed:  7\n",
      "Cross Validations:  71\n",
      "Step size:  1\n",
      "Step Blocks removed: 1.0\n",
      "-----------------------------------------------------\n",
      "Final Base Score:  0.95439\n",
      "Total Features Removed:  7\n",
      "Cross Validations:  94\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CVFE(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "     estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                      class_weight=None, criterion='gini',\n",
       "                                      max_depth=3, max_features='auto',\n",
       "                                      max_leaf_nodes=None, max_samples=None,\n",
       "                                      min_impurity_decrease=0.0,\n",
       "                                      min_impurity_split=None,\n",
       "                                      min_samples_leaf=1, min_samples_split=2,\n",
       "                                      min_weight_fraction_leaf=0.0,...\n",
       "       0.01215635, 0.0558037 , 0.10896174, 0.00129531, 0.00153071,\n",
       "       0.01289385, 0.00234503, 0.00569321, 0.02943147, 0.00129111,\n",
       "       0.00150723, 0.00261627, 0.0040772 , 0.00099453, 0.00136154,\n",
       "       0.07666241, 0.00905991, 0.16112714, 0.13878205, 0.00875322,\n",
       "       0.01488052, 0.04107773, 0.12528089, 0.00522418, 0.00333137]),\n",
       "     min_step_size=1, n_jobs=-1, preserve_increases=True, scoring='accuracy',\n",
       "     verbose=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "from StrandPy import CVFE\n",
    "# Sklean Tools \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "X = csc_matrix(X)\n",
    "\n",
    "# Get feature importances\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=42)\n",
    "rf.fit(X,y)\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Use Sklearn's StratifiedKFold to manage cross validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Create CVFE object using feature_importances created earlier \n",
    "cvfe = CVFE(rf, cv, n_jobs=-1, min_step_size=1, scoring='accuracy',\n",
    "            preserve_increases=True, feature_importances=feature_importances, verbose=True)\n",
    "\n",
    "cvfe.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Sklearn's Labeled Faces on the Web Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (2489, 1850)\n",
      "target shape: (2489,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "# only load people that have N or more examples in the dataset\n",
    "ds = fetch_lfw_people(min_faces_per_person=20, resize=0.4) \n",
    "X = pd.DataFrame(ds.data)\n",
    "y = ds.target\n",
    "\n",
    "print('features shape:', X.shape) \n",
    "print('target shape:', y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2489 entries, 0 to 2488\n",
      "Data columns (total 1850 columns):\n",
      " #    Column  Dtype  \n",
      "---   ------  -----  \n",
      " 0    0       float32\n",
      " 1    1       float32\n",
      " 2    2       float32\n",
      " 3    3       float32\n",
      " 4    4       float32\n",
      " 5    5       float32\n",
      " 6    6       float32\n",
      " 7    7       float32\n",
      " 8    8       float32\n",
      " 9    9       float32\n",
      " 10   10      float32\n",
      " 11   11      float32\n",
      " 12   12      float32\n",
      " 13   13      float32\n",
      " 14   14      float32\n",
      " 15   15      float32\n",
      " 16   16      float32\n",
      " 17   17      float32\n",
      " 18   18      float32\n",
      " 19   19      float32\n",
      " 20   20      float32\n",
      " 21   21      float32\n",
      " 22   22      float32\n",
      " 23   23      float32\n",
      " 24   24      float32\n",
      " 25   25      float32\n",
      " 26   26      float32\n",
      " 27   27      float32\n",
      " 28   28      float32\n",
      " 29   29      float32\n",
      " 30   30      float32\n",
      " 31   31      float32\n",
      " 32   32      float32\n",
      " 33   33      float32\n",
      " 34   34      float32\n",
      " 35   35      float32\n",
      " 36   36      float32\n",
      " 37   37      float32\n",
      " 38   38      float32\n",
      " 39   39      float32\n",
      " 40   40      float32\n",
      " 41   41      float32\n",
      " 42   42      float32\n",
      " 43   43      float32\n",
      " 44   44      float32\n",
      " 45   45      float32\n",
      " 46   46      float32\n",
      " 47   47      float32\n",
      " 48   48      float32\n",
      " 49   49      float32\n",
      " 50   50      float32\n",
      " 51   51      float32\n",
      " 52   52      float32\n",
      " 53   53      float32\n",
      " 54   54      float32\n",
      " 55   55      float32\n",
      " 56   56      float32\n",
      " 57   57      float32\n",
      " 58   58      float32\n",
      " 59   59      float32\n",
      " 60   60      float32\n",
      " 61   61      float32\n",
      " 62   62      float32\n",
      " 63   63      float32\n",
      " 64   64      float32\n",
      " 65   65      float32\n",
      " 66   66      float32\n",
      " 67   67      float32\n",
      " 68   68      float32\n",
      " 69   69      float32\n",
      " 70   70      float32\n",
      " 71   71      float32\n",
      " 72   72      float32\n",
      " 73   73      float32\n",
      " 74   74      float32\n",
      " 75   75      float32\n",
      " 76   76      float32\n",
      " 77   77      float32\n",
      " 78   78      float32\n",
      " 79   79      float32\n",
      " 80   80      float32\n",
      " 81   81      float32\n",
      " 82   82      float32\n",
      " 83   83      float32\n",
      " 84   84      float32\n",
      " 85   85      float32\n",
      " 86   86      float32\n",
      " 87   87      float32\n",
      " 88   88      float32\n",
      " 89   89      float32\n",
      " 90   90      float32\n",
      " 91   91      float32\n",
      " 92   92      float32\n",
      " 93   93      float32\n",
      " 94   94      float32\n",
      " 95   95      float32\n",
      " 96   96      float32\n",
      " 97   97      float32\n",
      " 98   98      float32\n",
      " 99   99      float32\n",
      " 100  100     float32\n",
      " 101  101     float32\n",
      " 102  102     float32\n",
      " 103  103     float32\n",
      " 104  104     float32\n",
      " 105  105     float32\n",
      " 106  106     float32\n",
      " 107  107     float32\n",
      " 108  108     float32\n",
      " 109  109     float32\n",
      " 110  110     float32\n",
      " 111  111     float32\n",
      " 112  112     float32\n",
      " 113  113     float32\n",
      " 114  114     float32\n",
      " 115  115     float32\n",
      " 116  116     float32\n",
      " 117  117     float32\n",
      " 118  118     float32\n",
      " 119  119     float32\n",
      " 120  120     float32\n",
      " 121  121     float32\n",
      " 122  122     float32\n",
      " 123  123     float32\n",
      " 124  124     float32\n",
      " 125  125     float32\n",
      " 126  126     float32\n",
      " 127  127     float32\n",
      " 128  128     float32\n",
      " 129  129     float32\n",
      " 130  130     float32\n",
      " 131  131     float32\n",
      " 132  132     float32\n",
      " 133  133     float32\n",
      " 134  134     float32\n",
      " 135  135     float32\n",
      " 136  136     float32\n",
      " 137  137     float32\n",
      " 138  138     float32\n",
      " 139  139     float32\n",
      " 140  140     float32\n",
      " 141  141     float32\n",
      " 142  142     float32\n",
      " 143  143     float32\n",
      " 144  144     float32\n",
      " 145  145     float32\n",
      " 146  146     float32\n",
      " 147  147     float32\n",
      " 148  148     float32\n",
      " 149  149     float32\n",
      " 150  150     float32\n",
      " 151  151     float32\n",
      " 152  152     float32\n",
      " 153  153     float32\n",
      " 154  154     float32\n",
      " 155  155     float32\n",
      " 156  156     float32\n",
      " 157  157     float32\n",
      " 158  158     float32\n",
      " 159  159     float32\n",
      " 160  160     float32\n",
      " 161  161     float32\n",
      " 162  162     float32\n",
      " 163  163     float32\n",
      " 164  164     float32\n",
      " 165  165     float32\n",
      " 166  166     float32\n",
      " 167  167     float32\n",
      " 168  168     float32\n",
      " 169  169     float32\n",
      " 170  170     float32\n",
      " 171  171     float32\n",
      " 172  172     float32\n",
      " 173  173     float32\n",
      " 174  174     float32\n",
      " 175  175     float32\n",
      " 176  176     float32\n",
      " 177  177     float32\n",
      " 178  178     float32\n",
      " 179  179     float32\n",
      " 180  180     float32\n",
      " 181  181     float32\n",
      " 182  182     float32\n",
      " 183  183     float32\n",
      " 184  184     float32\n",
      " 185  185     float32\n",
      " 186  186     float32\n",
      " 187  187     float32\n",
      " 188  188     float32\n",
      " 189  189     float32\n",
      " 190  190     float32\n",
      " 191  191     float32\n",
      " 192  192     float32\n",
      " 193  193     float32\n",
      " 194  194     float32\n",
      " 195  195     float32\n",
      " 196  196     float32\n",
      " 197  197     float32\n",
      " 198  198     float32\n",
      " 199  199     float32\n",
      " 200  200     float32\n",
      " 201  201     float32\n",
      " 202  202     float32\n",
      " 203  203     float32\n",
      " 204  204     float32\n",
      " 205  205     float32\n",
      " 206  206     float32\n",
      " 207  207     float32\n",
      " 208  208     float32\n",
      " 209  209     float32\n",
      " 210  210     float32\n",
      " 211  211     float32\n",
      " 212  212     float32\n",
      " 213  213     float32\n",
      " 214  214     float32\n",
      " 215  215     float32\n",
      " 216  216     float32\n",
      " 217  217     float32\n",
      " 218  218     float32\n",
      " 219  219     float32\n",
      " 220  220     float32\n",
      " 221  221     float32\n",
      " 222  222     float32\n",
      " 223  223     float32\n",
      " 224  224     float32\n",
      " 225  225     float32\n",
      " 226  226     float32\n",
      " 227  227     float32\n",
      " 228  228     float32\n",
      " 229  229     float32\n",
      " 230  230     float32\n",
      " 231  231     float32\n",
      " 232  232     float32\n",
      " 233  233     float32\n",
      " 234  234     float32\n",
      " 235  235     float32\n",
      " 236  236     float32\n",
      " 237  237     float32\n",
      " 238  238     float32\n",
      " 239  239     float32\n",
      " 240  240     float32\n",
      " 241  241     float32\n",
      " 242  242     float32\n",
      " 243  243     float32\n",
      " 244  244     float32\n",
      " 245  245     float32\n",
      " 246  246     float32\n",
      " 247  247     float32\n",
      " 248  248     float32\n",
      " 249  249     float32\n",
      " 250  250     float32\n",
      " 251  251     float32\n",
      " 252  252     float32\n",
      " 253  253     float32\n",
      " 254  254     float32\n",
      " 255  255     float32\n",
      " 256  256     float32\n",
      " 257  257     float32\n",
      " 258  258     float32\n",
      " 259  259     float32\n",
      " 260  260     float32\n",
      " 261  261     float32\n",
      " 262  262     float32\n",
      " 263  263     float32\n",
      " 264  264     float32\n",
      " 265  265     float32\n",
      " 266  266     float32\n",
      " 267  267     float32\n",
      " 268  268     float32\n",
      " 269  269     float32\n",
      " 270  270     float32\n",
      " 271  271     float32\n",
      " 272  272     float32\n",
      " 273  273     float32\n",
      " 274  274     float32\n",
      " 275  275     float32\n",
      " 276  276     float32\n",
      " 277  277     float32\n",
      " 278  278     float32\n",
      " 279  279     float32\n",
      " 280  280     float32\n",
      " 281  281     float32\n",
      " 282  282     float32\n",
      " 283  283     float32\n",
      " 284  284     float32\n",
      " 285  285     float32\n",
      " 286  286     float32\n",
      " 287  287     float32\n",
      " 288  288     float32\n",
      " 289  289     float32\n",
      " 290  290     float32\n",
      " 291  291     float32\n",
      " 292  292     float32\n",
      " 293  293     float32\n",
      " 294  294     float32\n",
      " 295  295     float32\n",
      " 296  296     float32\n",
      " 297  297     float32\n",
      " 298  298     float32\n",
      " 299  299     float32\n",
      " 300  300     float32\n",
      " 301  301     float32\n",
      " 302  302     float32\n",
      " 303  303     float32\n",
      " 304  304     float32\n",
      " 305  305     float32\n",
      " 306  306     float32\n",
      " 307  307     float32\n",
      " 308  308     float32\n",
      " 309  309     float32\n",
      " 310  310     float32\n",
      " 311  311     float32\n",
      " 312  312     float32\n",
      " 313  313     float32\n",
      " 314  314     float32\n",
      " 315  315     float32\n",
      " 316  316     float32\n",
      " 317  317     float32\n",
      " 318  318     float32\n",
      " 319  319     float32\n",
      " 320  320     float32\n",
      " 321  321     float32\n",
      " 322  322     float32\n",
      " 323  323     float32\n",
      " 324  324     float32\n",
      " 325  325     float32\n",
      " 326  326     float32\n",
      " 327  327     float32\n",
      " 328  328     float32\n",
      " 329  329     float32\n",
      " 330  330     float32\n",
      " 331  331     float32\n",
      " 332  332     float32\n",
      " 333  333     float32\n",
      " 334  334     float32\n",
      " 335  335     float32\n",
      " 336  336     float32\n",
      " 337  337     float32\n",
      " 338  338     float32\n",
      " 339  339     float32\n",
      " 340  340     float32\n",
      " 341  341     float32\n",
      " 342  342     float32\n",
      " 343  343     float32\n",
      " 344  344     float32\n",
      " 345  345     float32\n",
      " 346  346     float32\n",
      " 347  347     float32\n",
      " 348  348     float32\n",
      " 349  349     float32\n",
      " 350  350     float32\n",
      " 351  351     float32\n",
      " 352  352     float32\n",
      " 353  353     float32\n",
      " 354  354     float32\n",
      " 355  355     float32\n",
      " 356  356     float32\n",
      " 357  357     float32\n",
      " 358  358     float32\n",
      " 359  359     float32\n",
      " 360  360     float32\n",
      " 361  361     float32\n",
      " 362  362     float32\n",
      " 363  363     float32\n",
      " 364  364     float32\n",
      " 365  365     float32\n",
      " 366  366     float32\n",
      " 367  367     float32\n",
      " 368  368     float32\n",
      " 369  369     float32\n",
      " 370  370     float32\n",
      " 371  371     float32\n",
      " 372  372     float32\n",
      " 373  373     float32\n",
      " 374  374     float32\n",
      " 375  375     float32\n",
      " 376  376     float32\n",
      " 377  377     float32\n",
      " 378  378     float32\n",
      " 379  379     float32\n",
      " 380  380     float32\n",
      " 381  381     float32\n",
      " 382  382     float32\n",
      " 383  383     float32\n",
      " 384  384     float32\n",
      " 385  385     float32\n",
      " 386  386     float32\n",
      " 387  387     float32\n",
      " 388  388     float32\n",
      " 389  389     float32\n",
      " 390  390     float32\n",
      " 391  391     float32\n",
      " 392  392     float32\n",
      " 393  393     float32\n",
      " 394  394     float32\n",
      " 395  395     float32\n",
      " 396  396     float32\n",
      " 397  397     float32\n",
      " 398  398     float32\n",
      " 399  399     float32\n",
      " 400  400     float32\n",
      " 401  401     float32\n",
      " 402  402     float32\n",
      " 403  403     float32\n",
      " 404  404     float32\n",
      " 405  405     float32\n",
      " 406  406     float32\n",
      " 407  407     float32\n",
      " 408  408     float32\n",
      " 409  409     float32\n",
      " 410  410     float32\n",
      " 411  411     float32\n",
      " 412  412     float32\n",
      " 413  413     float32\n",
      " 414  414     float32\n",
      " 415  415     float32\n",
      " 416  416     float32\n",
      " 417  417     float32\n",
      " 418  418     float32\n",
      " 419  419     float32\n",
      " 420  420     float32\n",
      " 421  421     float32\n",
      " 422  422     float32\n",
      " 423  423     float32\n",
      " 424  424     float32\n",
      " 425  425     float32\n",
      " 426  426     float32\n",
      " 427  427     float32\n",
      " 428  428     float32\n",
      " 429  429     float32\n",
      " 430  430     float32\n",
      " 431  431     float32\n",
      " 432  432     float32\n",
      " 433  433     float32\n",
      " 434  434     float32\n",
      " 435  435     float32\n",
      " 436  436     float32\n",
      " 437  437     float32\n",
      " 438  438     float32\n",
      " 439  439     float32\n",
      " 440  440     float32\n",
      " 441  441     float32\n",
      " 442  442     float32\n",
      " 443  443     float32\n",
      " 444  444     float32\n",
      " 445  445     float32\n",
      " 446  446     float32\n",
      " 447  447     float32\n",
      " 448  448     float32\n",
      " 449  449     float32\n",
      " 450  450     float32\n",
      " 451  451     float32\n",
      " 452  452     float32\n",
      " 453  453     float32\n",
      " 454  454     float32\n",
      " 455  455     float32\n",
      " 456  456     float32\n",
      " 457  457     float32\n",
      " 458  458     float32\n",
      " 459  459     float32\n",
      " 460  460     float32\n",
      " 461  461     float32\n",
      " 462  462     float32\n",
      " 463  463     float32\n",
      " 464  464     float32\n",
      " 465  465     float32\n",
      " 466  466     float32\n",
      " 467  467     float32\n",
      " 468  468     float32\n",
      " 469  469     float32\n",
      " 470  470     float32\n",
      " 471  471     float32\n",
      " 472  472     float32\n",
      " 473  473     float32\n",
      " 474  474     float32\n",
      " 475  475     float32\n",
      " 476  476     float32\n",
      " 477  477     float32\n",
      " 478  478     float32\n",
      " 479  479     float32\n",
      " 480  480     float32\n",
      " 481  481     float32\n",
      " 482  482     float32\n",
      " 483  483     float32\n",
      " 484  484     float32\n",
      " 485  485     float32\n",
      " 486  486     float32\n",
      " 487  487     float32\n",
      " 488  488     float32\n",
      " 489  489     float32\n",
      " 490  490     float32\n",
      " 491  491     float32\n",
      " 492  492     float32\n",
      " 493  493     float32\n",
      " 494  494     float32\n",
      " 495  495     float32\n",
      " 496  496     float32\n",
      " 497  497     float32\n",
      " 498  498     float32\n",
      " 499  499     float32\n",
      " 500  500     float32\n",
      " 501  501     float32\n",
      " 502  502     float32\n",
      " 503  503     float32\n",
      " 504  504     float32\n",
      " 505  505     float32\n",
      " 506  506     float32\n",
      " 507  507     float32\n",
      " 508  508     float32\n",
      " 509  509     float32\n",
      " 510  510     float32\n",
      " 511  511     float32\n",
      " 512  512     float32\n",
      " 513  513     float32\n",
      " 514  514     float32\n",
      " 515  515     float32\n",
      " 516  516     float32\n",
      " 517  517     float32\n",
      " 518  518     float32\n",
      " 519  519     float32\n",
      " 520  520     float32\n",
      " 521  521     float32\n",
      " 522  522     float32\n",
      " 523  523     float32\n",
      " 524  524     float32\n",
      " 525  525     float32\n",
      " 526  526     float32\n",
      " 527  527     float32\n",
      " 528  528     float32\n",
      " 529  529     float32\n",
      " 530  530     float32\n",
      " 531  531     float32\n",
      " 532  532     float32\n",
      " 533  533     float32\n",
      " 534  534     float32\n",
      " 535  535     float32\n",
      " 536  536     float32\n",
      " 537  537     float32\n",
      " 538  538     float32\n",
      " 539  539     float32\n",
      " 540  540     float32\n",
      " 541  541     float32\n",
      " 542  542     float32\n",
      " 543  543     float32\n",
      " 544  544     float32\n",
      " 545  545     float32\n",
      " 546  546     float32\n",
      " 547  547     float32\n",
      " 548  548     float32\n",
      " 549  549     float32\n",
      " 550  550     float32\n",
      " 551  551     float32\n",
      " 552  552     float32\n",
      " 553  553     float32\n",
      " 554  554     float32\n",
      " 555  555     float32\n",
      " 556  556     float32\n",
      " 557  557     float32\n",
      " 558  558     float32\n",
      " 559  559     float32\n",
      " 560  560     float32\n",
      " 561  561     float32\n",
      " 562  562     float32\n",
      " 563  563     float32\n",
      " 564  564     float32\n",
      " 565  565     float32\n",
      " 566  566     float32\n",
      " 567  567     float32\n",
      " 568  568     float32\n",
      " 569  569     float32\n",
      " 570  570     float32\n",
      " 571  571     float32\n",
      " 572  572     float32\n",
      " 573  573     float32\n",
      " 574  574     float32\n",
      " 575  575     float32\n",
      " 576  576     float32\n",
      " 577  577     float32\n",
      " 578  578     float32\n",
      " 579  579     float32\n",
      " 580  580     float32\n",
      " 581  581     float32\n",
      " 582  582     float32\n",
      " 583  583     float32\n",
      " 584  584     float32\n",
      " 585  585     float32\n",
      " 586  586     float32\n",
      " 587  587     float32\n",
      " 588  588     float32\n",
      " 589  589     float32\n",
      " 590  590     float32\n",
      " 591  591     float32\n",
      " 592  592     float32\n",
      " 593  593     float32\n",
      " 594  594     float32\n",
      " 595  595     float32\n",
      " 596  596     float32\n",
      " 597  597     float32\n",
      " 598  598     float32\n",
      " 599  599     float32\n",
      " 600  600     float32\n",
      " 601  601     float32\n",
      " 602  602     float32\n",
      " 603  603     float32\n",
      " 604  604     float32\n",
      " 605  605     float32\n",
      " 606  606     float32\n",
      " 607  607     float32\n",
      " 608  608     float32\n",
      " 609  609     float32\n",
      " 610  610     float32\n",
      " 611  611     float32\n",
      " 612  612     float32\n",
      " 613  613     float32\n",
      " 614  614     float32\n",
      " 615  615     float32\n",
      " 616  616     float32\n",
      " 617  617     float32\n",
      " 618  618     float32\n",
      " 619  619     float32\n",
      " 620  620     float32\n",
      " 621  621     float32\n",
      " 622  622     float32\n",
      " 623  623     float32\n",
      " 624  624     float32\n",
      " 625  625     float32\n",
      " 626  626     float32\n",
      " 627  627     float32\n",
      " 628  628     float32\n",
      " 629  629     float32\n",
      " 630  630     float32\n",
      " 631  631     float32\n",
      " 632  632     float32\n",
      " 633  633     float32\n",
      " 634  634     float32\n",
      " 635  635     float32\n",
      " 636  636     float32\n",
      " 637  637     float32\n",
      " 638  638     float32\n",
      " 639  639     float32\n",
      " 640  640     float32\n",
      " 641  641     float32\n",
      " 642  642     float32\n",
      " 643  643     float32\n",
      " 644  644     float32\n",
      " 645  645     float32\n",
      " 646  646     float32\n",
      " 647  647     float32\n",
      " 648  648     float32\n",
      " 649  649     float32\n",
      " 650  650     float32\n",
      " 651  651     float32\n",
      " 652  652     float32\n",
      " 653  653     float32\n",
      " 654  654     float32\n",
      " 655  655     float32\n",
      " 656  656     float32\n",
      " 657  657     float32\n",
      " 658  658     float32\n",
      " 659  659     float32\n",
      " 660  660     float32\n",
      " 661  661     float32\n",
      " 662  662     float32\n",
      " 663  663     float32\n",
      " 664  664     float32\n",
      " 665  665     float32\n",
      " 666  666     float32\n",
      " 667  667     float32\n",
      " 668  668     float32\n",
      " 669  669     float32\n",
      " 670  670     float32\n",
      " 671  671     float32\n",
      " 672  672     float32\n",
      " 673  673     float32\n",
      " 674  674     float32\n",
      " 675  675     float32\n",
      " 676  676     float32\n",
      " 677  677     float32\n",
      " 678  678     float32\n",
      " 679  679     float32\n",
      " 680  680     float32\n",
      " 681  681     float32\n",
      " 682  682     float32\n",
      " 683  683     float32\n",
      " 684  684     float32\n",
      " 685  685     float32\n",
      " 686  686     float32\n",
      " 687  687     float32\n",
      " 688  688     float32\n",
      " 689  689     float32\n",
      " 690  690     float32\n",
      " 691  691     float32\n",
      " 692  692     float32\n",
      " 693  693     float32\n",
      " 694  694     float32\n",
      " 695  695     float32\n",
      " 696  696     float32\n",
      " 697  697     float32\n",
      " 698  698     float32\n",
      " 699  699     float32\n",
      " 700  700     float32\n",
      " 701  701     float32\n",
      " 702  702     float32\n",
      " 703  703     float32\n",
      " 704  704     float32\n",
      " 705  705     float32\n",
      " 706  706     float32\n",
      " 707  707     float32\n",
      " 708  708     float32\n",
      " 709  709     float32\n",
      " 710  710     float32\n",
      " 711  711     float32\n",
      " 712  712     float32\n",
      " 713  713     float32\n",
      " 714  714     float32\n",
      " 715  715     float32\n",
      " 716  716     float32\n",
      " 717  717     float32\n",
      " 718  718     float32\n",
      " 719  719     float32\n",
      " 720  720     float32\n",
      " 721  721     float32\n",
      " 722  722     float32\n",
      " 723  723     float32\n",
      " 724  724     float32\n",
      " 725  725     float32\n",
      " 726  726     float32\n",
      " 727  727     float32\n",
      " 728  728     float32\n",
      " 729  729     float32\n",
      " 730  730     float32\n",
      " 731  731     float32\n",
      " 732  732     float32\n",
      " 733  733     float32\n",
      " 734  734     float32\n",
      " 735  735     float32\n",
      " 736  736     float32\n",
      " 737  737     float32\n",
      " 738  738     float32\n",
      " 739  739     float32\n",
      " 740  740     float32\n",
      " 741  741     float32\n",
      " 742  742     float32\n",
      " 743  743     float32\n",
      " 744  744     float32\n",
      " 745  745     float32\n",
      " 746  746     float32\n",
      " 747  747     float32\n",
      " 748  748     float32\n",
      " 749  749     float32\n",
      " 750  750     float32\n",
      " 751  751     float32\n",
      " 752  752     float32\n",
      " 753  753     float32\n",
      " 754  754     float32\n",
      " 755  755     float32\n",
      " 756  756     float32\n",
      " 757  757     float32\n",
      " 758  758     float32\n",
      " 759  759     float32\n",
      " 760  760     float32\n",
      " 761  761     float32\n",
      " 762  762     float32\n",
      " 763  763     float32\n",
      " 764  764     float32\n",
      " 765  765     float32\n",
      " 766  766     float32\n",
      " 767  767     float32\n",
      " 768  768     float32\n",
      " 769  769     float32\n",
      " 770  770     float32\n",
      " 771  771     float32\n",
      " 772  772     float32\n",
      " 773  773     float32\n",
      " 774  774     float32\n",
      " 775  775     float32\n",
      " 776  776     float32\n",
      " 777  777     float32\n",
      " 778  778     float32\n",
      " 779  779     float32\n",
      " 780  780     float32\n",
      " 781  781     float32\n",
      " 782  782     float32\n",
      " 783  783     float32\n",
      " 784  784     float32\n",
      " 785  785     float32\n",
      " 786  786     float32\n",
      " 787  787     float32\n",
      " 788  788     float32\n",
      " 789  789     float32\n",
      " 790  790     float32\n",
      " 791  791     float32\n",
      " 792  792     float32\n",
      " 793  793     float32\n",
      " 794  794     float32\n",
      " 795  795     float32\n",
      " 796  796     float32\n",
      " 797  797     float32\n",
      " 798  798     float32\n",
      " 799  799     float32\n",
      " 800  800     float32\n",
      " 801  801     float32\n",
      " 802  802     float32\n",
      " 803  803     float32\n",
      " 804  804     float32\n",
      " 805  805     float32\n",
      " 806  806     float32\n",
      " 807  807     float32\n",
      " 808  808     float32\n",
      " 809  809     float32\n",
      " 810  810     float32\n",
      " 811  811     float32\n",
      " 812  812     float32\n",
      " 813  813     float32\n",
      " 814  814     float32\n",
      " 815  815     float32\n",
      " 816  816     float32\n",
      " 817  817     float32\n",
      " 818  818     float32\n",
      " 819  819     float32\n",
      " 820  820     float32\n",
      " 821  821     float32\n",
      " 822  822     float32\n",
      " 823  823     float32\n",
      " 824  824     float32\n",
      " 825  825     float32\n",
      " 826  826     float32\n",
      " 827  827     float32\n",
      " 828  828     float32\n",
      " 829  829     float32\n",
      " 830  830     float32\n",
      " 831  831     float32\n",
      " 832  832     float32\n",
      " 833  833     float32\n",
      " 834  834     float32\n",
      " 835  835     float32\n",
      " 836  836     float32\n",
      " 837  837     float32\n",
      " 838  838     float32\n",
      " 839  839     float32\n",
      " 840  840     float32\n",
      " 841  841     float32\n",
      " 842  842     float32\n",
      " 843  843     float32\n",
      " 844  844     float32\n",
      " 845  845     float32\n",
      " 846  846     float32\n",
      " 847  847     float32\n",
      " 848  848     float32\n",
      " 849  849     float32\n",
      " 850  850     float32\n",
      " 851  851     float32\n",
      " 852  852     float32\n",
      " 853  853     float32\n",
      " 854  854     float32\n",
      " 855  855     float32\n",
      " 856  856     float32\n",
      " 857  857     float32\n",
      " 858  858     float32\n",
      " 859  859     float32\n",
      " 860  860     float32\n",
      " 861  861     float32\n",
      " 862  862     float32\n",
      " 863  863     float32\n",
      " 864  864     float32\n",
      " 865  865     float32\n",
      " 866  866     float32\n",
      " 867  867     float32\n",
      " 868  868     float32\n",
      " 869  869     float32\n",
      " 870  870     float32\n",
      " 871  871     float32\n",
      " 872  872     float32\n",
      " 873  873     float32\n",
      " 874  874     float32\n",
      " 875  875     float32\n",
      " 876  876     float32\n",
      " 877  877     float32\n",
      " 878  878     float32\n",
      " 879  879     float32\n",
      " 880  880     float32\n",
      " 881  881     float32\n",
      " 882  882     float32\n",
      " 883  883     float32\n",
      " 884  884     float32\n",
      " 885  885     float32\n",
      " 886  886     float32\n",
      " 887  887     float32\n",
      " 888  888     float32\n",
      " 889  889     float32\n",
      " 890  890     float32\n",
      " 891  891     float32\n",
      " 892  892     float32\n",
      " 893  893     float32\n",
      " 894  894     float32\n",
      " 895  895     float32\n",
      " 896  896     float32\n",
      " 897  897     float32\n",
      " 898  898     float32\n",
      " 899  899     float32\n",
      " 900  900     float32\n",
      " 901  901     float32\n",
      " 902  902     float32\n",
      " 903  903     float32\n",
      " 904  904     float32\n",
      " 905  905     float32\n",
      " 906  906     float32\n",
      " 907  907     float32\n",
      " 908  908     float32\n",
      " 909  909     float32\n",
      " 910  910     float32\n",
      " 911  911     float32\n",
      " 912  912     float32\n",
      " 913  913     float32\n",
      " 914  914     float32\n",
      " 915  915     float32\n",
      " 916  916     float32\n",
      " 917  917     float32\n",
      " 918  918     float32\n",
      " 919  919     float32\n",
      " 920  920     float32\n",
      " 921  921     float32\n",
      " 922  922     float32\n",
      " 923  923     float32\n",
      " 924  924     float32\n",
      " 925  925     float32\n",
      " 926  926     float32\n",
      " 927  927     float32\n",
      " 928  928     float32\n",
      " 929  929     float32\n",
      " 930  930     float32\n",
      " 931  931     float32\n",
      " 932  932     float32\n",
      " 933  933     float32\n",
      " 934  934     float32\n",
      " 935  935     float32\n",
      " 936  936     float32\n",
      " 937  937     float32\n",
      " 938  938     float32\n",
      " 939  939     float32\n",
      " 940  940     float32\n",
      " 941  941     float32\n",
      " 942  942     float32\n",
      " 943  943     float32\n",
      " 944  944     float32\n",
      " 945  945     float32\n",
      " 946  946     float32\n",
      " 947  947     float32\n",
      " 948  948     float32\n",
      " 949  949     float32\n",
      " 950  950     float32\n",
      " 951  951     float32\n",
      " 952  952     float32\n",
      " 953  953     float32\n",
      " 954  954     float32\n",
      " 955  955     float32\n",
      " 956  956     float32\n",
      " 957  957     float32\n",
      " 958  958     float32\n",
      " 959  959     float32\n",
      " 960  960     float32\n",
      " 961  961     float32\n",
      " 962  962     float32\n",
      " 963  963     float32\n",
      " 964  964     float32\n",
      " 965  965     float32\n",
      " 966  966     float32\n",
      " 967  967     float32\n",
      " 968  968     float32\n",
      " 969  969     float32\n",
      " 970  970     float32\n",
      " 971  971     float32\n",
      " 972  972     float32\n",
      " 973  973     float32\n",
      " 974  974     float32\n",
      " 975  975     float32\n",
      " 976  976     float32\n",
      " 977  977     float32\n",
      " 978  978     float32\n",
      " 979  979     float32\n",
      " 980  980     float32\n",
      " 981  981     float32\n",
      " 982  982     float32\n",
      " 983  983     float32\n",
      " 984  984     float32\n",
      " 985  985     float32\n",
      " 986  986     float32\n",
      " 987  987     float32\n",
      " 988  988     float32\n",
      " 989  989     float32\n",
      " 990  990     float32\n",
      " 991  991     float32\n",
      " 992  992     float32\n",
      " 993  993     float32\n",
      " 994  994     float32\n",
      " 995  995     float32\n",
      " 996  996     float32\n",
      " 997  997     float32\n",
      " 998  998     float32\n",
      " 999  999     float32\n",
      " 1000 1000    float32\n",
      " 1001 1001    float32\n",
      " 1002 1002    float32\n",
      " 1003 1003    float32\n",
      " 1004 1004    float32\n",
      " 1005 1005    float32\n",
      " 1006 1006    float32\n",
      " 1007 1007    float32\n",
      " 1008 1008    float32\n",
      " 1009 1009    float32\n",
      " 1010 1010    float32\n",
      " 1011 1011    float32\n",
      " 1012 1012    float32\n",
      " 1013 1013    float32\n",
      " 1014 1014    float32\n",
      " 1015 1015    float32\n",
      " 1016 1016    float32\n",
      " 1017 1017    float32\n",
      " 1018 1018    float32\n",
      " 1019 1019    float32\n",
      " 1020 1020    float32\n",
      " 1021 1021    float32\n",
      " 1022 1022    float32\n",
      " 1023 1023    float32\n",
      " 1024 1024    float32\n",
      " 1025 1025    float32\n",
      " 1026 1026    float32\n",
      " 1027 1027    float32\n",
      " 1028 1028    float32\n",
      " 1029 1029    float32\n",
      " 1030 1030    float32\n",
      " 1031 1031    float32\n",
      " 1032 1032    float32\n",
      " 1033 1033    float32\n",
      " 1034 1034    float32\n",
      " 1035 1035    float32\n",
      " 1036 1036    float32\n",
      " 1037 1037    float32\n",
      " 1038 1038    float32\n",
      " 1039 1039    float32\n",
      " 1040 1040    float32\n",
      " 1041 1041    float32\n",
      " 1042 1042    float32\n",
      " 1043 1043    float32\n",
      " 1044 1044    float32\n",
      " 1045 1045    float32\n",
      " 1046 1046    float32\n",
      " 1047 1047    float32\n",
      " 1048 1048    float32\n",
      " 1049 1049    float32\n",
      " 1050 1050    float32\n",
      " 1051 1051    float32\n",
      " 1052 1052    float32\n",
      " 1053 1053    float32\n",
      " 1054 1054    float32\n",
      " 1055 1055    float32\n",
      " 1056 1056    float32\n",
      " 1057 1057    float32\n",
      " 1058 1058    float32\n",
      " 1059 1059    float32\n",
      " 1060 1060    float32\n",
      " 1061 1061    float32\n",
      " 1062 1062    float32\n",
      " 1063 1063    float32\n",
      " 1064 1064    float32\n",
      " 1065 1065    float32\n",
      " 1066 1066    float32\n",
      " 1067 1067    float32\n",
      " 1068 1068    float32\n",
      " 1069 1069    float32\n",
      " 1070 1070    float32\n",
      " 1071 1071    float32\n",
      " 1072 1072    float32\n",
      " 1073 1073    float32\n",
      " 1074 1074    float32\n",
      " 1075 1075    float32\n",
      " 1076 1076    float32\n",
      " 1077 1077    float32\n",
      " 1078 1078    float32\n",
      " 1079 1079    float32\n",
      " 1080 1080    float32\n",
      " 1081 1081    float32\n",
      " 1082 1082    float32\n",
      " 1083 1083    float32\n",
      " 1084 1084    float32\n",
      " 1085 1085    float32\n",
      " 1086 1086    float32\n",
      " 1087 1087    float32\n",
      " 1088 1088    float32\n",
      " 1089 1089    float32\n",
      " 1090 1090    float32\n",
      " 1091 1091    float32\n",
      " 1092 1092    float32\n",
      " 1093 1093    float32\n",
      " 1094 1094    float32\n",
      " 1095 1095    float32\n",
      " 1096 1096    float32\n",
      " 1097 1097    float32\n",
      " 1098 1098    float32\n",
      " 1099 1099    float32\n",
      " 1100 1100    float32\n",
      " 1101 1101    float32\n",
      " 1102 1102    float32\n",
      " 1103 1103    float32\n",
      " 1104 1104    float32\n",
      " 1105 1105    float32\n",
      " 1106 1106    float32\n",
      " 1107 1107    float32\n",
      " 1108 1108    float32\n",
      " 1109 1109    float32\n",
      " 1110 1110    float32\n",
      " 1111 1111    float32\n",
      " 1112 1112    float32\n",
      " 1113 1113    float32\n",
      " 1114 1114    float32\n",
      " 1115 1115    float32\n",
      " 1116 1116    float32\n",
      " 1117 1117    float32\n",
      " 1118 1118    float32\n",
      " 1119 1119    float32\n",
      " 1120 1120    float32\n",
      " 1121 1121    float32\n",
      " 1122 1122    float32\n",
      " 1123 1123    float32\n",
      " 1124 1124    float32\n",
      " 1125 1125    float32\n",
      " 1126 1126    float32\n",
      " 1127 1127    float32\n",
      " 1128 1128    float32\n",
      " 1129 1129    float32\n",
      " 1130 1130    float32\n",
      " 1131 1131    float32\n",
      " 1132 1132    float32\n",
      " 1133 1133    float32\n",
      " 1134 1134    float32\n",
      " 1135 1135    float32\n",
      " 1136 1136    float32\n",
      " 1137 1137    float32\n",
      " 1138 1138    float32\n",
      " 1139 1139    float32\n",
      " 1140 1140    float32\n",
      " 1141 1141    float32\n",
      " 1142 1142    float32\n",
      " 1143 1143    float32\n",
      " 1144 1144    float32\n",
      " 1145 1145    float32\n",
      " 1146 1146    float32\n",
      " 1147 1147    float32\n",
      " 1148 1148    float32\n",
      " 1149 1149    float32\n",
      " 1150 1150    float32\n",
      " 1151 1151    float32\n",
      " 1152 1152    float32\n",
      " 1153 1153    float32\n",
      " 1154 1154    float32\n",
      " 1155 1155    float32\n",
      " 1156 1156    float32\n",
      " 1157 1157    float32\n",
      " 1158 1158    float32\n",
      " 1159 1159    float32\n",
      " 1160 1160    float32\n",
      " 1161 1161    float32\n",
      " 1162 1162    float32\n",
      " 1163 1163    float32\n",
      " 1164 1164    float32\n",
      " 1165 1165    float32\n",
      " 1166 1166    float32\n",
      " 1167 1167    float32\n",
      " 1168 1168    float32\n",
      " 1169 1169    float32\n",
      " 1170 1170    float32\n",
      " 1171 1171    float32\n",
      " 1172 1172    float32\n",
      " 1173 1173    float32\n",
      " 1174 1174    float32\n",
      " 1175 1175    float32\n",
      " 1176 1176    float32\n",
      " 1177 1177    float32\n",
      " 1178 1178    float32\n",
      " 1179 1179    float32\n",
      " 1180 1180    float32\n",
      " 1181 1181    float32\n",
      " 1182 1182    float32\n",
      " 1183 1183    float32\n",
      " 1184 1184    float32\n",
      " 1185 1185    float32\n",
      " 1186 1186    float32\n",
      " 1187 1187    float32\n",
      " 1188 1188    float32\n",
      " 1189 1189    float32\n",
      " 1190 1190    float32\n",
      " 1191 1191    float32\n",
      " 1192 1192    float32\n",
      " 1193 1193    float32\n",
      " 1194 1194    float32\n",
      " 1195 1195    float32\n",
      " 1196 1196    float32\n",
      " 1197 1197    float32\n",
      " 1198 1198    float32\n",
      " 1199 1199    float32\n",
      " 1200 1200    float32\n",
      " 1201 1201    float32\n",
      " 1202 1202    float32\n",
      " 1203 1203    float32\n",
      " 1204 1204    float32\n",
      " 1205 1205    float32\n",
      " 1206 1206    float32\n",
      " 1207 1207    float32\n",
      " 1208 1208    float32\n",
      " 1209 1209    float32\n",
      " 1210 1210    float32\n",
      " 1211 1211    float32\n",
      " 1212 1212    float32\n",
      " 1213 1213    float32\n",
      " 1214 1214    float32\n",
      " 1215 1215    float32\n",
      " 1216 1216    float32\n",
      " 1217 1217    float32\n",
      " 1218 1218    float32\n",
      " 1219 1219    float32\n",
      " 1220 1220    float32\n",
      " 1221 1221    float32\n",
      " 1222 1222    float32\n",
      " 1223 1223    float32\n",
      " 1224 1224    float32\n",
      " 1225 1225    float32\n",
      " 1226 1226    float32\n",
      " 1227 1227    float32\n",
      " 1228 1228    float32\n",
      " 1229 1229    float32\n",
      " 1230 1230    float32\n",
      " 1231 1231    float32\n",
      " 1232 1232    float32\n",
      " 1233 1233    float32\n",
      " 1234 1234    float32\n",
      " 1235 1235    float32\n",
      " 1236 1236    float32\n",
      " 1237 1237    float32\n",
      " 1238 1238    float32\n",
      " 1239 1239    float32\n",
      " 1240 1240    float32\n",
      " 1241 1241    float32\n",
      " 1242 1242    float32\n",
      " 1243 1243    float32\n",
      " 1244 1244    float32\n",
      " 1245 1245    float32\n",
      " 1246 1246    float32\n",
      " 1247 1247    float32\n",
      " 1248 1248    float32\n",
      " 1249 1249    float32\n",
      " 1250 1250    float32\n",
      " 1251 1251    float32\n",
      " 1252 1252    float32\n",
      " 1253 1253    float32\n",
      " 1254 1254    float32\n",
      " 1255 1255    float32\n",
      " 1256 1256    float32\n",
      " 1257 1257    float32\n",
      " 1258 1258    float32\n",
      " 1259 1259    float32\n",
      " 1260 1260    float32\n",
      " 1261 1261    float32\n",
      " 1262 1262    float32\n",
      " 1263 1263    float32\n",
      " 1264 1264    float32\n",
      " 1265 1265    float32\n",
      " 1266 1266    float32\n",
      " 1267 1267    float32\n",
      " 1268 1268    float32\n",
      " 1269 1269    float32\n",
      " 1270 1270    float32\n",
      " 1271 1271    float32\n",
      " 1272 1272    float32\n",
      " 1273 1273    float32\n",
      " 1274 1274    float32\n",
      " 1275 1275    float32\n",
      " 1276 1276    float32\n",
      " 1277 1277    float32\n",
      " 1278 1278    float32\n",
      " 1279 1279    float32\n",
      " 1280 1280    float32\n",
      " 1281 1281    float32\n",
      " 1282 1282    float32\n",
      " 1283 1283    float32\n",
      " 1284 1284    float32\n",
      " 1285 1285    float32\n",
      " 1286 1286    float32\n",
      " 1287 1287    float32\n",
      " 1288 1288    float32\n",
      " 1289 1289    float32\n",
      " 1290 1290    float32\n",
      " 1291 1291    float32\n",
      " 1292 1292    float32\n",
      " 1293 1293    float32\n",
      " 1294 1294    float32\n",
      " 1295 1295    float32\n",
      " 1296 1296    float32\n",
      " 1297 1297    float32\n",
      " 1298 1298    float32\n",
      " 1299 1299    float32\n",
      " 1300 1300    float32\n",
      " 1301 1301    float32\n",
      " 1302 1302    float32\n",
      " 1303 1303    float32\n",
      " 1304 1304    float32\n",
      " 1305 1305    float32\n",
      " 1306 1306    float32\n",
      " 1307 1307    float32\n",
      " 1308 1308    float32\n",
      " 1309 1309    float32\n",
      " 1310 1310    float32\n",
      " 1311 1311    float32\n",
      " 1312 1312    float32\n",
      " 1313 1313    float32\n",
      " 1314 1314    float32\n",
      " 1315 1315    float32\n",
      " 1316 1316    float32\n",
      " 1317 1317    float32\n",
      " 1318 1318    float32\n",
      " 1319 1319    float32\n",
      " 1320 1320    float32\n",
      " 1321 1321    float32\n",
      " 1322 1322    float32\n",
      " 1323 1323    float32\n",
      " 1324 1324    float32\n",
      " 1325 1325    float32\n",
      " 1326 1326    float32\n",
      " 1327 1327    float32\n",
      " 1328 1328    float32\n",
      " 1329 1329    float32\n",
      " 1330 1330    float32\n",
      " 1331 1331    float32\n",
      " 1332 1332    float32\n",
      " 1333 1333    float32\n",
      " 1334 1334    float32\n",
      " 1335 1335    float32\n",
      " 1336 1336    float32\n",
      " 1337 1337    float32\n",
      " 1338 1338    float32\n",
      " 1339 1339    float32\n",
      " 1340 1340    float32\n",
      " 1341 1341    float32\n",
      " 1342 1342    float32\n",
      " 1343 1343    float32\n",
      " 1344 1344    float32\n",
      " 1345 1345    float32\n",
      " 1346 1346    float32\n",
      " 1347 1347    float32\n",
      " 1348 1348    float32\n",
      " 1349 1349    float32\n",
      " 1350 1350    float32\n",
      " 1351 1351    float32\n",
      " 1352 1352    float32\n",
      " 1353 1353    float32\n",
      " 1354 1354    float32\n",
      " 1355 1355    float32\n",
      " 1356 1356    float32\n",
      " 1357 1357    float32\n",
      " 1358 1358    float32\n",
      " 1359 1359    float32\n",
      " 1360 1360    float32\n",
      " 1361 1361    float32\n",
      " 1362 1362    float32\n",
      " 1363 1363    float32\n",
      " 1364 1364    float32\n",
      " 1365 1365    float32\n",
      " 1366 1366    float32\n",
      " 1367 1367    float32\n",
      " 1368 1368    float32\n",
      " 1369 1369    float32\n",
      " 1370 1370    float32\n",
      " 1371 1371    float32\n",
      " 1372 1372    float32\n",
      " 1373 1373    float32\n",
      " 1374 1374    float32\n",
      " 1375 1375    float32\n",
      " 1376 1376    float32\n",
      " 1377 1377    float32\n",
      " 1378 1378    float32\n",
      " 1379 1379    float32\n",
      " 1380 1380    float32\n",
      " 1381 1381    float32\n",
      " 1382 1382    float32\n",
      " 1383 1383    float32\n",
      " 1384 1384    float32\n",
      " 1385 1385    float32\n",
      " 1386 1386    float32\n",
      " 1387 1387    float32\n",
      " 1388 1388    float32\n",
      " 1389 1389    float32\n",
      " 1390 1390    float32\n",
      " 1391 1391    float32\n",
      " 1392 1392    float32\n",
      " 1393 1393    float32\n",
      " 1394 1394    float32\n",
      " 1395 1395    float32\n",
      " 1396 1396    float32\n",
      " 1397 1397    float32\n",
      " 1398 1398    float32\n",
      " 1399 1399    float32\n",
      " 1400 1400    float32\n",
      " 1401 1401    float32\n",
      " 1402 1402    float32\n",
      " 1403 1403    float32\n",
      " 1404 1404    float32\n",
      " 1405 1405    float32\n",
      " 1406 1406    float32\n",
      " 1407 1407    float32\n",
      " 1408 1408    float32\n",
      " 1409 1409    float32\n",
      " 1410 1410    float32\n",
      " 1411 1411    float32\n",
      " 1412 1412    float32\n",
      " 1413 1413    float32\n",
      " 1414 1414    float32\n",
      " 1415 1415    float32\n",
      " 1416 1416    float32\n",
      " 1417 1417    float32\n",
      " 1418 1418    float32\n",
      " 1419 1419    float32\n",
      " 1420 1420    float32\n",
      " 1421 1421    float32\n",
      " 1422 1422    float32\n",
      " 1423 1423    float32\n",
      " 1424 1424    float32\n",
      " 1425 1425    float32\n",
      " 1426 1426    float32\n",
      " 1427 1427    float32\n",
      " 1428 1428    float32\n",
      " 1429 1429    float32\n",
      " 1430 1430    float32\n",
      " 1431 1431    float32\n",
      " 1432 1432    float32\n",
      " 1433 1433    float32\n",
      " 1434 1434    float32\n",
      " 1435 1435    float32\n",
      " 1436 1436    float32\n",
      " 1437 1437    float32\n",
      " 1438 1438    float32\n",
      " 1439 1439    float32\n",
      " 1440 1440    float32\n",
      " 1441 1441    float32\n",
      " 1442 1442    float32\n",
      " 1443 1443    float32\n",
      " 1444 1444    float32\n",
      " 1445 1445    float32\n",
      " 1446 1446    float32\n",
      " 1447 1447    float32\n",
      " 1448 1448    float32\n",
      " 1449 1449    float32\n",
      " 1450 1450    float32\n",
      " 1451 1451    float32\n",
      " 1452 1452    float32\n",
      " 1453 1453    float32\n",
      " 1454 1454    float32\n",
      " 1455 1455    float32\n",
      " 1456 1456    float32\n",
      " 1457 1457    float32\n",
      " 1458 1458    float32\n",
      " 1459 1459    float32\n",
      " 1460 1460    float32\n",
      " 1461 1461    float32\n",
      " 1462 1462    float32\n",
      " 1463 1463    float32\n",
      " 1464 1464    float32\n",
      " 1465 1465    float32\n",
      " 1466 1466    float32\n",
      " 1467 1467    float32\n",
      " 1468 1468    float32\n",
      " 1469 1469    float32\n",
      " 1470 1470    float32\n",
      " 1471 1471    float32\n",
      " 1472 1472    float32\n",
      " 1473 1473    float32\n",
      " 1474 1474    float32\n",
      " 1475 1475    float32\n",
      " 1476 1476    float32\n",
      " 1477 1477    float32\n",
      " 1478 1478    float32\n",
      " 1479 1479    float32\n",
      " 1480 1480    float32\n",
      " 1481 1481    float32\n",
      " 1482 1482    float32\n",
      " 1483 1483    float32\n",
      " 1484 1484    float32\n",
      " 1485 1485    float32\n",
      " 1486 1486    float32\n",
      " 1487 1487    float32\n",
      " 1488 1488    float32\n",
      " 1489 1489    float32\n",
      " 1490 1490    float32\n",
      " 1491 1491    float32\n",
      " 1492 1492    float32\n",
      " 1493 1493    float32\n",
      " 1494 1494    float32\n",
      " 1495 1495    float32\n",
      " 1496 1496    float32\n",
      " 1497 1497    float32\n",
      " 1498 1498    float32\n",
      " 1499 1499    float32\n",
      " 1500 1500    float32\n",
      " 1501 1501    float32\n",
      " 1502 1502    float32\n",
      " 1503 1503    float32\n",
      " 1504 1504    float32\n",
      " 1505 1505    float32\n",
      " 1506 1506    float32\n",
      " 1507 1507    float32\n",
      " 1508 1508    float32\n",
      " 1509 1509    float32\n",
      " 1510 1510    float32\n",
      " 1511 1511    float32\n",
      " 1512 1512    float32\n",
      " 1513 1513    float32\n",
      " 1514 1514    float32\n",
      " 1515 1515    float32\n",
      " 1516 1516    float32\n",
      " 1517 1517    float32\n",
      " 1518 1518    float32\n",
      " 1519 1519    float32\n",
      " 1520 1520    float32\n",
      " 1521 1521    float32\n",
      " 1522 1522    float32\n",
      " 1523 1523    float32\n",
      " 1524 1524    float32\n",
      " 1525 1525    float32\n",
      " 1526 1526    float32\n",
      " 1527 1527    float32\n",
      " 1528 1528    float32\n",
      " 1529 1529    float32\n",
      " 1530 1530    float32\n",
      " 1531 1531    float32\n",
      " 1532 1532    float32\n",
      " 1533 1533    float32\n",
      " 1534 1534    float32\n",
      " 1535 1535    float32\n",
      " 1536 1536    float32\n",
      " 1537 1537    float32\n",
      " 1538 1538    float32\n",
      " 1539 1539    float32\n",
      " 1540 1540    float32\n",
      " 1541 1541    float32\n",
      " 1542 1542    float32\n",
      " 1543 1543    float32\n",
      " 1544 1544    float32\n",
      " 1545 1545    float32\n",
      " 1546 1546    float32\n",
      " 1547 1547    float32\n",
      " 1548 1548    float32\n",
      " 1549 1549    float32\n",
      " 1550 1550    float32\n",
      " 1551 1551    float32\n",
      " 1552 1552    float32\n",
      " 1553 1553    float32\n",
      " 1554 1554    float32\n",
      " 1555 1555    float32\n",
      " 1556 1556    float32\n",
      " 1557 1557    float32\n",
      " 1558 1558    float32\n",
      " 1559 1559    float32\n",
      " 1560 1560    float32\n",
      " 1561 1561    float32\n",
      " 1562 1562    float32\n",
      " 1563 1563    float32\n",
      " 1564 1564    float32\n",
      " 1565 1565    float32\n",
      " 1566 1566    float32\n",
      " 1567 1567    float32\n",
      " 1568 1568    float32\n",
      " 1569 1569    float32\n",
      " 1570 1570    float32\n",
      " 1571 1571    float32\n",
      " 1572 1572    float32\n",
      " 1573 1573    float32\n",
      " 1574 1574    float32\n",
      " 1575 1575    float32\n",
      " 1576 1576    float32\n",
      " 1577 1577    float32\n",
      " 1578 1578    float32\n",
      " 1579 1579    float32\n",
      " 1580 1580    float32\n",
      " 1581 1581    float32\n",
      " 1582 1582    float32\n",
      " 1583 1583    float32\n",
      " 1584 1584    float32\n",
      " 1585 1585    float32\n",
      " 1586 1586    float32\n",
      " 1587 1587    float32\n",
      " 1588 1588    float32\n",
      " 1589 1589    float32\n",
      " 1590 1590    float32\n",
      " 1591 1591    float32\n",
      " 1592 1592    float32\n",
      " 1593 1593    float32\n",
      " 1594 1594    float32\n",
      " 1595 1595    float32\n",
      " 1596 1596    float32\n",
      " 1597 1597    float32\n",
      " 1598 1598    float32\n",
      " 1599 1599    float32\n",
      " 1600 1600    float32\n",
      " 1601 1601    float32\n",
      " 1602 1602    float32\n",
      " 1603 1603    float32\n",
      " 1604 1604    float32\n",
      " 1605 1605    float32\n",
      " 1606 1606    float32\n",
      " 1607 1607    float32\n",
      " 1608 1608    float32\n",
      " 1609 1609    float32\n",
      " 1610 1610    float32\n",
      " 1611 1611    float32\n",
      " 1612 1612    float32\n",
      " 1613 1613    float32\n",
      " 1614 1614    float32\n",
      " 1615 1615    float32\n",
      " 1616 1616    float32\n",
      " 1617 1617    float32\n",
      " 1618 1618    float32\n",
      " 1619 1619    float32\n",
      " 1620 1620    float32\n",
      " 1621 1621    float32\n",
      " 1622 1622    float32\n",
      " 1623 1623    float32\n",
      " 1624 1624    float32\n",
      " 1625 1625    float32\n",
      " 1626 1626    float32\n",
      " 1627 1627    float32\n",
      " 1628 1628    float32\n",
      " 1629 1629    float32\n",
      " 1630 1630    float32\n",
      " 1631 1631    float32\n",
      " 1632 1632    float32\n",
      " 1633 1633    float32\n",
      " 1634 1634    float32\n",
      " 1635 1635    float32\n",
      " 1636 1636    float32\n",
      " 1637 1637    float32\n",
      " 1638 1638    float32\n",
      " 1639 1639    float32\n",
      " 1640 1640    float32\n",
      " 1641 1641    float32\n",
      " 1642 1642    float32\n",
      " 1643 1643    float32\n",
      " 1644 1644    float32\n",
      " 1645 1645    float32\n",
      " 1646 1646    float32\n",
      " 1647 1647    float32\n",
      " 1648 1648    float32\n",
      " 1649 1649    float32\n",
      " 1650 1650    float32\n",
      " 1651 1651    float32\n",
      " 1652 1652    float32\n",
      " 1653 1653    float32\n",
      " 1654 1654    float32\n",
      " 1655 1655    float32\n",
      " 1656 1656    float32\n",
      " 1657 1657    float32\n",
      " 1658 1658    float32\n",
      " 1659 1659    float32\n",
      " 1660 1660    float32\n",
      " 1661 1661    float32\n",
      " 1662 1662    float32\n",
      " 1663 1663    float32\n",
      " 1664 1664    float32\n",
      " 1665 1665    float32\n",
      " 1666 1666    float32\n",
      " 1667 1667    float32\n",
      " 1668 1668    float32\n",
      " 1669 1669    float32\n",
      " 1670 1670    float32\n",
      " 1671 1671    float32\n",
      " 1672 1672    float32\n",
      " 1673 1673    float32\n",
      " 1674 1674    float32\n",
      " 1675 1675    float32\n",
      " 1676 1676    float32\n",
      " 1677 1677    float32\n",
      " 1678 1678    float32\n",
      " 1679 1679    float32\n",
      " 1680 1680    float32\n",
      " 1681 1681    float32\n",
      " 1682 1682    float32\n",
      " 1683 1683    float32\n",
      " 1684 1684    float32\n",
      " 1685 1685    float32\n",
      " 1686 1686    float32\n",
      " 1687 1687    float32\n",
      " 1688 1688    float32\n",
      " 1689 1689    float32\n",
      " 1690 1690    float32\n",
      " 1691 1691    float32\n",
      " 1692 1692    float32\n",
      " 1693 1693    float32\n",
      " 1694 1694    float32\n",
      " 1695 1695    float32\n",
      " 1696 1696    float32\n",
      " 1697 1697    float32\n",
      " 1698 1698    float32\n",
      " 1699 1699    float32\n",
      " 1700 1700    float32\n",
      " 1701 1701    float32\n",
      " 1702 1702    float32\n",
      " 1703 1703    float32\n",
      " 1704 1704    float32\n",
      " 1705 1705    float32\n",
      " 1706 1706    float32\n",
      " 1707 1707    float32\n",
      " 1708 1708    float32\n",
      " 1709 1709    float32\n",
      " 1710 1710    float32\n",
      " 1711 1711    float32\n",
      " 1712 1712    float32\n",
      " 1713 1713    float32\n",
      " 1714 1714    float32\n",
      " 1715 1715    float32\n",
      " 1716 1716    float32\n",
      " 1717 1717    float32\n",
      " 1718 1718    float32\n",
      " 1719 1719    float32\n",
      " 1720 1720    float32\n",
      " 1721 1721    float32\n",
      " 1722 1722    float32\n",
      " 1723 1723    float32\n",
      " 1724 1724    float32\n",
      " 1725 1725    float32\n",
      " 1726 1726    float32\n",
      " 1727 1727    float32\n",
      " 1728 1728    float32\n",
      " 1729 1729    float32\n",
      " 1730 1730    float32\n",
      " 1731 1731    float32\n",
      " 1732 1732    float32\n",
      " 1733 1733    float32\n",
      " 1734 1734    float32\n",
      " 1735 1735    float32\n",
      " 1736 1736    float32\n",
      " 1737 1737    float32\n",
      " 1738 1738    float32\n",
      " 1739 1739    float32\n",
      " 1740 1740    float32\n",
      " 1741 1741    float32\n",
      " 1742 1742    float32\n",
      " 1743 1743    float32\n",
      " 1744 1744    float32\n",
      " 1745 1745    float32\n",
      " 1746 1746    float32\n",
      " 1747 1747    float32\n",
      " 1748 1748    float32\n",
      " 1749 1749    float32\n",
      " 1750 1750    float32\n",
      " 1751 1751    float32\n",
      " 1752 1752    float32\n",
      " 1753 1753    float32\n",
      " 1754 1754    float32\n",
      " 1755 1755    float32\n",
      " 1756 1756    float32\n",
      " 1757 1757    float32\n",
      " 1758 1758    float32\n",
      " 1759 1759    float32\n",
      " 1760 1760    float32\n",
      " 1761 1761    float32\n",
      " 1762 1762    float32\n",
      " 1763 1763    float32\n",
      " 1764 1764    float32\n",
      " 1765 1765    float32\n",
      " 1766 1766    float32\n",
      " 1767 1767    float32\n",
      " 1768 1768    float32\n",
      " 1769 1769    float32\n",
      " 1770 1770    float32\n",
      " 1771 1771    float32\n",
      " 1772 1772    float32\n",
      " 1773 1773    float32\n",
      " 1774 1774    float32\n",
      " 1775 1775    float32\n",
      " 1776 1776    float32\n",
      " 1777 1777    float32\n",
      " 1778 1778    float32\n",
      " 1779 1779    float32\n",
      " 1780 1780    float32\n",
      " 1781 1781    float32\n",
      " 1782 1782    float32\n",
      " 1783 1783    float32\n",
      " 1784 1784    float32\n",
      " 1785 1785    float32\n",
      " 1786 1786    float32\n",
      " 1787 1787    float32\n",
      " 1788 1788    float32\n",
      " 1789 1789    float32\n",
      " 1790 1790    float32\n",
      " 1791 1791    float32\n",
      " 1792 1792    float32\n",
      " 1793 1793    float32\n",
      " 1794 1794    float32\n",
      " 1795 1795    float32\n",
      " 1796 1796    float32\n",
      " 1797 1797    float32\n",
      " 1798 1798    float32\n",
      " 1799 1799    float32\n",
      " 1800 1800    float32\n",
      " 1801 1801    float32\n",
      " 1802 1802    float32\n",
      " 1803 1803    float32\n",
      " 1804 1804    float32\n",
      " 1805 1805    float32\n",
      " 1806 1806    float32\n",
      " 1807 1807    float32\n",
      " 1808 1808    float32\n",
      " 1809 1809    float32\n",
      " 1810 1810    float32\n",
      " 1811 1811    float32\n",
      " 1812 1812    float32\n",
      " 1813 1813    float32\n",
      " 1814 1814    float32\n",
      " 1815 1815    float32\n",
      " 1816 1816    float32\n",
      " 1817 1817    float32\n",
      " 1818 1818    float32\n",
      " 1819 1819    float32\n",
      " 1820 1820    float32\n",
      " 1821 1821    float32\n",
      " 1822 1822    float32\n",
      " 1823 1823    float32\n",
      " 1824 1824    float32\n",
      " 1825 1825    float32\n",
      " 1826 1826    float32\n",
      " 1827 1827    float32\n",
      " 1828 1828    float32\n",
      " 1829 1829    float32\n",
      " 1830 1830    float32\n",
      " 1831 1831    float32\n",
      " 1832 1832    float32\n",
      " 1833 1833    float32\n",
      " 1834 1834    float32\n",
      " 1835 1835    float32\n",
      " 1836 1836    float32\n",
      " 1837 1837    float32\n",
      " 1838 1838    float32\n",
      " 1839 1839    float32\n",
      " 1840 1840    float32\n",
      " 1841 1841    float32\n",
      " 1842 1842    float32\n",
      " 1843 1843    float32\n",
      " 1844 1844    float32\n",
      " 1845 1845    float32\n",
      " 1846 1846    float32\n",
      " 1847 1847    float32\n",
      " 1848 1848    float32\n",
      " 1849 1849    float32\n",
      "dtypes: float32(1850)\n",
      "memory usage: 17.6 MB\n"
     ]
    }
   ],
   "source": [
    "X.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.333336</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>114.333336</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>122.666664</td>\n",
       "      <td>124.333336</td>\n",
       "      <td>138.333328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201.666672</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>134.666672</td>\n",
       "      <td>158.666672</td>\n",
       "      <td>181.333328</td>\n",
       "      <td>171.333328</td>\n",
       "      <td>167.333328</td>\n",
       "      <td>168.333328</td>\n",
       "      <td>168.333328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>105.333336</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>116.333336</td>\n",
       "      <td>136.666672</td>\n",
       "      <td>137.333328</td>\n",
       "      <td>139.333328</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122.333336</td>\n",
       "      <td>131.666672</td>\n",
       "      <td>128.666672</td>\n",
       "      <td>130.666672</td>\n",
       "      <td>137.666672</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>155.333328</td>\n",
       "      <td>166.333328</td>\n",
       "      <td>177.333328</td>\n",
       "      <td>184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.333328</td>\n",
       "      <td>136.666672</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>142.666672</td>\n",
       "      <td>144.666672</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>161.666672</td>\n",
       "      <td>168.666672</td>\n",
       "      <td>174.666672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5  \\\n",
       "0   66.333336   84.000000   99.000000  102.000000  112.000000  114.333336   \n",
       "1  201.666672  181.000000  149.000000  134.666672  158.666672  181.333328   \n",
       "2  100.000000  105.333336  105.000000  116.333336  136.666672  137.333328   \n",
       "3  122.333336  131.666672  128.666672  130.666672  137.666672  144.000000   \n",
       "4  132.333328  136.666672  141.000000  144.000000  142.666672  144.666672   \n",
       "\n",
       "            6           7           8           9  \n",
       "0  119.000000  122.666664  124.333336  138.333328  \n",
       "1  171.333328  167.333328  168.333328  168.333328  \n",
       "2  139.333328  148.000000  157.000000  156.000000  \n",
       "3  155.333328  166.333328  177.333328  184.000000  \n",
       "4  153.000000  161.666672  168.666672  174.666672  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "X.iloc[0:5, 0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a base level accuracy for the dataset\n",
    "**Since Strand is a text classifier, it would treat each exact value in the dataset as a token and be unable to make accurate classifications without some transformation of the data.**\n",
    "* LogisticRegression performs best on this dataset with a 10-fold cross validation accuracy of 66.45% in 239.05s\n",
    "* LinearSVC also does well with a 10-fold cross validation accuracy of 62.31% in 20.20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.02339944839477539\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.21287918090820312\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.023401594161987303\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.22101163864135742\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.022699618339538576\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.20470619201660156\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.26104418 0.26506024 0.31325301 0.23694779 0.24096386 0.27710843\n",
      " 0.24096386 0.28514056 0.24096386 0.25806452]\n",
      " \n",
      "Mean Accuracy:  0.2619510299261562\n",
      "Mean Fit Time:  0.10810341835021972\n",
      "Mean Score Time:  0.011900115013122558\n",
      "CV Time:  0.3839743137359619\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.18875502 0.15662651 0.28915663 0.21686747 0.2811245  0.19277108\n",
      " 0.28915663 0.04016064 0.37751004 0.4516129 ]\n",
      " \n",
      "Mean Accuracy:  0.24837414172820313\n",
      "Mean Fit Time:  3.197898745536804\n",
      "Mean Score Time:  0.012803196907043457\n",
      "CV Time:  5.0269975662231445\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.25702811 0.25301205 0.27309237 0.24497992 0.26104418 0.25301205\n",
      " 0.25702811 0.26104418 0.26104418 0.26209677]\n",
      " \n",
      "Mean Accuracy:  0.25833819147557974\n",
      "Mean Fit Time:  5.780297470092774\n",
      "Mean Score Time:  0.04280169010162353\n",
      "CV Time:  10.278285503387451\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.65863454 0.62248996 0.61044177 0.63052209 0.59036145 0.59437751\n",
      " 0.63855422 0.62650602 0.60240964 0.65725806]\n",
      " \n",
      "Mean Accuracy:  0.6231555253271149\n",
      "Mean Fit Time:  161.47431993484497\n",
      "Mean Score Time:  0.012601113319396973\n",
      "CV Time:  249.96472191810608\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.65461847 0.66666667 0.6626506  0.66666667 0.65863454 0.69879518\n",
      " 0.64658635 0.67068273 0.61044177 0.70967742]\n",
      " \n",
      "Mean Accuracy:  0.664542039124239\n",
      "Mean Fit Time:  13.825209426879884\n",
      "Mean Score Time:  0.015599322319030762\n",
      "CV Time:  20.96045160293579\n",
      " \n"
     ]
    }
   ],
   "source": [
    "test_models(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can We Improve Our Baseline To Start \n",
    "* Below I scale the data and then peform PCA with n_components = to the total number of columns.\n",
    "* Next I plot the cumulative explained variance ratio to find the optimal number of components for PCA.\n",
    "* However we will not transform the data using PCA until later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale the data \n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained variance at 200 components: 0.9658556347712874\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pca(X):\n",
    "    # Perform PCA on the data to reduce the number of initial features \n",
    "    # and to remove correlations that are common between pixel features \n",
    "    pca = PCA(n_components=X.shape[1])\n",
    "    pca.fit(X)\n",
    "\n",
    "    # Inspect the explained variances to determine how many components to use  \n",
    "    plt.subplots(figsize=(8, 8))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance');\n",
    "    print('Cumulative Explained variance at 200 components:',sum(pca.explained_variance_ratio_[0:199]) )\n",
    "    \n",
    "plot_pca(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "* A quick inspection of the target classes we are trying to predict shows this is a 43 class problem.\n",
    "* In a two class problem we have at least 1/2 = 50% accuracy even when guessing.\n",
    "* This multi-class problem is much more complex with only 1/43 = 2.33% accuracy when guessing.\n",
    "* To make things more challenging, we also have very imbalanced classes.\n",
    "* It appears that class # 11 is by far the largest class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records 2489\n",
      "Total Classes: 43\n",
      "Class Gini Index 0.9290543316264526\n",
      "Smallest Class Id: 32 Records: 20\n",
      "Largest Class Id: 11 Records: 530\n",
      "Accuracy when Guessing: 2.33 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Adapted from:\n",
    "# https://www.featureranking.com/tutorials/machine-learning-tutorials/information-gain-computation/\n",
    "def gini_index(y):\n",
    "    probs = pd.value_counts(y,normalize=True)\n",
    "    return 1 - np.sum(np.square(probs))\n",
    "\n",
    "def plot_class_dist(y):\n",
    "    fig, axarr = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    class_ct = len(np.unique(y))\n",
    "    vc = pd.value_counts(y)\n",
    "    print('Total Records', len(y))\n",
    "    print('Total Classes:', class_ct)\n",
    "    print('Class Gini Index', gini_index(y))\n",
    "    print('Smallest Class Id:',vc.idxmin(),'Records:',vc.min())\n",
    "    print('Largest Class Id:',vc.idxmax(),'Records:',vc.max())\n",
    "    print('Accuracy when Guessing:', np.round( (1 / len(np.unique(y))) * 100, 2), '%')\n",
    "\n",
    "    sns.distplot(y, ax=axarr[0], bins=class_ct).set_title('LFW Class Distribution');\n",
    "    sns.distplot(y, ax=axarr[1], kde=False, bins=class_ct).set_title('LFW Class Counts');\n",
    "    \n",
    "\n",
    "plot_class_dist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting The Confusion Matrix \n",
    "* Here I use train_test_split to divide the data into 70% training and 30% testing random samples.   \n",
    "* The top performing baseline LogisticRegression model is used to make predictions against the test data. \n",
    "* Finally, I plot a confusion matrix.\n",
    " * A perfect confusion matrix will only show shaded squares across the matrix diagonal. \n",
    "* However, the confusion matrix below shows that many class predictions are getting confused with the larger classes 7, 11, 12 and 40.\n",
    "* This is evident by the high number of off-diagonal shaded boxes for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from StrandSliceClassifier import StrandSliceClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Break our data into 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "# Use StrandSliceClassifier to build a model and predict on the test set\n",
    "strand = LogisticRegression(solver='liblinear')\n",
    "strand.fit(X_train, y_train)\n",
    "y_pred = strand.predict(X_test)\n",
    "\n",
    "# Create a confusion matrix to see what classes StrandSliceClassifier is getting wrong \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(10, 10))\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.imshow(cm_normalized,cmap=plt.get_cmap('Blues'),aspect='auto')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling, Oversampling, and SMOTE\n",
    "**In this section we use random sampling via the imblearn package to address the dataset's class imbalance problem.**\n",
    "* First we undersample adjusting all classe sizes to be equal to the smallest class.\n",
    " * The dataset is reduced from 2,489 records to 860 with each class containing only 20 records.\n",
    " * This approach is not desirable, since we lost over half of our data. \n",
    "* Next we undersample the majority class only reducing class 11 from 530 to 20 records.\n",
    " * This approach is not desirable, since class 7 still has 236 records. (Multiple classes are imbalanced in the dataset)\n",
    "* Finally, we use Synthetic Minority Over-sampling to over sample all classes, except the majority. \n",
    " * This uses random sampling to increase under-represented classes to the majority size.\n",
    " * This approach could be problematic on large datasets.  In this case we increase the dataset rows from 2,489 to 22,790."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Selected: 860\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "us = RandomUnderSampler()\n",
    "X_us, y_us = us.fit_sample(X, y)\n",
    "\n",
    "print('Records Selected:', len(us.sample_indices_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records 860\n",
      "Total Classes: 43\n",
      "Class Gini Index 0.9767441860465116\n",
      "Smallest Class Id: 42 Records: 20\n",
      "Largest Class Id: 42 Records: 20\n",
      "Accuracy when Guessing: 2.33 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_class_dist(y_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Selected: 1979\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "us = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_us_maj, y_us_maj = us.fit_sample(X, y)\n",
    "\n",
    "print('Records Selected:', len(us.sample_indices_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records 1979\n",
      "Total Classes: 43\n",
      "Class Gini Index 0.9593975755028609\n",
      "Smallest Class Id: 11 Records: 20\n",
      "Largest Class Id: 7 Records: 236\n",
      "Accuracy when Guessing: 2.33 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_class_dist(y_us_maj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(sampling_strategy='not majority')\n",
    "X_sm, y_sm = sm.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records 22790\n",
      "Total Classes: 43\n",
      "Class Gini Index 0.9767441860465116\n",
      "Smallest Class Id: 31 Records: 530\n",
      "Largest Class Id: 31 Records: 530\n",
      "Accuracy when Guessing: 2.33 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_class_dist(y_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Adjusted Datasets \n",
    "**I perform 10-fold cross validation again to see which dataset above performs best using the LogisticRegression classifier, since it had the highest accuracy originally.  The original dataset has also been scaled now, so I re-run cross validation on it as well.**\n",
    "* Original Dataset Scaled - 69.38% accuracy\n",
    "* Minority Undersampled Dataset - 54.06% accuracy\n",
    "* Majority Undersampled Dataset - 67.61% accuracy\n",
    "* Oversample all Classes to Majority Dataset - **99.34% accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset\n",
      "----------------------------------------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.73895582 0.70682731 0.69879518 0.69076305 0.6626506  0.69879518\n",
      " 0.64257028 0.69477912 0.66666667 0.73790323]\n",
      " \n",
      "Mean Accuracy:  0.6938706438657858\n",
      "Mean Fit Time:  13.302919864654541\n",
      "Mean Score Time:  0.010057830810546875\n",
      "CV Time:  22.023164987564087\n",
      "Minority Undersampled Dataset\n",
      "----------------------------------------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.59302326 0.53488372 0.52325581 0.56976744 0.51162791 0.47674419\n",
      " 0.5        0.53488372 0.5        0.6627907 ]\n",
      " \n",
      "Mean Accuracy:  0.5406976744186047\n",
      "Mean Fit Time:  8.115061068534851\n",
      "Mean Score Time:  0.004802727699279785\n",
      "CV Time:  11.942819118499756\n",
      "Majority Undersampled Dataset\n",
      "----------------------------------------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.7020202  0.66161616 0.71212121 0.65656566 0.72222222 0.63131313\n",
      " 0.66666667 0.60606061 0.68181818 0.72081218]\n",
      " \n",
      "Mean Accuracy:  0.6761216223145158\n",
      "Mean Fit Time:  11.469553327560424\n",
      "Mean Score Time:  0.007606816291809082\n",
      "CV Time:  17.224608421325684\n",
      "Oversample all Classes to Majority Dataset\n",
      "----------------------------------------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99254059 0.99561211 0.99429574 0.99473453 0.9921018  0.99122422\n",
      " 0.99561211 0.99297938 0.9921018  0.99341817]\n",
      " \n",
      "Mean Accuracy:  0.993462044756472\n",
      "Mean Fit Time:  83.87204966545104\n",
      "Mean Score Time:  0.09411635398864746\n",
      "CV Time:  129.79186463356018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "print('Original Dataset')\n",
    "print('----------------------------------------------------------------')\n",
    "stratified_cross_validate(LogisticRegression(), X, y, cv)\n",
    "print('Minority Undersampled Dataset')\n",
    "print('----------------------------------------------------------------')\n",
    "stratified_cross_validate(LogisticRegression(), X_us, y_us, cv)\n",
    "print('Majority Undersampled Dataset')\n",
    "print('----------------------------------------------------------------')\n",
    "stratified_cross_validate(LogisticRegression(), X_us_maj, y_us_maj, cv)\n",
    "print('Oversample all Classes to Majority Dataset')\n",
    "print('----------------------------------------------------------------')\n",
    "stratified_cross_validate(LogisticRegression(), X_sm, y_sm, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA to Reduce Dataset Size Number of Features\n",
    "* Here we take the SMOTE oversampled dataset and perform Principal Component Analisys to reduce its' size.\n",
    "* Plotting PCA components for all features in the dataset we see that selecting only 200 out of 1850 components will still get us 97.42% of the cumulative variance in this dataset. \n",
    "* Reducing the dataset from 1850 features to only 200 principal component features will save a lot of processing time later, if the smaller dataset still performs well.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained variance at 200 components: 0.974024432580336\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca(X_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the 200 Component Dataset\n",
    "* The PCA reduced dataset still achieves 99.17% accuracy.  The original SMOTE dataset 99.34%.\n",
    "* PCA allows us to give up 1650 columns of data in this case for a cost 0.17% accuracy.  This seems like an acceptable tradeoff. \n",
    "* PCA also removes correlations from columns within a dataset.  This is an added benefit, since we are classifying image data and should help some of our classifiers perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversample all Classes to Majority Dataset @ 200 Principal Components\n",
      "----------------------------------------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.98683633 0.99429574 0.98859149 0.99254059 0.99034664 0.98990785\n",
      " 0.99385695 0.98990785 0.98859149 0.99297938]\n",
      " \n",
      "Mean Accuracy:  0.9907854322071084\n",
      "Mean Fit Time:  17.934167361259462\n",
      "Mean Score Time:  0.01330568790435791\n",
      "CV Time:  31.43050217628479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Convert X_sm to 200 principal components\n",
    "pca = PCA(n_components=200)\n",
    "X_sm_pca200 = pca.fit_transform(X_sm)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "print('Oversample all Classes to Majority Dataset @ 200 Principal Components')\n",
    "print('----------------------------------------------------------------')\n",
    "stratified_cross_validate(LogisticRegression(), X_sm_pca200, y_sm, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the New Baselines for all Models\n",
    "**Here we recalulate our accuracy baselines for each model.** \n",
    "* At this point Strand classifiers are still unable to make classifications on this data until it is Strand Vectorized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrandSliceClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.02540268898010254\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  1.9503300189971924\n",
      " \n",
      "StrandGiniClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.028809237480163574\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.2344651222229004\n",
      " \n",
      "StrandBinaryClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.026245617866516115\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.20824933052062988\n",
      " \n",
      "MultinomialNB\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      " \n",
      "Mean Accuracy:  nan\n",
      "Mean Fit Time:  0.04861044883728027\n",
      "Mean Score Time:  0.0\n",
      "CV Time:  0.24827909469604492\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.88810882 0.90785432 0.90039491 0.89732339 0.90653796 0.90039491\n",
      " 0.90127249 0.90039491 0.91224221 0.9008337 ]\n",
      " \n",
      "Mean Accuracy:  0.9015357612988153\n",
      "Mean Fit Time:  4.1192734956741335\n",
      "Mean Score Time:  0.01459970474243164\n",
      "CV Time:  6.941084861755371\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.62132514 0.64940763 0.650724   0.64326459 0.65730584 0.64238701\n",
      " 0.62395788 0.63931549 0.64589732 0.6428258 ]\n",
      " \n",
      "Mean Accuracy:  0.6416410706450197\n",
      "Mean Fit Time:  30.1400377035141\n",
      "Mean Score Time:  0.1951779842376709\n",
      "CV Time:  52.19593548774719\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.97806055 0.98903028 0.98332602 0.98376481 0.9881527  0.98376481\n",
      " 0.98508118 0.98376481 0.98551996 0.98639754]\n",
      " \n",
      "Mean Accuracy:  0.9846862659060992\n",
      "Mean Fit Time:  145.20492334365844\n",
      "Mean Score Time:  0.008910727500915528\n",
      "CV Time:  228.96744394302368\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "Fold Scores:\n",
      " \n",
      "[0.99034664 0.99473453 0.99078543 0.99297938 0.99078543 0.98771391\n",
      " 0.99517332 0.98990785 0.9921018  0.99254059]\n",
      " \n",
      "Mean Accuracy:  0.9917068889863975\n",
      "Mean Fit Time:  18.150195360183716\n",
      "Mean Score Time:  0.012503933906555176\n",
      "CV Time:  28.28733491897583\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Recreate our baseline accuracy\n",
    "test_models(X_sm_pca200,y_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strand Vectorize the balanced LFW Dataset\n",
    "**Now that we have a nicer baseline accuracy.  Let's see how StrandPy tools handle this dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<22790x4551796 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4558000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from StrandPy import StrandVectorizer\n",
    "\n",
    "# StrandVectorizer only accepts a Pandas dataframe as input to\n",
    "# best inspect column data types for transformation.\n",
    "X_sm_pca200_df = pd.DataFrame(X_sm_pca200)\n",
    "\n",
    "sv = StrandVectorizer(truncate_to=10,signature_length=None, analyzer='word', ngram_range=(1,1)\n",
    "                      , binary=False, use_idf=False, norm=None)\n",
    "X_sv = sv.fit_transform(X_sm_pca200_df)\n",
    "X_sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Strand Vectorized Dataset for a Baseline Accuracy\n",
    "* This version of the Strand Vectorized dataset produces 27.07% accuracy during 10-fold cross validation. \n",
    "* Currently the Strand classifier is below the best classifier tested which was at 66.45%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.02852128 0.02544976 0.02939886 0.02544976 0.02544976 0.02808249\n",
      " 0.02676613 0.02939886 0.02413339 0.02632734]\n",
      " \n",
      "Mean Accuracy:  0.02689776217639316\n",
      "Mean Fit Time:  19.101768708229066\n",
      "Mean Score Time:  0.6343705415725708\n",
      "CV Time:  33.337400674819946\n",
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from StrandPy import StrandBinaryClassifier\n",
    "\n",
    "strand = StrandBinaryClassifier()\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stratified_cross_validate(strand, X_sv, y_sm, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.02808249 0.02501097 0.0276437  0.02501097 0.02501097 0.02588855\n",
      " 0.02501097 0.02852128 0.02281703 0.02501097]\n",
      " \n",
      "Mean Accuracy:  0.025800789820096537\n",
      "Mean Fit Time:  0.7326058149337769\n",
      "Mean Score Time:  1.6649063110351563\n",
      "CV Time:  4.330974340438843\n",
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stratified_cross_validate(strand, X_sv, y_sm, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best truncate_to Parameters for the Breast Cancer Dataset\n",
    "**Below, I check each column for the best truncate_to parameters**\n",
    "* This process is experimental and took 37.1s\n",
    "* We can see when looking at each of the individual trun_parms that different values are required to find the best separation of the classes.\n",
    "* This is a feature that could easily be incorporated into the StrandVectorizer once it is perfected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20h 46min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 2, 3,\n",
       "       3, 3, 3, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 5, 2, 1, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,\n",
       "       1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 6, 1, 0, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 6, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 6, 0, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 6, 2, 2, 2,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create one truncate parameter for each continuous field\n",
    "# Each value starts at 10 \n",
    "trun_parms = [10] * X_sm_pca200_df.shape[1] \n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Test the trunc value for each column \n",
    "for c in range(X_sm_pca200_df.shape[1]):\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        # Test possible truncate_to values for each individual column\n",
    "        trun_parms[c] = i\n",
    "        sv = StrandVectorizer(truncate_to=trun_parms,signature_length=None, analyzer='word', ngram_range=(1,1)\n",
    "                          , binary=False, use_idf=False, norm=None)\n",
    "        X_sv = sv.fit_transform(X_sm_pca200_df)\n",
    "        # Perform cross validation to find the best value parameter for each column \n",
    "        estimator = StrandSliceClassifier()\n",
    "        scores.append(np.mean(cross_val_score(estimator, X_sv, y_sm, cv=cv, n_jobs=-1, scoring='accuracy')))\n",
    "        \n",
    "    # Find the parm with the max score\n",
    "    best_parm = scores.index(max(scores))\n",
    "    #Use this parameter for this column\n",
    "    trun_parms[c] = best_parm \n",
    "    \n",
    "np.array(trun_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trun_parms = [4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 2, 3,\n",
    "       3, 3, 3, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "       2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 5, 2, 1, 2, 2, 2, 2, 2, 1, 2,\n",
    "       2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,\n",
    "       1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 6, 1, 0, 1, 2, 2, 2, 2,\n",
    "       2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 6, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1,\n",
    "       1, 1, 1, 2, 6, 0, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 6, 2, 2, 2,\n",
    "       1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22790x187358 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4558000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv = StrandVectorizer(truncate_to=trun_parms,signature_length=None, analyzer='word', ngram_range=(1,1)\n",
    "                          , binary=False, use_idf=False, norm=None)\n",
    "X_sv = sv.fit_transform(X_sm_pca200_df)\n",
    "X_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.49275998 0.48266784 0.50416849 0.4681878  0.48310663 0.48530057\n",
      " 0.48837209 0.4839842  0.48705573 0.49100483]\n",
      " \n",
      "Mean Accuracy:  0.4866608161474331\n",
      "Mean Fit Time:  0.7585675477981567\n",
      "Mean Score Time:  0.6791712045669556\n",
      "CV Time:  3.3022758960723877\n"
     ]
    }
   ],
   "source": [
    "from StrandPy import StrandSliceClassifier\n",
    "\n",
    "strand = StrandSliceClassifier()\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "stratified_cross_validate(strand, X_sv, y_sm, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (22790, 187358)\n",
      "-----------------------------------------------------\n",
      "Remove Low Nonzero Features...\n",
      "X Shape: (22790, 187358)\n",
      "Current Base Score:  0.49579\n",
      "Step Features Removed:  148641\n",
      "Total Features Removed:  148641\n",
      "Cross Validations:  616\n",
      "-----------------------------------------------------\n",
      "Remove Features by Importances...\n",
      "X Shape: (22790, 38717)\n",
      "Current Base Score:  0.49588\n",
      "Step Features Removed:  52\n",
      "Total Features Removed:  148693\n",
      "Cross Validations:  715\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 38665)\n",
      "Current Base Score:  0.49588\n",
      "Step Features Removed:  1\n",
      "Total Features Removed:  148694\n",
      "Cross Validations:  718\n",
      "Step size:  19332\n",
      "Step Blocks removed: 5.172770535899027e-05\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 38664)\n",
      "Current Base Score:  0.49588\n",
      "Step Features Removed:  8\n",
      "Total Features Removed:  148702\n",
      "Cross Validations:  727\n",
      "Step size:  4832\n",
      "Step Blocks removed: 0.0016556291390728477\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 38656)\n",
      "Current Base Score:  0.49658\n",
      "Step Features Removed:  3653\n",
      "Total Features Removed:  152355\n",
      "Cross Validations:  760\n",
      "Step size:  1207\n",
      "Step Blocks removed: 3.026512013256007\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 35003)\n",
      "Current Base Score:  0.49719\n",
      "Step Features Removed:  3600\n",
      "Total Features Removed:  155955\n",
      "Cross Validations:  877\n",
      "Step size:  300\n",
      "Step Blocks removed: 12.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 31403)\n",
      "Current Base Score:  0.49917\n",
      "Step Features Removed:  3579\n",
      "Total Features Removed:  159534\n",
      "Cross Validations:  1302\n",
      "Step size:  74\n",
      "Step Blocks removed: 48.36486486486486\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 27824)\n",
      "Current Base Score:  0.50654\n",
      "Step Features Removed:  5146\n",
      "Total Features Removed:  164680\n",
      "Cross Validations:  2939\n",
      "Step size:  17\n",
      "Step Blocks removed: 302.70588235294116\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 22678)\n",
      "Current Base Score:  0.54322\n",
      "Step Features Removed:  7237\n",
      "Total Features Removed:  171917\n",
      "Cross Validations:  10499\n",
      "Step size:  3\n",
      "Step Blocks removed: 2412.3333333333335\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 15441)\n",
      "Current Base Score:  0.56235\n",
      "Step Features Removed:  2830\n",
      "Total Features Removed:  174747\n",
      "Cross Validations:  18220\n",
      "Step size:  2\n",
      "Step Blocks removed: 1415.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 12611)\n",
      "Current Base Score:  0.59329\n",
      "Step Features Removed:  2834\n",
      "Total Features Removed:  177581\n",
      "Cross Validations:  30831\n",
      "Step size:  1\n",
      "Step Blocks removed: 2834.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 9777)\n",
      "Current Base Score:  0.60294\n",
      "Step Features Removed:  1011\n",
      "Total Features Removed:  178592\n",
      "Cross Validations:  40608\n",
      "Step size:  1\n",
      "Step Blocks removed: 1011.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 8766)\n",
      "Current Base Score:  0.60623\n",
      "Step Features Removed:  442\n",
      "Total Features Removed:  179034\n",
      "Cross Validations:  49374\n",
      "Step size:  1\n",
      "Step Blocks removed: 442.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 8324)\n",
      "Current Base Score:  0.60742\n",
      "Step Features Removed:  250\n",
      "Total Features Removed:  179284\n",
      "Cross Validations:  57698\n",
      "Step size:  1\n",
      "Step Blocks removed: 250.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 8074)\n",
      "Current Base Score:  0.60799\n",
      "Step Features Removed:  165\n",
      "Total Features Removed:  179449\n",
      "Cross Validations:  65772\n",
      "Step size:  1\n",
      "Step Blocks removed: 165.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7909)\n",
      "Current Base Score:  0.60847\n",
      "Step Features Removed:  104\n",
      "Total Features Removed:  179553\n",
      "Cross Validations:  73681\n",
      "Step size:  1\n",
      "Step Blocks removed: 104.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7805)\n",
      "Current Base Score:  0.60869\n",
      "Step Features Removed:  94\n",
      "Total Features Removed:  179647\n",
      "Cross Validations:  81486\n",
      "Step size:  1\n",
      "Step Blocks removed: 94.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7711)\n",
      "Current Base Score:  0.60878\n",
      "Step Features Removed:  51\n",
      "Total Features Removed:  179698\n",
      "Cross Validations:  89197\n",
      "Step size:  1\n",
      "Step Blocks removed: 51.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7660)\n",
      "Current Base Score:  0.60878\n",
      "Step Features Removed:  23\n",
      "Total Features Removed:  179721\n",
      "Cross Validations:  96857\n",
      "Step size:  1\n",
      "Step Blocks removed: 23.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7637)\n",
      "Current Base Score:  0.60878\n",
      "Step Features Removed:  19\n",
      "Total Features Removed:  179740\n",
      "Cross Validations:  104494\n",
      "Step size:  1\n",
      "Step Blocks removed: 19.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7618)\n",
      "Current Base Score:  0.60882\n",
      "Step Features Removed:  17\n",
      "Total Features Removed:  179757\n",
      "Cross Validations:  112112\n",
      "Step size:  1\n",
      "Step Blocks removed: 17.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7601)\n",
      "Current Base Score:  0.60891\n",
      "Step Features Removed:  26\n",
      "Total Features Removed:  179783\n",
      "Cross Validations:  119713\n",
      "Step size:  1\n",
      "Step Blocks removed: 26.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7575)\n",
      "Current Base Score:  0.60891\n",
      "Step Features Removed:  13\n",
      "Total Features Removed:  179796\n",
      "Cross Validations:  127288\n",
      "Step size:  1\n",
      "Step Blocks removed: 13.0\n",
      "-----------------------------------------------------\n",
      "X Shape: (22790, 7562)\n",
      "Current Base Score:  0.60891\n",
      "Step Features Removed:  2\n",
      "Total Features Removed:  179798\n",
      "Cross Validations:  134850\n",
      "Step size:  1\n",
      "Step Blocks removed: 2.0\n",
      "-----------------------------------------------------\n",
      "Final Base Score:  0.60891\n",
      "Total Features Removed:  179798\n",
      "Cross Validations:  142410\n",
      "Wall time: 1d 18h 32min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CVFE(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "     estimator=StrandSliceClassifier(feature_importances=False,\n",
       "                                     noise_thresh=None),\n",
       "     feature_importances=array([0.01164985, 0.01164985, 0.01167179, ..., 0.01164985, 0.01164985,\n",
       "       0.01164985]),\n",
       "     min_step_size=1, n_jobs=-1, preserve_increases=True, scoring='accuracy',\n",
       "     verbose=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# StrandPy Tools\n",
    "from StrandPy import StrandSliceClassifier\n",
    "from StrandPy import CVFE\n",
    "# Sklean Tools \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Get feature importances\n",
    "strand = StrandSliceClassifier(feature_importances=True)\n",
    "strand.fit(X_sv, y_sm)\n",
    "feature_importances = strand.feature_importances_\n",
    "\n",
    "# Create faster, no-feature_importances strand object \n",
    "strand = StrandSliceClassifier()\n",
    "\n",
    "# Use Sklearn's StratifiedKFold to manage cross validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Create CVFE object using feature_importances created earlier \n",
    "cvfe = CVFE(strand, cv, n_jobs=-1, min_step_size=1, scoring='accuracy',\n",
    "            preserve_increases=True, feature_importances=feature_importances, verbose=True)\n",
    "\n",
    "cvfe.fit(X_sv, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Scores:\n",
      " \n",
      "[0.61693725 0.60991663 0.61211057 0.60596753 0.6151821  0.61693725\n",
      " 0.59543659 0.61211057 0.60026327 0.60421237]\n",
      " \n",
      "Mean Accuracy:  0.6089074155331288\n",
      "Mean Fit Time:  0.39143297672271726\n",
      "Mean Score Time:  0.08281702995300293\n",
      "CV Time:  0.9590508937835693\n"
     ]
    }
   ],
   "source": [
    "stratified_cross_validate(strand, cvfe.transform(X_sv), y_sm, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Note on Strand Vectorizer Benefits and Enhancements\n",
    "* Strand Vectorizer benefits are not fully expressed in this notebook.  \n",
    "* This is the only tool I know of that would be capable of vectorizing and classifiying a single \"mixed type\" dataset containing documents, gene sequences, numeric, and categorical data.  \n",
    "* I also believe that the Strand Vectorizer may represent a new paradigm in feature engineering.  For example, I was able to turn 30 features into 15,340 and then narrow that down to only 173 features that were best suited for the StrandSliceClassifier.\n",
    "* Once features are transformed into this space, the StrandSliceClassifier outperforms the other classifiers tested in both speed and accuracy in many cases.\n",
    "* In the last example here, it does not.  I think this has something to do with the way bins are created for numeric features. However, this requires a lot more research and work. I have plenty of ideas.\n",
    "* The other piece of work that remains is performing automated selection of the bin sizes i.e. the truncate_to parameter.  However, under other bin selection techniques this would go away entirely.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
