{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify RDP file using SciKit Learn Algorithms\n",
    "* Override Tokenizer in TfidfVectorizer to produce kmers\n",
    "* Override Tokenizer in TfidfVectorizer to produce minhash signatures from kmers\n",
    "* Test both tf-idf and binary, sparse matrices\n",
    "\n",
    "* kmer_length = 15, as larger lengths produce more unique tokens and large matrices\n",
    "* Test matrices against common text classification algorithms including:\n",
    " * 'MultinomialNB','SGDClassifier','RandomForestClassifier','LinearSVC','LogisticRegression'\n",
    "* In each instance perform 10-fold cross validation using StratifiedKFold\n",
    "* Use random_state = 42 whenever possbile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the RDP Test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta_file(file_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(file_path, 'r') as dat:\n",
    "        for line in dat.readlines():\n",
    "            #print(line)\n",
    "            if line[0] == '>':\n",
    "                g_start = line.find(\"g__\")\n",
    "                g_end = line.find(\";\", g_start)\n",
    "                genus = line[g_start:g_end]\n",
    "                y.append(genus)\n",
    "            else:\n",
    "                X.append(line)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size: 4786\n",
      "Longest Sequence Chars:1834\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the fasta file\n",
    "X, y = read_fasta_file('D:/StrandPy/Data/RDP_All_Clean.strand')\n",
    "#Remove low count genera that halt cross validation\n",
    "data = {'X': X,'y':y}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Inspect counts for each class\n",
    "vcts = df.y.value_counts()\n",
    "low_vcts = vcts[vcts < 20].index.values\n",
    "\n",
    "#Remove low count genera. Any classes < the fold count will halt cross validation\n",
    "df = df[~df.y.isin(low_vcts)]\n",
    "\n",
    "# Create X and y\n",
    "X = df.X.values\n",
    "y = df.y.values\n",
    "\n",
    "print('File Size: ' + str(len(X)))\n",
    "print('Longest Sequence Chars:' + str(len(max(X, key=len))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tokenizer with no minhashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_length=15\n",
    "\n",
    "def kmer_generator(text):\n",
    "    kmer_count = len(text) - (kmer_length - 1)\n",
    "    for i in range(0, kmer_count):\n",
    "        yield text[i:i + kmer_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a TfidfVectorizer that uses the naive kmer_generator implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique kmers:  590930\n",
      "X_tfidf shape:,  (4786, 590930)\n",
      "y shape:  (4786,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        \n",
    "tfidf = TfidfVectorizer(tokenizer=kmer_generator, binary=False, use_idf=True)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "print('Total unique kmers: ', len(tfidf.get_feature_names()))\n",
    "print('X_tfidf shape:, ', X_tfidf.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of our sparse X_tfidf:  56\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Size of our sparse X_tfidf: ', sys.getsizeof(X_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4786x590930 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6964226 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Test our sparse matrix against a bunch of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "\n",
    "def stratified_cross_validate(model, X, y, cv):\n",
    "    start = time.time()\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "    elapsed_time = (time.time() - start) \n",
    "    print(cv_results)\n",
    "    print(' ')\n",
    "    print('Mean Accuracy: ', cv_results['test_score'].mean())\n",
    "    print('Wall Time: ', elapsed_time)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "--------------------------------\n",
      "{'fit_time': array([6.90475702, 7.01076293, 6.84175682, 6.45990849, 6.93575382,\n",
      "       6.56391168, 7.06874108, 6.90975547, 3.27616954, 3.08183956]), 'score_time': array([0.71744728, 0.97903275, 0.90545058, 1.24929428, 0.98145032,\n",
      "       0.7589643 , 0.92803264, 0.74245143, 0.33001399, 0.32001662]), 'test_score': array([0.86692759, 0.86706349, 0.86788618, 0.87679671, 0.88075314,\n",
      "       0.86919831, 0.89079229, 0.88720174, 0.88427948, 0.87665198])}\n",
      " \n",
      "Mean Accuracy:  0.8767550913710789\n",
      "Wall Time:  11.474984884262085\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "{'fit_time': array([43.45372415, 44.07971931, 44.01722527, 44.11097193, 43.51723051,\n",
      "       43.67147565, 43.55710268, 44.1943531 , 12.28191304, 12.29127908]), 'score_time': array([0.73437047, 0.69882703, 0.72316742, 0.68257689, 0.68749523,\n",
      "       0.65624619, 0.67187572, 0.64480805, 0.31299281, 0.32799745]), 'test_score': array([0.98825832, 0.99603175, 0.98780488, 0.99794661, 0.99372385,\n",
      "       0.98734177, 1.        , 0.99349241, 1.        , 0.99559471])}\n",
      " \n",
      "Mean Accuracy:  0.99401942960054\n",
      "Wall Time:  57.24052882194519\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "{'fit_time': array([5.42498398, 5.52599239, 5.4849844 , 5.45298195, 5.66603208,\n",
      "       5.51598883, 5.75703812, 5.50798965, 4.93014526, 4.66514015]), 'score_time': array([10.88132453, 10.6691184 , 10.53862906,  9.1776216 , 10.51208448,\n",
      "        9.33963394, 10.24958873,  9.45662832,  2.49893856,  2.49931455]), 'test_score': array([0.45596869, 0.46825397, 0.50406504, 0.48459959, 0.5       ,\n",
      "       0.49367089, 0.51605996, 0.49457701, 0.51965066, 0.5154185 ])}\n",
      " \n",
      "Mean Accuracy:  0.49522642940536243\n",
      "Wall Time:  22.45096206665039\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "{'fit_time': array([235.48168397, 236.9456861 , 238.35890818, 237.03668737,\n",
      "       236.30769324, 232.83368111, 233.39168692, 237.22538424,\n",
      "        56.08934975,  56.27236891]), 'score_time': array([0.44500089, 0.29870772, 0.22791553, 0.267699  , 0.45898986,\n",
      "       0.3440063 , 0.33200574, 0.28640223, 0.10200047, 0.07899976]), 'test_score': array([0.99217221, 0.99603175, 0.99390244, 0.99794661, 0.99790795,\n",
      "       0.99367089, 0.99785867, 0.99566161, 1.        , 0.99559471])}\n",
      " \n",
      "Mean Accuracy:  0.9960746835422161\n",
      "Wall Time:  290.52527141571045\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "{'fit_time': array([445.5505383 , 438.0879941 , 442.61153007, 451.33524847,\n",
      "       452.61334181, 452.21062446, 449.45738959, 447.98752379,\n",
      "       126.4811039 , 124.08537006]), 'score_time': array([0.33599257, 0.31800842, 0.30400181, 0.2869637 , 0.18940663,\n",
      "       0.21399403, 0.31854272, 0.3219943 , 0.13285732, 0.07814884]), 'test_score': array([0.98238748, 0.99206349, 0.98373984, 0.99178645, 0.9832636 ,\n",
      "       0.98312236, 0.99357602, 0.99132321, 0.99344978, 0.99559471])}\n",
      " \n",
      "Mean Accuracy:  0.9890306936692733\n",
      "Wall Time:  567.4871530532837\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "\n",
    "models = [\n",
    "    MultinomialNB(),\n",
    "    SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None),\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=42),\n",
    "    LinearSVC(random_state=42),\n",
    "    LogisticRegression(random_state=42)   \n",
    "]\n",
    "\n",
    "model_names = ['MultinomialNB','SGDClassifier','RandomForestClassifier','LinearSVC','LogisticRegression']\n",
    "\n",
    "for model, model_name in zip(models,model_names):\n",
    "    print(model_name)\n",
    "    print('--------------------------------')\n",
    "    stratified_cross_validate(model,X_tfidf,y,cv)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tokenizer that uses minhashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_length=15\n",
    "minhash_length = 250\n",
    "\n",
    "def kmer_generator(text):\n",
    "    kmer_count = len(text) - (kmer_length - 1)\n",
    "    for i in range(0, kmer_count):\n",
    "        yield text[i:i + kmer_length]\n",
    "        \n",
    "def create_minhash_signature(text):\n",
    "    # Break sequence into a unique set of hashed kmers\n",
    "    kmer_hashes = list(set(hash(kmer) for kmer in kmer_generator(text)))\n",
    "    kmer_hashes.sort()\n",
    "\n",
    "    if minhash_length==None:\n",
    "        #Return all of the kmer_hashes as the signature \n",
    "        signature = kmer_hashes\n",
    "    else:\n",
    "        #Take the first minhash_length hashes to create the minhash signature \n",
    "        signature = kmer_hashes[:minhash_length]\n",
    "\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a TfidfVectorizer that uses the minhash implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique minhashes:  101870\n",
      "X_tfidf shape:,  (4786, 101870)\n",
      "y shape:  (4786,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        \n",
    "tfidf = TfidfVectorizer(tokenizer=create_minhash_signature, binary=False, use_idf=True)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "print('Total unique minhashes: ', len(tfidf.get_feature_names()))\n",
    "print('X_tfidf shape:, ', X_tfidf.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of our sparse X_tfidf:  56\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Size of our sparse X_tfidf: ', sys.getsizeof(X_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4786x101870 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1196500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Test our sparse MinHash matrix against a bunch of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "\n",
    "def stratified_cross_validate(model, X, y, cv):\n",
    "    start = time.time()\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "    elapsed_time = (time.time() - start) \n",
    "    print(cv_results)\n",
    "    print(' ')\n",
    "    print('Mean Accuracy: ', cv_results['test_score'].mean())\n",
    "    print('Wall Time: ', elapsed_time)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "--------------------------------\n",
      "{'fit_time': array([0.89999413, 0.99600077, 0.87200952, 0.87200952, 0.91000915,\n",
      "       0.98100114, 1.01599026, 1.01900077, 0.49891543, 0.47329736]), 'score_time': array([0.12200212, 0.10199022, 0.14098859, 0.13598609, 0.11399889,\n",
      "       0.10198879, 0.09299755, 0.08999133, 0.06250215, 0.04687166]), 'test_score': array([0.89236791, 0.88492063, 0.88617886, 0.90349076, 0.89539749,\n",
      "       0.89029536, 0.90792291, 0.90455531, 0.90393013, 0.88986784])}\n",
      " \n",
      "Mean Accuracy:  0.8958927209872168\n",
      "Wall Time:  1.767406702041626\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "{'fit_time': array([3.99300385, 4.00099683, 4.01599455, 4.07999969, 4.02299476,\n",
      "       4.00499701, 4.0339942 , 4.09973288, 1.49460292, 1.55561543]), 'score_time': array([0.10900593, 0.11000896, 0.10800433, 0.08510661, 0.10400939,\n",
      "       0.10899878, 0.10000539, 0.05571437, 0.04999876, 0.05950284]), 'test_score': array([0.98825832, 0.99603175, 0.98780488, 0.99794661, 0.99372385,\n",
      "       0.98523207, 1.        , 0.99349241, 1.        , 0.99559471])}\n",
      " \n",
      "Mean Accuracy:  0.9938084591364049\n",
      "Wall Time:  6.028123140335083\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "{'fit_time': array([1.87190056, 1.95290017, 1.82111454, 1.83674192, 1.78986287,\n",
      "       1.80448079, 1.81611323, 1.92633891, 1.57971501, 1.55546927]), 'score_time': array([0.94536471, 0.75936961, 0.74905801, 0.84280586, 0.8271842 ,\n",
      "       0.73345447, 0.84280634, 0.74335814, 0.17071581, 0.17371678]), 'test_score': array([0.42270059, 0.43650794, 0.41463415, 0.43531828, 0.458159  ,\n",
      "       0.43881857, 0.46680942, 0.45553145, 0.45633188, 0.45154185])}\n",
      " \n",
      "Mean Accuracy:  0.4436353109457616\n",
      "Wall Time:  4.513607025146484\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "{'fit_time': array([21.38602519, 21.86202836, 21.7470305 , 22.05402303, 22.10098553,\n",
      "       22.31254792, 21.98301935, 21.87601519,  6.71297073,  6.52704239]), 'score_time': array([0.0349977 , 0.0459938 , 0.03900003, 0.03200817, 0.02303553,\n",
      "       0.03123713, 0.0390141 , 0.0309999 , 0.01200342, 0.00899744]), 'test_score': array([0.99217221, 0.99603175, 0.99186992, 0.99794661, 0.99790795,\n",
      "       0.99367089, 0.99785867, 0.99566161, 1.        , 0.99559471])}\n",
      " \n",
      "Mean Accuracy:  0.9958714315096957\n",
      "Wall Time:  28.51099967956543\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "{'fit_time': array([58.06124902, 59.45223927, 59.37424111, 60.09824514, 59.17324114,\n",
      "       60.09124875, 58.12025619, 60.25744247, 19.49105573, 19.3490417 ]), 'score_time': array([0.04300284, 0.03600264, 0.03701138, 0.03100371, 0.04000974,\n",
      "       0.03199601, 0.03499222, 0.02700353, 0.00900054, 0.01300097]), 'test_score': array([0.98238748, 0.99007937, 0.98373984, 0.99178645, 0.98535565,\n",
      "       0.98101266, 0.99357602, 0.98698482, 0.98908297, 0.99118943])}\n",
      " \n",
      "Mean Accuracy:  0.9875194661911848\n",
      "Wall Time:  77.7856605052948\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "\n",
    "models = [\n",
    "    MultinomialNB(),\n",
    "    SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None),\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=42),\n",
    "    LinearSVC(random_state=42),\n",
    "    LogisticRegression(random_state=42)   \n",
    "]\n",
    "\n",
    "model_names = ['MultinomialNB','SGDClassifier','RandomForestClassifier','LinearSVC','LogisticRegression']\n",
    "\n",
    "for model, model_name in zip(models,model_names):\n",
    "    print(model_name)\n",
    "    print('--------------------------------')\n",
    "    stratified_cross_validate(model,X_tfidf,y,cv)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Binary TfidfVectorizer that uses the minhash implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique minhashes:  101870\n",
      "X_tfidf shape:,  (4786, 101870)\n",
      "y shape:  (4786,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        \n",
    "tfidf = TfidfVectorizer(tokenizer=create_minhash_signature, binary=True, use_idf=False, norm=None)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "print('Total unique minhashes: ', len(tfidf.get_feature_names()))\n",
    "print('X_tfidf shape:, ', X_tfidf.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of our sparse X_tfidf:  56\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Size of our sparse X_tfidf: ', sys.getsizeof(X_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4786x101870 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1196500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Test our sparse, binary MinHash matrix against a bunch of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "\n",
    "def stratified_cross_validate(model, X, y, cv):\n",
    "    start = time.time()\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "    elapsed_time = (time.time() - start) \n",
    "    print(cv_results)\n",
    "    print(' ')\n",
    "    print('Mean Accuracy: ', cv_results['test_score'].mean())\n",
    "    print('Wall Time: ', elapsed_time)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "--------------------------------\n",
      "{'fit_time': array([0.90298414, 0.90298414, 0.88735485, 0.88735485, 0.88735485,\n",
      "       0.88735485, 0.90298223, 0.92529416, 0.4060266 , 0.39039683]), 'score_time': array([0.10936332, 0.10936332, 0.1093719 , 0.1093719 , 0.1093719 ,\n",
      "       0.1093719 , 0.09374332, 0.09375405, 0.04685569, 0.06248546]), 'test_score': array([0.97455969, 0.97619048, 0.96341463, 0.97741273, 0.9707113 ,\n",
      "       0.96835443, 0.98072805, 0.97830803, 0.98253275, 0.969163  ])}\n",
      " \n",
      "Mean Accuracy:  0.9741375079790956\n",
      "Wall Time:  3.730381488800049\n",
      " \n",
      "SGDClassifier\n",
      "--------------------------------\n",
      "{'fit_time': array([4.08680749, 4.02349257, 4.00786662, 4.1019001 , 4.16441011,\n",
      "       4.13315654, 4.15740633, 4.22555017, 1.4250977 , 1.40947151]), 'score_time': array([0.09222054, 0.09404564, 0.10967159, 0.10938478, 0.10378766,\n",
      "       0.11939359, 0.10378766, 0.06252503, 0.04687715, 0.04686904]), 'test_score': array([0.99021526, 0.99404762, 0.99186992, 0.99794661, 0.99372385,\n",
      "       0.98945148, 0.99785867, 0.99349241, 1.        , 0.99118943])}\n",
      " \n",
      "Mean Accuracy:  0.9939795247508718\n",
      "Wall Time:  5.9276368618011475\n",
      " \n",
      "RandomForestClassifier\n",
      "--------------------------------\n",
      "{'fit_time': array([1.6473248 , 1.70333028, 1.6813271 , 1.63732362, 1.73671031,\n",
      "       1.66932464, 1.70832682, 1.76875591, 1.45512724, 1.43311095]), 'score_time': array([0.75576091, 0.87974095, 0.80075526, 0.71345544, 0.82736683,\n",
      "       0.81275773, 0.86075377, 0.81068444, 0.3155086 , 0.20137739]), 'test_score': array([0.54990215, 0.53968254, 0.51219512, 0.56468172, 0.54811715,\n",
      "       0.56118143, 0.56959315, 0.54880694, 0.58078603, 0.53303965])}\n",
      " \n",
      "Mean Accuracy:  0.5507985891493747\n",
      "Wall Time:  4.5118536949157715\n",
      " \n",
      "LinearSVC\n",
      "--------------------------------\n",
      "{'fit_time': array([27.47781372, 27.59013915, 27.14969754, 24.65843558, 27.30494022,\n",
      "       22.58285284, 26.80568671, 27.21144533,  9.69755793,  7.11050177]), 'score_time': array([0.0312531 , 0.01100063, 0.03125072, 0.03099132, 0.03125572,\n",
      "       0.03124595, 0.04688406, 0.03125286, 0.00999665, 0.01899672]), 'test_score': array([0.99217221, 0.99603175, 0.99186992, 0.99794661, 0.9958159 ,\n",
      "       0.99367089, 0.99785867, 0.99349241, 1.        , 0.99559471])}\n",
      " \n",
      "Mean Accuracy:  0.9954453067490789\n",
      "Wall Time:  32.63639283180237\n",
      " \n",
      "LogisticRegression\n",
      "--------------------------------\n",
      "{'fit_time': array([98.25477529, 95.51304054, 96.18165612, 97.58289361, 96.71859622,\n",
      "       97.22047925, 98.34374976, 98.22351146, 28.74791622, 28.04851007]), 'score_time': array([0.03125191, 0.04688239, 0.03575206, 0.03126574, 0.03311968,\n",
      "       0.05069375, 0.02273822, 0.03125834, 0.01562548, 0.01300097]), 'test_score': array([0.99217221, 0.99603175, 0.99186992, 0.99794661, 0.9958159 ,\n",
      "       0.99367089, 0.99785867, 0.99566161, 1.        , 0.99559471])}\n",
      " \n",
      "Mean Accuracy:  0.9956622264887752\n",
      "Wall Time:  124.62039685249329\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "\n",
    "models = [\n",
    "    MultinomialNB(),\n",
    "    SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None),\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=42),\n",
    "    LinearSVC(random_state=42),\n",
    "    LogisticRegression(random_state=42)   \n",
    "]\n",
    "\n",
    "model_names = ['MultinomialNB','SGDClassifier','RandomForestClassifier','LinearSVC','LogisticRegression']\n",
    "\n",
    "for model, model_name in zip(models,model_names):\n",
    "    print(model_name)\n",
    "    print('--------------------------------')\n",
    "    stratified_cross_validate(model,X_tfidf,y,cv)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
